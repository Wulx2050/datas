{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMPy48R19Umd",
        "colab_type": "code",
        "outputId": "a91ed978-5937-473d-dcd0-22df5595b822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.4\n",
            "1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBCJ0M6WL5ST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x29VGkI8MLC7",
        "colab_type": "code",
        "outputId": "aebc81bc-8f08-4f31-a360-d54768620636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ssWXnudMLFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2xfPNkSMLIe",
        "colab_type": "code",
        "outputId": "b19f6b8e-c061-4e98-a98b-cb4a42d5aaea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "plt.imshow(x_train[6])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6d4ce99a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inhesaWhMLLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'标签字典'\n",
        "label_dict = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer',\n",
        "              5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}\n",
        "\n",
        "def plot_images_lables_prediction(images_list, labels_list, prediction_list, # 图像，标签， 预测值\n",
        "                                  index=0,      # 开始指针\n",
        "                                  num=10, num_max=25):    # 设置显示图的数量\n",
        "    \n",
        "    fig = plt.gcf()  #  获取当前图表 get current figure\n",
        "    fig.set_size_inches(20, 20)  #  1 inches = 2.54 cm\n",
        "    if num > num_max:\n",
        "        num = num_max\n",
        "    for i in range(0, num):\n",
        "        ax = plt.subplot(5, 5, i+1)\n",
        "        ax.imshow(images_list[index], cmap='binary')\n",
        "        title = str(index) + ': ' + label_dict[int(labels_list[index])]\n",
        "        if len(prediction_list) > 0:\n",
        "            title += '= >' + str(prediction_list[index])\n",
        "        ax.set_title(title, fontsize=30)\n",
        "        ax.set_xticks([])   # 不显示x坐标轴\n",
        "        ax.set_yticks([])   # 不显示y坐标轴\n",
        "        index += 1\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yRIrPD0MLOK",
        "colab_type": "code",
        "outputId": "4514c487-2314-466f-cb79-5153ccaaceb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "plot_images_lables_prediction(x_train, y_train, [], index=1000, num=10, num_max=25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGwAAAHLCAYAAACd0Q6tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAJQML2wAAAAAAABK5v8HwZLNiDNuL3MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x1440 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBz0LonJMcf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "from keras.utils import np_utils\n",
        "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7pew8zOq4GO",
        "colab_type": "text"
      },
      "source": [
        "## 基础卷积网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMokUEsQMcjZ",
        "colab_type": "code",
        "outputId": "c3c9b2ae-696c-4d0b-c6b7-be7bc9524ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        }
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_251 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_252 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_253 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_61 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_254 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_255 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_256 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_257 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_62 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_258 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_259 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_260 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_261 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_262 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_63 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_18  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 815,050\n",
            "Trainable params: 814,602\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ckxDC5Mcn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "\n",
        "optimizer = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=1e-6)\n",
        "# optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-5, amsgrad=False)\n",
        "# optimizer = RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=1e-3)\n",
        "# optimizer = SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
        "\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfbZ6xFPMcu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_1.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "# callbacks = [model_checkpoint, reduce_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVLeddWWMcsB",
        "colab_type": "code",
        "outputId": "27d6a9d4-fb11-49cc-86f1-5d905de93f72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2719
        }
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128,\n",
        "          epochs=100, validation_split=0.2,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 22s 545us/step - loss: 1.6196 - acc: 0.3995 - val_loss: 2.5863 - val_acc: 0.3200\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.32000, saving model to cifar10_model_1.h5\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 1.1069 - acc: 0.6061 - val_loss: 1.7196 - val_acc: 0.4997\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.32000 to 0.49970, saving model to cifar10_model_1.h5\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.8723 - acc: 0.6953 - val_loss: 1.5601 - val_acc: 0.5268\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.49970 to 0.52680, saving model to cifar10_model_1.h5\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.7229 - acc: 0.7475 - val_loss: 1.2558 - val_acc: 0.6075\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.52680 to 0.60750, saving model to cifar10_model_1.h5\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.6263 - acc: 0.7806 - val_loss: 0.9242 - val_acc: 0.7006\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.60750 to 0.70060, saving model to cifar10_model_1.h5\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.5435 - acc: 0.8098 - val_loss: 0.9705 - val_acc: 0.6791\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.70060\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 10s 252us/step - loss: 0.4787 - acc: 0.8334 - val_loss: 1.0029 - val_acc: 0.6561\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.70060\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 10s 252us/step - loss: 0.4221 - acc: 0.8543 - val_loss: 1.0787 - val_acc: 0.6895\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.70060\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 10s 252us/step - loss: 0.3635 - acc: 0.8727 - val_loss: 0.7359 - val_acc: 0.7764\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.70060 to 0.77640, saving model to cifar10_model_1.h5\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 10s 252us/step - loss: 0.3108 - acc: 0.8921 - val_loss: 0.8922 - val_acc: 0.7399\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.77640\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.2668 - acc: 0.9073 - val_loss: 1.0377 - val_acc: 0.7123\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.77640\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.2285 - acc: 0.9200 - val_loss: 0.8596 - val_acc: 0.7585\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.77640\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 10s 252us/step - loss: 0.1900 - acc: 0.9325 - val_loss: 0.9197 - val_acc: 0.7704\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.77640\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 0.1612 - acc: 0.9434 - val_loss: 1.2361 - val_acc: 0.7030\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.77640\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 0.0589 - acc: 0.9823 - val_loss: 0.6471 - val_acc: 0.8319\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.77640 to 0.83190, saving model to cifar10_model_1.h5\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 0.0282 - acc: 0.9936 - val_loss: 0.6843 - val_acc: 0.8318\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.83190\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.0165 - acc: 0.9973 - val_loss: 0.6714 - val_acc: 0.8377\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.83190 to 0.83770, saving model to cifar10_model_1.h5\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.0106 - acc: 0.9989 - val_loss: 0.7115 - val_acc: 0.8392\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.83770 to 0.83920, saving model to cifar10_model_1.h5\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.0073 - acc: 0.9994 - val_loss: 0.7278 - val_acc: 0.8410\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.83920 to 0.84100, saving model to cifar10_model_1.h5\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.0053 - acc: 0.9996 - val_loss: 0.7803 - val_acc: 0.8396\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.84100\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 0.7731 - val_acc: 0.8418\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.84100 to 0.84180, saving model to cifar10_model_1.h5\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.8081 - val_acc: 0.8387\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.84180\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.8124 - val_acc: 0.8424\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.84180 to 0.84240, saving model to cifar10_model_1.h5\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.8174 - val_acc: 0.8429\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.84240 to 0.84290, saving model to cifar10_model_1.h5\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8254 - val_acc: 0.8464\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.84290 to 0.84640, saving model to cifar10_model_1.h5\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8426 - val_acc: 0.8409\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.84640\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8556 - val_acc: 0.8436\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.84640\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8432 - val_acc: 0.8439\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.84640\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 10s 252us/step - loss: 9.7935e-04 - acc: 1.0000 - val_loss: 0.8650 - val_acc: 0.8414\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.84640\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 8.7793e-04 - acc: 1.0000 - val_loss: 0.8699 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.84640\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 7.6352e-04 - acc: 1.0000 - val_loss: 0.8663 - val_acc: 0.8433\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.84640\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 6.9336e-04 - acc: 1.0000 - val_loss: 0.8662 - val_acc: 0.8443\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.84640\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 7.3568e-04 - acc: 1.0000 - val_loss: 0.8708 - val_acc: 0.8445\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.84640\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 10s 253us/step - loss: 6.5762e-04 - acc: 1.0000 - val_loss: 0.8687 - val_acc: 0.8445\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.84640\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 6.7097e-04 - acc: 1.0000 - val_loss: 0.8720 - val_acc: 0.8453\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.84640\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 00035: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c60a5be80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J-U6lvtNza3",
        "colab_type": "code",
        "outputId": "c0a2b64d-c0d0-40c5-8511-83ee6a5b9782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_1.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 6s 561us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8650078344345092, 0.8372]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOlWwj38Nzmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JKoSSfcnjjZ",
        "colab_type": "text"
      },
      "source": [
        "## 正则化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehk4kHu4NzsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import regularizers\n",
        "\n",
        "def model_regularizers(regularizer):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3), kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    \n",
        "    optimizer = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=1e-6)\n",
        "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubAYJiw9nu8F",
        "colab_type": "text"
      },
      "source": [
        "### regularizers.l2(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAWmmD8FQlJW",
        "colab_type": "code",
        "outputId": "296de436-dd0c-4f69-839e-7e00b0afb262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4697
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "from keras import regularizers\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_2.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "regularizer = regularizers.l2(0.1)    # <<---------------------------------\n",
        "model = model_regularizers(regularizer)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128,\n",
        "          epochs=100, validation_split=0.2,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_155 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_156 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_157 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_158 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_159 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_160 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_161 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_162 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_163 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_164 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_165 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_166 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_10  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 815,050\n",
            "Trainable params: 814,602\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 15s 374us/step - loss: 7.8913 - acc: 0.1929 - val_loss: 2.1185 - val_acc: 0.2073\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.20730, saving model to cifar10_model_2.h5\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 10s 250us/step - loss: 2.0567 - acc: 0.2134 - val_loss: 2.0495 - val_acc: 0.1996\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.20730\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 10s 248us/step - loss: 2.0179 - acc: 0.2224 - val_loss: 3.6243 - val_acc: 0.0990\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.20730\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 10s 249us/step - loss: 1.9940 - acc: 0.2329 - val_loss: 1.9791 - val_acc: 0.2384\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.20730 to 0.23840, saving model to cifar10_model_2.h5\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 1.9824 - acc: 0.2421 - val_loss: 2.2092 - val_acc: 0.1741\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.23840\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 1.9720 - acc: 0.2518 - val_loss: 6.8058 - val_acc: 0.1001\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.23840\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.9633 - acc: 0.2554 - val_loss: 2.4150 - val_acc: 0.1809\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.23840\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.9542 - acc: 0.2646 - val_loss: 3.1599 - val_acc: 0.1187\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.23840\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.9492 - acc: 0.2638 - val_loss: 3.4151 - val_acc: 0.1218\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.23840\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.9126 - acc: 0.2808 - val_loss: 2.3348 - val_acc: 0.1920\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.23840\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.9085 - acc: 0.2819 - val_loss: 1.9784 - val_acc: 0.2665\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.23840 to 0.26650, saving model to cifar10_model_2.h5\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.9047 - acc: 0.2887 - val_loss: 1.9154 - val_acc: 0.2834\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.26650 to 0.28340, saving model to cifar10_model_2.h5\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.9045 - acc: 0.2860 - val_loss: 1.8921 - val_acc: 0.3055\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.28340 to 0.30550, saving model to cifar10_model_2.h5\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.9032 - acc: 0.2901 - val_loss: 2.1360 - val_acc: 0.2356\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.30550\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8994 - acc: 0.2893 - val_loss: 1.9735 - val_acc: 0.2628\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.30550\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8978 - acc: 0.2914 - val_loss: 2.5492 - val_acc: 0.1669\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.30550\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8973 - acc: 0.2923 - val_loss: 2.2191 - val_acc: 0.2328\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.30550\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8942 - acc: 0.2951 - val_loss: 1.8916 - val_acc: 0.2929\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.30550\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8864 - acc: 0.2981 - val_loss: 1.8728 - val_acc: 0.3094\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.30550 to 0.30940, saving model to cifar10_model_2.h5\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8857 - acc: 0.2967 - val_loss: 1.8835 - val_acc: 0.3069\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.30940\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8855 - acc: 0.2993 - val_loss: 1.8737 - val_acc: 0.3095\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.30940 to 0.30950, saving model to cifar10_model_2.h5\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8855 - acc: 0.2999 - val_loss: 1.8679 - val_acc: 0.3131\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.30950 to 0.31310, saving model to cifar10_model_2.h5\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8833 - acc: 0.2986 - val_loss: 1.8953 - val_acc: 0.3038\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.31310\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8819 - acc: 0.3019 - val_loss: 1.8939 - val_acc: 0.3051\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.31310\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8859 - acc: 0.2994 - val_loss: 1.8673 - val_acc: 0.3078\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.31310\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8838 - acc: 0.3035 - val_loss: 1.8654 - val_acc: 0.3130\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.31310\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 1.8803 - acc: 0.3039 - val_loss: 1.8742 - val_acc: 0.3123\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.31310\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8801 - acc: 0.3029 - val_loss: 1.8632 - val_acc: 0.3118\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.31310\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8812 - acc: 0.3006 - val_loss: 1.8637 - val_acc: 0.3150\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.31310 to 0.31500, saving model to cifar10_model_2.h5\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8823 - acc: 0.3020 - val_loss: 1.8619 - val_acc: 0.3147\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.31500\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8790 - acc: 0.3050 - val_loss: 1.8651 - val_acc: 0.3124\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.31500\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8793 - acc: 0.3014 - val_loss: 1.8623 - val_acc: 0.3146\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.31500\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8804 - acc: 0.3019 - val_loss: 1.8620 - val_acc: 0.3168\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.31500 to 0.31680, saving model to cifar10_model_2.h5\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8805 - acc: 0.3052 - val_loss: 1.8685 - val_acc: 0.3149\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.31680\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8793 - acc: 0.3039 - val_loss: 1.8622 - val_acc: 0.3137\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.31680\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8790 - acc: 0.3038 - val_loss: 1.8636 - val_acc: 0.3132\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.31680\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8788 - acc: 0.3046 - val_loss: 1.8658 - val_acc: 0.3116\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.31680\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8782 - acc: 0.3053 - val_loss: 1.8637 - val_acc: 0.3131\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.31680\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8777 - acc: 0.3045 - val_loss: 1.8604 - val_acc: 0.3172\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.31680 to 0.31720, saving model to cifar10_model_2.h5\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8786 - acc: 0.3050 - val_loss: 1.8606 - val_acc: 0.3164\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.31720\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8786 - acc: 0.3072 - val_loss: 1.8605 - val_acc: 0.3155\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.31720\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8802 - acc: 0.3029 - val_loss: 1.8604 - val_acc: 0.3170\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.31720\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8801 - acc: 0.3053 - val_loss: 1.8604 - val_acc: 0.3165\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.31720\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8801 - acc: 0.3039 - val_loss: 1.8606 - val_acc: 0.3165\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.31720\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0003199999686330557.\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8783 - acc: 0.3057 - val_loss: 1.8604 - val_acc: 0.3163\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.31720\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8776 - acc: 0.3060 - val_loss: 1.8604 - val_acc: 0.3164\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.31720\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8807 - acc: 0.3025 - val_loss: 1.8604 - val_acc: 0.3167\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.31720\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.8776 - acc: 0.3061 - val_loss: 1.8604 - val_acc: 0.3165\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.31720\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8801 - acc: 0.3034 - val_loss: 1.8603 - val_acc: 0.3167\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.31720\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 6.399999256245792e-05.\n",
            "Epoch 00049: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c69e5d860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiWOrDQ5X1qE",
        "colab_type": "code",
        "outputId": "98738df4-4f5f-48ef-c6ba-806d7259ce74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_2.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 359us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8557699523925781, 0.3108]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huPM2Zyan4ix",
        "colab_type": "text"
      },
      "source": [
        "### regularizers.l2(0.01)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhbESsAcQlGA",
        "colab_type": "code",
        "outputId": "e0205f9a-4a6d-400e-e428-4edc8a4f682a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4517
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "from keras import regularizers\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_3.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "regularizer = regularizers.l2(0.01)    # <<---------------------------------\n",
        "model = model_regularizers(regularizer)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128,\n",
        "          epochs=100, validation_split=0.2,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_167 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_168 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_169 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_170 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_171 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_172 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_173 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_174 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_175 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_176 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_177 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_178 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_11  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 815,050\n",
            "Trainable params: 814,602\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 15s 383us/step - loss: 4.2206 - acc: 0.3422 - val_loss: 2.7299 - val_acc: 0.2430\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.24300, saving model to cifar10_model_3.h5\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 10s 249us/step - loss: 1.8178 - acc: 0.4742 - val_loss: 2.5375 - val_acc: 0.3219\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.24300 to 0.32190, saving model to cifar10_model_3.h5\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 10s 248us/step - loss: 1.5469 - acc: 0.5437 - val_loss: 10.4959 - val_acc: 0.1335\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.32190\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 10s 249us/step - loss: 1.4320 - acc: 0.5797 - val_loss: 5.1780 - val_acc: 0.2536\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.32190\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 10s 247us/step - loss: 1.3492 - acc: 0.6101 - val_loss: 1.9275 - val_acc: 0.4329\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.32190 to 0.43290, saving model to cifar10_model_3.h5\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 1.2914 - acc: 0.6305 - val_loss: 2.7154 - val_acc: 0.3648\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.43290\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 1.2538 - acc: 0.6459 - val_loss: 3.3325 - val_acc: 0.3037\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.43290\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 10s 247us/step - loss: 1.2185 - acc: 0.6601 - val_loss: 3.0457 - val_acc: 0.2555\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.43290\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 1.1879 - acc: 0.6704 - val_loss: 1.6399 - val_acc: 0.5166\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.43290 to 0.51660, saving model to cifar10_model_3.h5\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.1662 - acc: 0.6791 - val_loss: 2.2049 - val_acc: 0.4257\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.51660\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.1429 - acc: 0.6931 - val_loss: 3.3842 - val_acc: 0.3001\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.51660\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.1251 - acc: 0.6972 - val_loss: 1.6272 - val_acc: 0.5545\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.51660 to 0.55450, saving model to cifar10_model_3.h5\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.1100 - acc: 0.7040 - val_loss: 2.7418 - val_acc: 0.4209\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.55450\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.0924 - acc: 0.7099 - val_loss: 2.6486 - val_acc: 0.3972\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.55450\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.0842 - acc: 0.7150 - val_loss: 1.4668 - val_acc: 0.5990\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.55450 to 0.59900, saving model to cifar10_model_3.h5\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.0694 - acc: 0.7201 - val_loss: 2.1699 - val_acc: 0.4206\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.59900\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 1.0632 - acc: 0.7231 - val_loss: 1.9759 - val_acc: 0.4575\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.59900\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.0574 - acc: 0.7253 - val_loss: 3.1954 - val_acc: 0.2699\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.59900\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.0448 - acc: 0.7318 - val_loss: 2.2091 - val_acc: 0.4657\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.59900\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.0405 - acc: 0.7334 - val_loss: 5.4199 - val_acc: 0.2292\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.59900\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.8780 - acc: 0.7878 - val_loss: 1.2012 - val_acc: 0.6716\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.59900 to 0.67160, saving model to cifar10_model_3.h5\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.8373 - acc: 0.7975 - val_loss: 0.9267 - val_acc: 0.7637\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.67160 to 0.76370, saving model to cifar10_model_3.h5\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.8173 - acc: 0.8012 - val_loss: 0.9056 - val_acc: 0.7754\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.76370 to 0.77540, saving model to cifar10_model_3.h5\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.8027 - acc: 0.8038 - val_loss: 1.0165 - val_acc: 0.7356\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.77540\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.7914 - acc: 0.8085 - val_loss: 1.1338 - val_acc: 0.7032\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.77540\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.7810 - acc: 0.8109 - val_loss: 0.9189 - val_acc: 0.7581\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.77540\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7730 - acc: 0.8138 - val_loss: 1.0005 - val_acc: 0.7424\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.77540\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7640 - acc: 0.8166 - val_loss: 1.1449 - val_acc: 0.6967\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.77540\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7140 - acc: 0.8360 - val_loss: 0.8171 - val_acc: 0.8005\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.77540 to 0.80050, saving model to cifar10_model_3.h5\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7059 - acc: 0.8382 - val_loss: 0.8100 - val_acc: 0.8019\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.80050 to 0.80190, saving model to cifar10_model_3.h5\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7032 - acc: 0.8388 - val_loss: 0.8133 - val_acc: 0.8038\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.80190 to 0.80380, saving model to cifar10_model_3.h5\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7000 - acc: 0.8407 - val_loss: 0.8202 - val_acc: 0.7967\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80380\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.6966 - acc: 0.8412 - val_loss: 0.8304 - val_acc: 0.7952\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80380\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6942 - acc: 0.8425 - val_loss: 0.8276 - val_acc: 0.7982\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80380\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6897 - acc: 0.8439 - val_loss: 0.8269 - val_acc: 0.7944\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80380\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6874 - acc: 0.8432 - val_loss: 0.8450 - val_acc: 0.7929\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80380\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6769 - acc: 0.8476 - val_loss: 0.7951 - val_acc: 0.8109\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.80380 to 0.81090, saving model to cifar10_model_3.h5\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6718 - acc: 0.8492 - val_loss: 0.7965 - val_acc: 0.8086\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.81090\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.6737 - acc: 0.8483 - val_loss: 0.7947 - val_acc: 0.8089\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.81090\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.6702 - acc: 0.8505 - val_loss: 0.7966 - val_acc: 0.8091\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.81090\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6698 - acc: 0.8494 - val_loss: 0.7957 - val_acc: 0.8069\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.81090\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6711 - acc: 0.8494 - val_loss: 0.7965 - val_acc: 0.8092\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.81090\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6682 - acc: 0.8525 - val_loss: 0.7940 - val_acc: 0.8094\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.81090\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6667 - acc: 0.8507 - val_loss: 0.7937 - val_acc: 0.8095\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.81090\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6663 - acc: 0.8509 - val_loss: 0.7934 - val_acc: 0.8100\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.81090\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.6671 - acc: 0.8516 - val_loss: 0.7935 - val_acc: 0.8100\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.81090\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6678 - acc: 0.8508 - val_loss: 0.7938 - val_acc: 0.8096\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.81090\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0003199999686330557.\n",
            "Epoch 00047: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c68930240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeUpcI-YY96B",
        "colab_type": "code",
        "outputId": "cfa5ea11-11db-4f86-a907-5321e48fbf40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_3.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 377us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8144150612831116, 0.8047]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6CwLGoBoAc5",
        "colab_type": "text"
      },
      "source": [
        "### regularizers.l2(0.001)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhOTdhESY93O",
        "colab_type": "code",
        "outputId": "1f5cf9f7-274d-49e9-e491-9cf4448c42b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3329
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "from keras import regularizers\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_4.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "regularizer = regularizers.l2(0.001)    # <<---------------------------------\n",
        "model = model_regularizers(regularizer)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128,\n",
        "          epochs=100, validation_split=0.2,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_179 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_180 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_181 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_182 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_183 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_184 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_185 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_186 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_187 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_188 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_189 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_190 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_12  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 815,050\n",
            "Trainable params: 814,602\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 15s 382us/step - loss: 2.2699 - acc: 0.4245 - val_loss: 2.8532 - val_acc: 0.3152\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.31520, saving model to cifar10_model_4.h5\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 1.5222 - acc: 0.6193 - val_loss: 2.2215 - val_acc: 0.4564\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.31520 to 0.45640, saving model to cifar10_model_4.h5\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 1.2292 - acc: 0.6922 - val_loss: 1.8019 - val_acc: 0.4740\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.45640 to 0.47400, saving model to cifar10_model_4.h5\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 10s 247us/step - loss: 1.0747 - acc: 0.7318 - val_loss: 1.5755 - val_acc: 0.5861\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.47400 to 0.58610, saving model to cifar10_model_4.h5\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.9873 - acc: 0.7543 - val_loss: 1.5551 - val_acc: 0.6053\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.58610 to 0.60530, saving model to cifar10_model_4.h5\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.9175 - acc: 0.7768 - val_loss: 1.8257 - val_acc: 0.5865\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.60530\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.8718 - acc: 0.7919 - val_loss: 1.4845 - val_acc: 0.6115\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.60530 to 0.61150, saving model to cifar10_model_4.h5\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.8202 - acc: 0.8097 - val_loss: 2.5823 - val_acc: 0.4180\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.61150\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.7896 - acc: 0.8205 - val_loss: 1.4277 - val_acc: 0.6515\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.61150 to 0.65150, saving model to cifar10_model_4.h5\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.7626 - acc: 0.8302 - val_loss: 1.7390 - val_acc: 0.5775\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.65150\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7380 - acc: 0.8384 - val_loss: 2.1641 - val_acc: 0.5198\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.65150\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.7133 - acc: 0.8482 - val_loss: 1.4799 - val_acc: 0.6420\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.65150\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6900 - acc: 0.8569 - val_loss: 1.6689 - val_acc: 0.6136\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.65150\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6772 - acc: 0.8617 - val_loss: 1.7431 - val_acc: 0.6055\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.65150\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.4834 - acc: 0.9308 - val_loss: 0.7567 - val_acc: 0.8433\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.65150 to 0.84330, saving model to cifar10_model_4.h5\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.4082 - acc: 0.9518 - val_loss: 0.8041 - val_acc: 0.8338\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.84330\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.3605 - acc: 0.9649 - val_loss: 0.8261 - val_acc: 0.8326\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.84330\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.3222 - acc: 0.9748 - val_loss: 0.8470 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.84330\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.2921 - acc: 0.9825 - val_loss: 0.8668 - val_acc: 0.8342\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.84330\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.2698 - acc: 0.9869 - val_loss: 0.9658 - val_acc: 0.8237\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.84330\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.2408 - acc: 0.9959 - val_loss: 0.8495 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.84330 to 0.85270, saving model to cifar10_model_4.h5\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 10s 247us/step - loss: 0.2306 - acc: 0.9986 - val_loss: 0.8622 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.85270\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.2246 - acc: 0.9987 - val_loss: 0.8799 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.85270\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.2184 - acc: 0.9991 - val_loss: 0.8818 - val_acc: 0.8493\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.85270\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.2131 - acc: 0.9994 - val_loss: 0.8912 - val_acc: 0.8468\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.85270\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.2076 - acc: 0.9997 - val_loss: 0.8892 - val_acc: 0.8477\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.85270\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.2037 - acc: 0.9998 - val_loss: 0.8922 - val_acc: 0.8485\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.85270\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.2026 - acc: 0.9998 - val_loss: 0.8944 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.85270\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.2011 - acc: 0.9997 - val_loss: 0.8913 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.85270\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.2001 - acc: 0.9998 - val_loss: 0.8925 - val_acc: 0.8498\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.85270\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.1988 - acc: 0.9997 - val_loss: 0.8923 - val_acc: 0.8499\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.85270\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 00031: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c67437278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLZk6oCNY9zz",
        "colab_type": "code",
        "outputId": "d78ea606-54ef-4f7e-b92b-adb56133a011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_4.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 396us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8791415970802308, 0.8415]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY0CwpbyoGQ6",
        "colab_type": "text"
      },
      "source": [
        "### regularizers.l2(0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od4RrrHQY9vk",
        "colab_type": "code",
        "outputId": "fea7c539-8178-46fe-f023-ca80689b58a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3761
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "from keras import regularizers\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_5.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "regularizer = regularizers.l2(0.0001)    # <<---------------------------------\n",
        "model = model_regularizers(regularizer)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128,\n",
        "          epochs=100, validation_split=0.2,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_191 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_192 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_193 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_194 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_195 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_196 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_197 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_198 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_199 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_200 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_201 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_202 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_13  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 815,050\n",
            "Trainable params: 814,602\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 16s 391us/step - loss: 1.6801 - acc: 0.4136 - val_loss: 3.2095 - val_acc: 0.3416\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.34160, saving model to cifar10_model_5.h5\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 10s 247us/step - loss: 1.1700 - acc: 0.6164 - val_loss: 2.3730 - val_acc: 0.4174\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.34160 to 0.41740, saving model to cifar10_model_5.h5\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.9584 - acc: 0.6991 - val_loss: 1.8106 - val_acc: 0.4994\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.41740 to 0.49940, saving model to cifar10_model_5.h5\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.8357 - acc: 0.7446 - val_loss: 1.7683 - val_acc: 0.5210\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.49940 to 0.52100, saving model to cifar10_model_5.h5\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.7378 - acc: 0.7821 - val_loss: 1.6134 - val_acc: 0.5955\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.52100 to 0.59550, saving model to cifar10_model_5.h5\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6613 - acc: 0.8079 - val_loss: 1.1796 - val_acc: 0.6711\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.59550 to 0.67110, saving model to cifar10_model_5.h5\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6083 - acc: 0.8276 - val_loss: 1.6310 - val_acc: 0.6251\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.67110\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.5526 - acc: 0.8489 - val_loss: 0.8181 - val_acc: 0.7702\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.67110 to 0.77020, saving model to cifar10_model_5.h5\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.5025 - acc: 0.8673 - val_loss: 1.4025 - val_acc: 0.6517\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.77020\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.4582 - acc: 0.8826 - val_loss: 0.9673 - val_acc: 0.7512\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.77020\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.4220 - acc: 0.8964 - val_loss: 0.9732 - val_acc: 0.7489\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.77020\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.3877 - acc: 0.9097 - val_loss: 1.0342 - val_acc: 0.7559\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.77020\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.3561 - acc: 0.9238 - val_loss: 1.8255 - val_acc: 0.6184\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.77020\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.2271 - acc: 0.9726 - val_loss: 0.6869 - val_acc: 0.8402\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.77020 to 0.84020, saving model to cifar10_model_5.h5\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1830 - acc: 0.9874 - val_loss: 0.7542 - val_acc: 0.8351\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.84020\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.1631 - acc: 0.9937 - val_loss: 0.7699 - val_acc: 0.8390\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.84020\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.1501 - acc: 0.9970 - val_loss: 0.8128 - val_acc: 0.8406\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.84020 to 0.84060, saving model to cifar10_model_5.h5\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1419 - acc: 0.9986 - val_loss: 0.8533 - val_acc: 0.8369\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.84060\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1355 - acc: 0.9993 - val_loss: 0.8812 - val_acc: 0.8382\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.84060\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.1313 - acc: 0.9994 - val_loss: 0.8928 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.84060\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.1270 - acc: 0.9998 - val_loss: 0.9210 - val_acc: 0.8384\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.84060\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1236 - acc: 0.9998 - val_loss: 0.9578 - val_acc: 0.8342\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.84060\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1210 - acc: 1.0000 - val_loss: 0.9339 - val_acc: 0.8400\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.84060\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1200 - acc: 1.0000 - val_loss: 0.9315 - val_acc: 0.8411\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.84060 to 0.84110, saving model to cifar10_model_5.h5\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.1193 - acc: 1.0000 - val_loss: 0.9339 - val_acc: 0.8415\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.84110 to 0.84150, saving model to cifar10_model_5.h5\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1187 - acc: 1.0000 - val_loss: 0.9346 - val_acc: 0.8398\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.84150\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1181 - acc: 1.0000 - val_loss: 0.9407 - val_acc: 0.8417\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.84150 to 0.84170, saving model to cifar10_model_5.h5\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1175 - acc: 1.0000 - val_loss: 0.9389 - val_acc: 0.8407\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.84170\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1169 - acc: 1.0000 - val_loss: 0.9446 - val_acc: 0.8395\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.84170\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1163 - acc: 1.0000 - val_loss: 0.9446 - val_acc: 0.8409\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.84170\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.1156 - acc: 1.0000 - val_loss: 0.9460 - val_acc: 0.8416\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.84170\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.1150 - acc: 1.0000 - val_loss: 0.9477 - val_acc: 0.8406\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.84170\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 10s 247us/step - loss: 0.1148 - acc: 1.0000 - val_loss: 0.9529 - val_acc: 0.8400\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.84170\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1146 - acc: 1.0000 - val_loss: 0.9524 - val_acc: 0.8401\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.84170\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1145 - acc: 1.0000 - val_loss: 0.9518 - val_acc: 0.8395\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.84170\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1144 - acc: 1.0000 - val_loss: 0.9519 - val_acc: 0.8393\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.84170\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.1142 - acc: 1.0000 - val_loss: 0.9528 - val_acc: 0.8399\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.84170\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 00037: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c65d9ff98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8mglJrqY9rE",
        "colab_type": "code",
        "outputId": "b8a67ff5-8ff4-40b6-f9aa-4b50c202bef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_5.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 414us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9760564441680908, 0.8346]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm-ifb9ZoJw8",
        "colab_type": "text"
      },
      "source": [
        "### regularizers.l1(0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPNOYc_BY9nh",
        "colab_type": "code",
        "outputId": "8955fe68-a12b-45b8-cf0a-3b334157d75e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4913
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "from keras import regularizers\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_6.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "regularizer = regularizers.l1(0.0001)    # <<---------------------------------\n",
        "model = model_regularizers(regularizer)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128,\n",
        "          epochs=100, validation_split=0.2,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_203 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_204 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_205 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_206 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_207 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_208 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_209 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_210 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_211 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_212 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_213 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_214 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_51 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_14  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 815,050\n",
            "Trainable params: 814,602\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 16s 402us/step - loss: 3.3615 - acc: 0.4047 - val_loss: 3.8566 - val_acc: 0.3004\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.30040, saving model to cifar10_model_6.h5\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 10s 249us/step - loss: 2.0301 - acc: 0.5916 - val_loss: 3.0674 - val_acc: 0.3008\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.30040 to 0.30080, saving model to cifar10_model_6.h5\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 10s 248us/step - loss: 1.5605 - acc: 0.6577 - val_loss: 2.7129 - val_acc: 0.3786\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.30080 to 0.37860, saving model to cifar10_model_6.h5\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 10s 249us/step - loss: 1.3444 - acc: 0.7008 - val_loss: 1.8384 - val_acc: 0.5342\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.37860 to 0.53420, saving model to cifar10_model_6.h5\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 10s 248us/step - loss: 1.2179 - acc: 0.7323 - val_loss: 2.5961 - val_acc: 0.4187\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.53420\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 10s 247us/step - loss: 1.1237 - acc: 0.7555 - val_loss: 1.5296 - val_acc: 0.6191\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.53420 to 0.61910, saving model to cifar10_model_6.h5\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 1.0645 - acc: 0.7737 - val_loss: 1.8580 - val_acc: 0.5688\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.61910\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.0107 - acc: 0.7885 - val_loss: 1.3106 - val_acc: 0.6956\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.61910 to 0.69560, saving model to cifar10_model_6.h5\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.9761 - acc: 0.7970 - val_loss: 1.5984 - val_acc: 0.6379\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.69560\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.9391 - acc: 0.8098 - val_loss: 1.4357 - val_acc: 0.6545\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.69560\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.9085 - acc: 0.8206 - val_loss: 1.2869 - val_acc: 0.7018\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.69560 to 0.70180, saving model to cifar10_model_6.h5\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.8872 - acc: 0.8253 - val_loss: 2.5512 - val_acc: 0.5462\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.70180\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 10s 248us/step - loss: 0.8653 - acc: 0.8346 - val_loss: 1.5413 - val_acc: 0.6403\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.70180\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.8477 - acc: 0.8395 - val_loss: 1.7140 - val_acc: 0.6281\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.70180\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.8278 - acc: 0.8476 - val_loss: 1.4119 - val_acc: 0.7046\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.70180 to 0.70460, saving model to cifar10_model_6.h5\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.8132 - acc: 0.8507 - val_loss: 1.2558 - val_acc: 0.7281\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.70460 to 0.72810, saving model to cifar10_model_6.h5\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7922 - acc: 0.8587 - val_loss: 1.3925 - val_acc: 0.7039\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.72810\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7820 - acc: 0.8650 - val_loss: 1.5102 - val_acc: 0.6547\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.72810\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7706 - acc: 0.8677 - val_loss: 1.3292 - val_acc: 0.7140\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.72810\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.7570 - acc: 0.8731 - val_loss: 1.5120 - val_acc: 0.6759\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.72810\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7479 - acc: 0.8782 - val_loss: 1.3154 - val_acc: 0.7285\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.72810 to 0.72850, saving model to cifar10_model_6.h5\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7364 - acc: 0.8810 - val_loss: 1.2671 - val_acc: 0.7468\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.72850 to 0.74680, saving model to cifar10_model_6.h5\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.7300 - acc: 0.8838 - val_loss: 2.0404 - val_acc: 0.6137\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.74680\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7215 - acc: 0.8883 - val_loss: 1.1787 - val_acc: 0.7625\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.74680 to 0.76250, saving model to cifar10_model_6.h5\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.7150 - acc: 0.8904 - val_loss: 1.7006 - val_acc: 0.6828\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.76250\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.7075 - acc: 0.8955 - val_loss: 1.2060 - val_acc: 0.7700\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.76250 to 0.77000, saving model to cifar10_model_6.h5\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.7012 - acc: 0.8992 - val_loss: 1.6124 - val_acc: 0.6923\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.77000\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6935 - acc: 0.9012 - val_loss: 1.3521 - val_acc: 0.7447\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.77000\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.6868 - acc: 0.9034 - val_loss: 1.4822 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.77000\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6805 - acc: 0.9092 - val_loss: 1.3482 - val_acc: 0.7400\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.77000\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.6796 - acc: 0.9068 - val_loss: 2.3458 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.77000\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.5371 - acc: 0.9584 - val_loss: 1.0189 - val_acc: 0.8210\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.77000 to 0.82100, saving model to cifar10_model_6.h5\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.4770 - acc: 0.9750 - val_loss: 1.0296 - val_acc: 0.8310\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.82100 to 0.83100, saving model to cifar10_model_6.h5\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.4472 - acc: 0.9830 - val_loss: 1.0943 - val_acc: 0.8261\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.83100\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.4264 - acc: 0.9874 - val_loss: 1.0796 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.83100\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.4113 - acc: 0.9890 - val_loss: 1.1128 - val_acc: 0.8284\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.83100\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.3965 - acc: 0.9922 - val_loss: 1.1432 - val_acc: 0.8259\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.83100\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.3855 - acc: 0.9935 - val_loss: 1.1548 - val_acc: 0.8192\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.83100\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.3683 - acc: 0.9975 - val_loss: 1.1418 - val_acc: 0.8317\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.83100 to 0.83170, saving model to cifar10_model_6.h5\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.3626 - acc: 0.9983 - val_loss: 1.1499 - val_acc: 0.8300\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.83170\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.3584 - acc: 0.9982 - val_loss: 1.1567 - val_acc: 0.8326\n",
            "\n",
            "Epoch 00041: val_acc improved from 0.83170 to 0.83260, saving model to cifar10_model_6.h5\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.3554 - acc: 0.9985 - val_loss: 1.1463 - val_acc: 0.8318\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.83260\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.3509 - acc: 0.9988 - val_loss: 1.1573 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00043: val_acc improved from 0.83260 to 0.83280, saving model to cifar10_model_6.h5\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.3486 - acc: 0.9986 - val_loss: 1.1746 - val_acc: 0.8311\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.83280\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 10s 246us/step - loss: 0.3451 - acc: 0.9990 - val_loss: 1.1695 - val_acc: 0.8314\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.83280\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.3419 - acc: 0.9992 - val_loss: 1.1885 - val_acc: 0.8306\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.83280\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.3396 - acc: 0.9988 - val_loss: 1.1872 - val_acc: 0.8275\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.83280\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.3371 - acc: 0.9989 - val_loss: 1.1772 - val_acc: 0.8306\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.83280\n",
            "\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.3341 - acc: 0.9992 - val_loss: 1.1804 - val_acc: 0.8305\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.83280\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.3333 - acc: 0.9994 - val_loss: 1.1825 - val_acc: 0.8312\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.83280\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.3329 - acc: 0.9992 - val_loss: 1.1828 - val_acc: 0.8304\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.83280\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 0.3316 - acc: 0.9995 - val_loss: 1.1814 - val_acc: 0.8303\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.83280\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 0.3312 - acc: 0.9995 - val_loss: 1.1839 - val_acc: 0.8309\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.83280\n",
            "\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 00053: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c647c3160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU1y2at6bpi7",
        "colab_type": "code",
        "outputId": "3c4d52f2-fc25-4c99-8ccf-21c456a3d9dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_6.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 431us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2036891553878784, 0.8184]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95rqNVNsoRLl",
        "colab_type": "text"
      },
      "source": [
        "### regularizers.l1(0.001)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntKF4XA0bpw6",
        "colab_type": "code",
        "outputId": "ba1c0db9-8733-4164-a2b3-439294131137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5957
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "from keras import regularizers\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_7.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "regularizer = regularizers.l1(0.001)    # <<---------------------------------\n",
        "model = model_regularizers(regularizer)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128,\n",
        "          epochs=100, validation_split=0.2,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_215 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_216 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_217 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_52 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_218 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_219 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_220 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_221 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_222 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_223 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_224 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_225 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_226 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_15  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 815,050\n",
            "Trainable params: 814,602\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 16s 411us/step - loss: 7.3472 - acc: 0.3145 - val_loss: 4.2779 - val_acc: 0.1172\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.11720, saving model to cifar10_model_7.h5\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 10s 248us/step - loss: 2.4277 - acc: 0.4393 - val_loss: 2.9364 - val_acc: 0.3171\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.11720 to 0.31710, saving model to cifar10_model_7.h5\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 10s 247us/step - loss: 2.1141 - acc: 0.5100 - val_loss: 2.4360 - val_acc: 0.4056\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.31710 to 0.40560, saving model to cifar10_model_7.h5\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 10s 248us/step - loss: 1.9790 - acc: 0.5435 - val_loss: 2.8493 - val_acc: 0.3521\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.40560\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.9014 - acc: 0.5647 - val_loss: 2.6923 - val_acc: 0.3334\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.40560\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8442 - acc: 0.5827 - val_loss: 2.4538 - val_acc: 0.4429\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.40560 to 0.44290, saving model to cifar10_model_7.h5\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.8098 - acc: 0.5939 - val_loss: 2.5379 - val_acc: 0.3948\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.44290\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.7833 - acc: 0.6022 - val_loss: 3.4615 - val_acc: 0.2901\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.44290\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.7600 - acc: 0.6123 - val_loss: 5.1590 - val_acc: 0.2022\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.44290\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.7407 - acc: 0.6139 - val_loss: 6.4507 - val_acc: 0.1847\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.44290\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.7218 - acc: 0.6210 - val_loss: 2.1041 - val_acc: 0.5129\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.44290 to 0.51290, saving model to cifar10_model_7.h5\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.7093 - acc: 0.6277 - val_loss: 1.9122 - val_acc: 0.5440\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.51290 to 0.54400, saving model to cifar10_model_7.h5\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.6922 - acc: 0.6362 - val_loss: 2.0411 - val_acc: 0.5203\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.54400\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.6845 - acc: 0.6395 - val_loss: 1.7753 - val_acc: 0.6122\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.54400 to 0.61220, saving model to cifar10_model_7.h5\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.6670 - acc: 0.6451 - val_loss: 2.2190 - val_acc: 0.4811\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.61220\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.6589 - acc: 0.6497 - val_loss: 2.2366 - val_acc: 0.5110\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.61220\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.6466 - acc: 0.6549 - val_loss: 2.1954 - val_acc: 0.5242\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.61220\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.6356 - acc: 0.6580 - val_loss: 1.9123 - val_acc: 0.5768\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.61220\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.6314 - acc: 0.6588 - val_loss: 3.2792 - val_acc: 0.4231\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.61220\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 10s 247us/step - loss: 1.2005 - acc: 0.6990 - val_loss: 1.3472 - val_acc: 0.6365\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.61220 to 0.63650, saving model to cifar10_model_7.h5\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.1786 - acc: 0.7017 - val_loss: 1.4173 - val_acc: 0.6189\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.63650\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.1685 - acc: 0.7067 - val_loss: 1.4632 - val_acc: 0.6022\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.63650\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 10s 242us/step - loss: 1.1598 - acc: 0.7068 - val_loss: 1.1877 - val_acc: 0.6950\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.63650 to 0.69500, saving model to cifar10_model_7.h5\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.1577 - acc: 0.7067 - val_loss: 1.3030 - val_acc: 0.6624\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.69500\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.1474 - acc: 0.7072 - val_loss: 1.3142 - val_acc: 0.6557\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.69500\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.1451 - acc: 0.7099 - val_loss: 1.2331 - val_acc: 0.6785\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.69500\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.1424 - acc: 0.7103 - val_loss: 1.2172 - val_acc: 0.6828\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.69500\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.1361 - acc: 0.7119 - val_loss: 1.4782 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.69500\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0489 - acc: 0.7215 - val_loss: 1.0706 - val_acc: 0.7127\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.69500 to 0.71270, saving model to cifar10_model_7.h5\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0423 - acc: 0.7218 - val_loss: 1.0629 - val_acc: 0.7172\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.71270 to 0.71720, saving model to cifar10_model_7.h5\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0407 - acc: 0.7222 - val_loss: 1.0935 - val_acc: 0.7042\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.71720\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.0385 - acc: 0.7218 - val_loss: 1.0666 - val_acc: 0.7179\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.71720 to 0.71790, saving model to cifar10_model_7.h5\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0351 - acc: 0.7236 - val_loss: 1.0971 - val_acc: 0.7060\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.71790\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0373 - acc: 0.7217 - val_loss: 1.0770 - val_acc: 0.7088\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.71790\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0337 - acc: 0.7235 - val_loss: 1.0611 - val_acc: 0.7147\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.71790\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.0340 - acc: 0.7268 - val_loss: 1.1311 - val_acc: 0.6910\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.71790\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.0328 - acc: 0.7232 - val_loss: 1.0642 - val_acc: 0.7150\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.71790\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 10s 242us/step - loss: 1.0136 - acc: 0.7253 - val_loss: 1.0411 - val_acc: 0.7191\n",
            "\n",
            "Epoch 00038: val_acc improved from 0.71790 to 0.71910, saving model to cifar10_model_7.h5\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0128 - acc: 0.7265 - val_loss: 1.0365 - val_acc: 0.7204\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.71910 to 0.72040, saving model to cifar10_model_7.h5\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0116 - acc: 0.7267 - val_loss: 1.0372 - val_acc: 0.7210\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.72040 to 0.72100, saving model to cifar10_model_7.h5\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0090 - acc: 0.7280 - val_loss: 1.0346 - val_acc: 0.7213\n",
            "\n",
            "Epoch 00041: val_acc improved from 0.72100 to 0.72130, saving model to cifar10_model_7.h5\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0105 - acc: 0.7267 - val_loss: 1.0393 - val_acc: 0.7196\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.72130\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0114 - acc: 0.7273 - val_loss: 1.0368 - val_acc: 0.7198\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.72130\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0107 - acc: 0.7258 - val_loss: 1.0350 - val_acc: 0.7208\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.72130\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.0125 - acc: 0.7245 - val_loss: 1.0374 - val_acc: 0.7194\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.72130\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0132 - acc: 0.7264 - val_loss: 1.0356 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.72130\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.0068 - acc: 0.7274 - val_loss: 1.0315 - val_acc: 0.7220\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.72130 to 0.72200, saving model to cifar10_model_7.h5\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0047 - acc: 0.7279 - val_loss: 1.0313 - val_acc: 0.7220\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.72200\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0070 - acc: 0.7283 - val_loss: 1.0311 - val_acc: 0.7223\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.72200 to 0.72230, saving model to cifar10_model_7.h5\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0085 - acc: 0.7251 - val_loss: 1.0311 - val_acc: 0.7221\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.72230\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0052 - acc: 0.7264 - val_loss: 1.0309 - val_acc: 0.7218\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.72230\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.0050 - acc: 0.7285 - val_loss: 1.0312 - val_acc: 0.7216\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.72230\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 10s 245us/step - loss: 1.0028 - acc: 0.7285 - val_loss: 1.0310 - val_acc: 0.7211\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.72230\n",
            "Epoch 54/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0060 - acc: 0.7275 - val_loss: 1.0307 - val_acc: 0.7221\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.72230\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0003199999686330557.\n",
            "Epoch 55/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0037 - acc: 0.7285 - val_loss: 1.0304 - val_acc: 0.7222\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.72230\n",
            "Epoch 56/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0039 - acc: 0.7265 - val_loss: 1.0303 - val_acc: 0.7226\n",
            "\n",
            "Epoch 00056: val_acc improved from 0.72230 to 0.72260, saving model to cifar10_model_7.h5\n",
            "Epoch 57/100\n",
            "40000/40000 [==============================] - 10s 242us/step - loss: 1.0046 - acc: 0.7303 - val_loss: 1.0303 - val_acc: 0.7220\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.72260\n",
            "Epoch 58/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0047 - acc: 0.7281 - val_loss: 1.0302 - val_acc: 0.7217\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.72260\n",
            "Epoch 59/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0060 - acc: 0.7268 - val_loss: 1.0301 - val_acc: 0.7217\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.72260\n",
            "Epoch 60/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0057 - acc: 0.7266 - val_loss: 1.0302 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.72260\n",
            "Epoch 61/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.0044 - acc: 0.7278 - val_loss: 1.0302 - val_acc: 0.7217\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.72260\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 6.399999256245792e-05.\n",
            "Epoch 62/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0038 - acc: 0.7279 - val_loss: 1.0300 - val_acc: 0.7216\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.72260\n",
            "Epoch 63/100\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 1.0045 - acc: 0.7269 - val_loss: 1.0301 - val_acc: 0.7220\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.72260\n",
            "Epoch 64/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0042 - acc: 0.7271 - val_loss: 1.0301 - val_acc: 0.7221\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.72260\n",
            "Epoch 65/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0056 - acc: 0.7272 - val_loss: 1.0301 - val_acc: 0.7222\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.72260\n",
            "Epoch 66/100\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.0047 - acc: 0.7274 - val_loss: 1.0300 - val_acc: 0.7213\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.72260\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.2799998512491585e-05.\n",
            "Epoch 00066: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c631efcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbPmvG72bpcv",
        "colab_type": "code",
        "outputId": "c0b453c3-505b-4b79-a0ae-30aeb75964c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_7.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 451us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0561156918525696, 0.708]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6pNrUZNoZ-H",
        "colab_type": "text"
      },
      "source": [
        "### regularizers.l1_l2(l1=0.0001, l2=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgLOgKOxb5Eg",
        "colab_type": "code",
        "outputId": "bcc62a0b-dad9-4d96-992e-b77c01bb3208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4409
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "from keras import regularizers\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_8.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "regularizer = regularizers.l1_l2(l1=0.0001, l2=0.001)    # <<---------------------------------\n",
        "model = model_regularizers(regularizer)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128,\n",
        "          epochs=100, validation_split=0.2,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_239 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_240 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_241 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_58 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_49 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_242 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_243 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_244 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_245 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_59 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_50 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_246 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_247 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_248 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_249 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_250 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_60 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_17  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 815,050\n",
            "Trainable params: 814,602\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 21s 532us/step - loss: 3.6695 - acc: 0.3943 - val_loss: 3.6893 - val_acc: 0.2950\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.29500, saving model to cifar10_model_8.h5\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 10s 259us/step - loss: 1.9933 - acc: 0.5600 - val_loss: 3.1173 - val_acc: 0.2830\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.29500\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 10s 258us/step - loss: 1.5435 - acc: 0.6386 - val_loss: 1.9212 - val_acc: 0.5107\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.29500 to 0.51070, saving model to cifar10_model_8.h5\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 10s 260us/step - loss: 1.3438 - acc: 0.6818 - val_loss: 2.2852 - val_acc: 0.4456\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.51070\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 10s 260us/step - loss: 1.2228 - acc: 0.7134 - val_loss: 1.8870 - val_acc: 0.5075\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.51070\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 10s 258us/step - loss: 1.1326 - acc: 0.7375 - val_loss: 2.0138 - val_acc: 0.4802\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.51070\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 1.0830 - acc: 0.7518 - val_loss: 1.6571 - val_acc: 0.5661\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.51070 to 0.56610, saving model to cifar10_model_8.h5\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 10s 257us/step - loss: 1.0436 - acc: 0.7668 - val_loss: 2.4499 - val_acc: 0.4631\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.56610\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 1.0020 - acc: 0.7773 - val_loss: 1.6156 - val_acc: 0.5951\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.56610 to 0.59510, saving model to cifar10_model_8.h5\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.9735 - acc: 0.7858 - val_loss: 1.5569 - val_acc: 0.6303\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.59510 to 0.63030, saving model to cifar10_model_8.h5\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 10s 257us/step - loss: 0.9546 - acc: 0.7904 - val_loss: 1.5559 - val_acc: 0.6247\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.63030\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.9342 - acc: 0.7966 - val_loss: 1.2049 - val_acc: 0.7123\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.63030 to 0.71230, saving model to cifar10_model_8.h5\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.9120 - acc: 0.8085 - val_loss: 1.3381 - val_acc: 0.6804\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.71230\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 10s 257us/step - loss: 0.8922 - acc: 0.8133 - val_loss: 1.4090 - val_acc: 0.6555\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.71230\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 10s 257us/step - loss: 0.8802 - acc: 0.8205 - val_loss: 1.6637 - val_acc: 0.6129\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.71230\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 10s 258us/step - loss: 0.8695 - acc: 0.8233 - val_loss: 1.4350 - val_acc: 0.6792\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.71230\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 10s 257us/step - loss: 0.8591 - acc: 0.8260 - val_loss: 1.2995 - val_acc: 0.7221\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.71230 to 0.72210, saving model to cifar10_model_8.h5\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 10s 259us/step - loss: 0.8495 - acc: 0.8306 - val_loss: 1.2619 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.72210\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.8376 - acc: 0.8351 - val_loss: 1.1326 - val_acc: 0.7466\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.72210 to 0.74660, saving model to cifar10_model_8.h5\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.8325 - acc: 0.8385 - val_loss: 1.4084 - val_acc: 0.6728\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.74660\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.8246 - acc: 0.8401 - val_loss: 1.5334 - val_acc: 0.6604\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.74660\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.8138 - acc: 0.8441 - val_loss: 2.0248 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.74660\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.8090 - acc: 0.8451 - val_loss: 1.2519 - val_acc: 0.7322\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.74660\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 10s 257us/step - loss: 0.7989 - acc: 0.8500 - val_loss: 1.4727 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.74660\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.6246 - acc: 0.9085 - val_loss: 0.8765 - val_acc: 0.8302\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.74660 to 0.83020, saving model to cifar10_model_8.h5\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.5673 - acc: 0.9252 - val_loss: 0.9460 - val_acc: 0.8135\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.83020\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.5313 - acc: 0.9350 - val_loss: 0.9466 - val_acc: 0.8159\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.83020\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.5064 - acc: 0.9418 - val_loss: 0.9301 - val_acc: 0.8264\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.83020\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.4846 - acc: 0.9487 - val_loss: 0.9761 - val_acc: 0.8164\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.83020\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.4634 - acc: 0.9533 - val_loss: 1.1110 - val_acc: 0.7937\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.83020\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.4205 - acc: 0.9699 - val_loss: 0.9261 - val_acc: 0.8318\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.83020 to 0.83180, saving model to cifar10_model_8.h5\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.4091 - acc: 0.9746 - val_loss: 0.9365 - val_acc: 0.8350\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.83180 to 0.83500, saving model to cifar10_model_8.h5\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 10s 254us/step - loss: 0.3996 - acc: 0.9781 - val_loss: 0.9465 - val_acc: 0.8338\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.83500\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.3957 - acc: 0.9783 - val_loss: 0.9689 - val_acc: 0.8310\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.83500\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.3882 - acc: 0.9802 - val_loss: 0.9572 - val_acc: 0.8326\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.83500\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.3843 - acc: 0.9816 - val_loss: 0.9636 - val_acc: 0.8358\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.83500 to 0.83580, saving model to cifar10_model_8.h5\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.3796 - acc: 0.9826 - val_loss: 0.9866 - val_acc: 0.8321\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.83580\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 10s 255us/step - loss: 0.3753 - acc: 0.9835 - val_loss: 0.9864 - val_acc: 0.8313\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.83580\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.3710 - acc: 0.9842 - val_loss: 1.0157 - val_acc: 0.8264\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.83580\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 10s 257us/step - loss: 0.3664 - acc: 0.9857 - val_loss: 0.9988 - val_acc: 0.8311\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.83580\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.3615 - acc: 0.9868 - val_loss: 1.0218 - val_acc: 0.8291\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.83580\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.3544 - acc: 0.9900 - val_loss: 1.0082 - val_acc: 0.8315\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.83580\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.3527 - acc: 0.9904 - val_loss: 1.0097 - val_acc: 0.8327\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.83580\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.3528 - acc: 0.9897 - val_loss: 1.0103 - val_acc: 0.8295\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.83580\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.3505 - acc: 0.9908 - val_loss: 1.0115 - val_acc: 0.8319\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.83580\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 10s 256us/step - loss: 0.3508 - acc: 0.9905 - val_loss: 1.0143 - val_acc: 0.8312\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.83580\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 00046: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c6a3a8e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRj4li6ab4-g",
        "colab_type": "code",
        "outputId": "afacb2ac-c6c0-4f91-e0da-c58a0e47b7c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_8.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 523us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9611338333129883, 0.8319]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRsRGFMsb47d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEMtPbahqnFi",
        "colab_type": "text"
      },
      "source": [
        "## 数据增强"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XubjReIa4zvN",
        "colab_type": "text"
      },
      "source": [
        "### 基础卷积网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2w3zk9Sb43R",
        "colab_type": "code",
        "outputId": "7e01b2b2-07e8-4829-a56f-a0001f31c270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        }
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "'在卷积神经网络上添加分类器'\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_263 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_264 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_265 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_64 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_266 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_267 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_268 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_269 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_65 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_270 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_271 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_272 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_273 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_274 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_66 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_19  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 815,050\n",
            "Trainable params: 814,602\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqABuYB5b4zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # 在数据集上将输入平均值设置为0\n",
        "        samplewise_center=False,  # 将每个样本均值设置为0\n",
        "        featurewise_std_normalization=False,  # 将输入除以数据集的std\n",
        "        samplewise_std_normalization=False,  # 将每个输入除以其std\n",
        "        zca_whitening=False,  # 应用ZCA白化\n",
        "        rotation_range=20,  # 在一个范围下随机旋转图像(degrees, 0 to 180)\n",
        "        width_shift_range=0.2,  # 水平随机移位图像（总宽度的分数）\n",
        "        height_shift_range=0.2,  # 随机地垂直移动图像（总高度的分数）\n",
        "        horizontal_flip=True,  # 随机翻转图像\n",
        "        vertical_flip=False)  # 随机翻转图像\n",
        "\n",
        "    # 计算特征方向归一化所需的数量\n",
        "    # (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXJ0870ub4uu",
        "colab_type": "code",
        "outputId": "75a87dda-c8d2-49d7-fd86-b714ddfbce7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4537
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_9.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "optimizer = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=1e-6)\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                        batch_size=128),\n",
        "                        samples_per_epoch=x_train.shape[0],\n",
        "                        nb_epoch=100,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                   callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=390, epochs=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 1.7300 - acc: 0.3589 - val_loss: 1.9453 - val_acc: 0.4361\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.43610, saving model to cifar10_model_9.h5\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 1.3056 - acc: 0.5318 - val_loss: 1.8989 - val_acc: 0.4360\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.43610\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 1.0984 - acc: 0.6122 - val_loss: 1.4781 - val_acc: 0.5698\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.43610 to 0.56980, saving model to cifar10_model_9.h5\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.9792 - acc: 0.6581 - val_loss: 1.3827 - val_acc: 0.5910\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.56980 to 0.59100, saving model to cifar10_model_9.h5\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.8898 - acc: 0.6911 - val_loss: 0.9406 - val_acc: 0.6886\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.59100 to 0.68860, saving model to cifar10_model_9.h5\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.8218 - acc: 0.7146 - val_loss: 0.8050 - val_acc: 0.7210\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.68860 to 0.72100, saving model to cifar10_model_9.h5\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.7644 - acc: 0.7346 - val_loss: 0.7917 - val_acc: 0.7307\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.72100 to 0.73070, saving model to cifar10_model_9.h5\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.7192 - acc: 0.7527 - val_loss: 1.1762 - val_acc: 0.6549\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.73070\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.6833 - acc: 0.7635 - val_loss: 0.9336 - val_acc: 0.6942\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.73070\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.6496 - acc: 0.7771 - val_loss: 1.0227 - val_acc: 0.7040\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.73070\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.6178 - acc: 0.7870 - val_loss: 0.6435 - val_acc: 0.7924\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.73070 to 0.79240, saving model to cifar10_model_9.h5\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.5901 - acc: 0.7970 - val_loss: 0.9980 - val_acc: 0.7105\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.79240\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.5616 - acc: 0.8076 - val_loss: 1.1302 - val_acc: 0.7082\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.79240\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.5432 - acc: 0.8148 - val_loss: 0.5058 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.79240 to 0.82930, saving model to cifar10_model_9.h5\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.5257 - acc: 0.8196 - val_loss: 0.8327 - val_acc: 0.7506\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.82930\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.5069 - acc: 0.8270 - val_loss: 0.6733 - val_acc: 0.7927\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.82930\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.4945 - acc: 0.8290 - val_loss: 0.8059 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.82930\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.4840 - acc: 0.8346 - val_loss: 0.5271 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.82930\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.4671 - acc: 0.8428 - val_loss: 0.7095 - val_acc: 0.7849\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.82930\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.3817 - acc: 0.8684 - val_loss: 0.4292 - val_acc: 0.8607\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.82930 to 0.86070, saving model to cifar10_model_9.h5\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.3606 - acc: 0.8751 - val_loss: 0.4589 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.86070\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.3522 - acc: 0.8802 - val_loss: 0.4610 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.86070\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.3422 - acc: 0.8821 - val_loss: 0.4989 - val_acc: 0.8456\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.86070\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.3422 - acc: 0.8829 - val_loss: 0.4196 - val_acc: 0.8657\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.86070 to 0.86570, saving model to cifar10_model_9.h5\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.3372 - acc: 0.8848 - val_loss: 0.4447 - val_acc: 0.8586\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.86570\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.3301 - acc: 0.8858 - val_loss: 0.4340 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.86570\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.3246 - acc: 0.8887 - val_loss: 0.4266 - val_acc: 0.8628\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.86570\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.3183 - acc: 0.8899 - val_loss: 0.4371 - val_acc: 0.8619\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.86570\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.3206 - acc: 0.8894 - val_loss: 0.4039 - val_acc: 0.8703\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.86570 to 0.87030, saving model to cifar10_model_9.h5\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.3156 - acc: 0.8913 - val_loss: 0.3967 - val_acc: 0.8745\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.87030 to 0.87450, saving model to cifar10_model_9.h5\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.3104 - acc: 0.8949 - val_loss: 0.3906 - val_acc: 0.8740\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.87450\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3119 - acc: 0.8930 - val_loss: 0.4567 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.87450\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.3012 - acc: 0.8982 - val_loss: 0.4319 - val_acc: 0.8632\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.87450\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.3023 - acc: 0.8960 - val_loss: 0.4990 - val_acc: 0.8518\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.87450\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.2995 - acc: 0.8973 - val_loss: 0.4442 - val_acc: 0.8639\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.87450\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.2837 - acc: 0.9033 - val_loss: 0.4119 - val_acc: 0.8712\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.87450\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.2771 - acc: 0.9039 - val_loss: 0.4003 - val_acc: 0.8758\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.87450 to 0.87580, saving model to cifar10_model_9.h5\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.2766 - acc: 0.9055 - val_loss: 0.3977 - val_acc: 0.8753\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.87580\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.2770 - acc: 0.9048 - val_loss: 0.3941 - val_acc: 0.8762\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.87580 to 0.87620, saving model to cifar10_model_9.h5\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.2745 - acc: 0.9051 - val_loss: 0.4135 - val_acc: 0.8706\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.87620\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.2701 - acc: 0.9062 - val_loss: 0.4061 - val_acc: 0.8738\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.87620\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.2715 - acc: 0.9079 - val_loss: 0.3926 - val_acc: 0.8748\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.87620\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.2679 - acc: 0.9065 - val_loss: 0.4022 - val_acc: 0.8756\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.87620\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2709 - acc: 0.9072 - val_loss: 0.4087 - val_acc: 0.8730\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.87620\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.2642 - acc: 0.9087 - val_loss: 0.4018 - val_acc: 0.8751\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.87620\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 24s 62ms/step - loss: 0.2627 - acc: 0.9099 - val_loss: 0.4031 - val_acc: 0.8749\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.87620\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2571 - acc: 0.9115 - val_loss: 0.4038 - val_acc: 0.8756\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.87620\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2648 - acc: 0.9084 - val_loss: 0.3992 - val_acc: 0.8757\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.87620\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2620 - acc: 0.9083 - val_loss: 0.3995 - val_acc: 0.8772\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.87620 to 0.87720, saving model to cifar10_model_9.h5\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2665 - acc: 0.9081 - val_loss: 0.3998 - val_acc: 0.8761\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.87720\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2608 - acc: 0.9106 - val_loss: 0.4044 - val_acc: 0.8746\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.87720\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2644 - acc: 0.9085 - val_loss: 0.3999 - val_acc: 0.8761\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.87720\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2574 - acc: 0.9113 - val_loss: 0.4023 - val_acc: 0.8751\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.87720\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2638 - acc: 0.9097 - val_loss: 0.4045 - val_acc: 0.8758\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.87720\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2663 - acc: 0.9079 - val_loss: 0.4028 - val_acc: 0.8760\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.87720\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2609 - acc: 0.9099 - val_loss: 0.4040 - val_acc: 0.8760\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.87720\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2568 - acc: 0.9119 - val_loss: 0.4014 - val_acc: 0.8761\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.87720\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2588 - acc: 0.9114 - val_loss: 0.4006 - val_acc: 0.8769\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.87720\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2577 - acc: 0.9112 - val_loss: 0.4009 - val_acc: 0.8765\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.87720\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0003199999686330557.\n",
            "Epoch 00059: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c60a335c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCWLZv3bQk_T",
        "colab_type": "code",
        "outputId": "1fb87d6c-74b0-4d9d-bdc7-44506c4b43d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_9.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 6s 579us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3994561789035797, 0.8772]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecRJQ6nI48e-",
        "colab_type": "text"
      },
      "source": [
        "### MNIST数据集的一个高精度网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIQL4snrQk8p",
        "colab_type": "code",
        "outputId": "0e73afd1-7aa0-4e52-f8e4-5714fb8e90b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1259
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Dropout, Dense, GlobalAveragePooling2D, BatchNormalization, concatenate\n",
        "\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "temp = inputs\n",
        "x = Conv2D(16, (3, 3), padding='same', activation='relu')(inputs)\n",
        "x = Conv2D(16, (3, 3), padding='same', activation='relu')(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "temp = x\n",
        "x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "temp = x\n",
        "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "temp = x\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = Dropout(0.5)(x)\n",
        "x = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=x)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 32, 32, 16)   2320        conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 19)   0           conv2d_276[0][0]                 \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 32, 32, 19)   76          concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling2D) (None, 16, 16, 19)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 16, 16, 32)   5504        max_pooling2d_58[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 16, 16, 32)   9248        conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 16, 16, 51)   0           conv2d_279[0][0]                 \n",
            "                                                                 max_pooling2d_58[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 16, 16, 51)   204         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_59 (MaxPooling2D) (None, 8, 8, 51)     0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 8, 8, 64)     29440       max_pooling2d_59[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 8, 8, 64)     36928       conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 8, 8, 64)     36928       conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 8, 8, 64)     36928       conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 8, 115)    0           conv2d_283[0][0]                 \n",
            "                                                                 max_pooling2d_59[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 115)    460         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_60 (MaxPooling2D) (None, 4, 4, 115)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 4, 4, 128)    132608      max_pooling2d_60[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 4, 4, 128)    147584      conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 4, 4, 128)    147584      conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 4, 4, 128)    147584      conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 4, 4, 128)    147584      conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 4, 4, 243)    0           conv2d_288[0][0]                 \n",
            "                                                                 max_pooling2d_60[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 4, 4, 243)    972         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_20 (Gl (None, 243)          0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 243)          0           global_average_pooling2d_20[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 10)           2440        dropout_17[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 894,088\n",
            "Trainable params: 893,232\n",
            "Non-trainable params: 856\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C83BUv16Qk1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # 在数据集上将输入平均值设置为0\n",
        "        samplewise_center=False,  # 将每个样本均值设置为0\n",
        "        featurewise_std_normalization=False,  # 将输入除以数据集的std\n",
        "        samplewise_std_normalization=False,  # 将每个输入除以其std\n",
        "        zca_whitening=False,  # 应用ZCA白化\n",
        "        rotation_range=20,  # 在一个范围下随机旋转图像(degrees, 0 to 180)\n",
        "        width_shift_range=0.2,  # 水平随机移位图像（总宽度的分数）\n",
        "        height_shift_range=0.2,  # 随机地垂直移动图像（总高度的分数）\n",
        "        horizontal_flip=True,  # 随机翻转图像\n",
        "        vertical_flip=False)  # 随机翻转图像\n",
        "\n",
        "    # 计算特征方向归一化所需的数量\n",
        "    # (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlXEycrCNzwz",
        "colab_type": "code",
        "outputId": "534db91b-c190-46e0-932d-bc5c9e5a156b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5869
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_10.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "optimizer = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=1e-6)\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                        batch_size=128),\n",
        "                        samples_per_epoch=x_train.shape[0],\n",
        "                        nb_epoch=100,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                   callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=390, epochs=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 37s 96ms/step - loss: 1.5966 - acc: 0.4171 - val_loss: 2.3150 - val_acc: 0.3981\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.39810, saving model to cifar10_model_10.h5\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 23s 59ms/step - loss: 1.2478 - acc: 0.5533 - val_loss: 1.7072 - val_acc: 0.5058\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.39810 to 0.50580, saving model to cifar10_model_10.h5\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 1.0849 - acc: 0.6170 - val_loss: 1.1029 - val_acc: 0.6455\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.50580 to 0.64550, saving model to cifar10_model_10.h5\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.9825 - acc: 0.6575 - val_loss: 1.1645 - val_acc: 0.6182\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.64550\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 23s 59ms/step - loss: 0.8999 - acc: 0.6881 - val_loss: 0.9363 - val_acc: 0.6795\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.64550 to 0.67950, saving model to cifar10_model_10.h5\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 24s 60ms/step - loss: 0.8472 - acc: 0.7089 - val_loss: 0.9243 - val_acc: 0.6975\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.67950 to 0.69750, saving model to cifar10_model_10.h5\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 24s 60ms/step - loss: 0.7949 - acc: 0.7247 - val_loss: 0.8430 - val_acc: 0.7172\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.69750 to 0.71720, saving model to cifar10_model_10.h5\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.7549 - acc: 0.7423 - val_loss: 0.9485 - val_acc: 0.6950\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.71720\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.7159 - acc: 0.7554 - val_loss: 1.0398 - val_acc: 0.7016\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.71720\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.6883 - acc: 0.7643 - val_loss: 0.8356 - val_acc: 0.7263\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.71720 to 0.72630, saving model to cifar10_model_10.h5\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.6596 - acc: 0.7740 - val_loss: 0.6742 - val_acc: 0.7766\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.72630 to 0.77660, saving model to cifar10_model_10.h5\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 23s 59ms/step - loss: 0.6340 - acc: 0.7819 - val_loss: 0.6727 - val_acc: 0.7780\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.77660 to 0.77800, saving model to cifar10_model_10.h5\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.6168 - acc: 0.7912 - val_loss: 0.7865 - val_acc: 0.7422\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.77800\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.5963 - acc: 0.7962 - val_loss: 0.6421 - val_acc: 0.7887\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.77800 to 0.78870, saving model to cifar10_model_10.h5\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 23s 59ms/step - loss: 0.5787 - acc: 0.8032 - val_loss: 0.7257 - val_acc: 0.7729\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.78870\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 23s 59ms/step - loss: 0.5634 - acc: 0.8094 - val_loss: 0.6028 - val_acc: 0.8025\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.78870 to 0.80250, saving model to cifar10_model_10.h5\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.5539 - acc: 0.8126 - val_loss: 0.6367 - val_acc: 0.7861\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80250\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.5427 - acc: 0.8169 - val_loss: 0.6341 - val_acc: 0.7900\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80250\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.5326 - acc: 0.8183 - val_loss: 0.6709 - val_acc: 0.7812\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80250\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.5158 - acc: 0.8241 - val_loss: 0.6166 - val_acc: 0.8037\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.80250 to 0.80370, saving model to cifar10_model_10.h5\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 24s 60ms/step - loss: 0.5031 - acc: 0.8290 - val_loss: 0.7387 - val_acc: 0.7828\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80370\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4949 - acc: 0.8329 - val_loss: 0.5639 - val_acc: 0.8172\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.80370 to 0.81720, saving model to cifar10_model_10.h5\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4768 - acc: 0.8384 - val_loss: 0.6193 - val_acc: 0.8097\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.81720\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4736 - acc: 0.8386 - val_loss: 0.5806 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.81720 to 0.81770, saving model to cifar10_model_10.h5\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4662 - acc: 0.8413 - val_loss: 0.6719 - val_acc: 0.7904\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.81770\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4614 - acc: 0.8430 - val_loss: 0.5577 - val_acc: 0.8204\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.81770 to 0.82040, saving model to cifar10_model_10.h5\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4475 - acc: 0.8472 - val_loss: 0.6426 - val_acc: 0.8050\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.82040\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4403 - acc: 0.8506 - val_loss: 0.6058 - val_acc: 0.8125\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.82040\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4328 - acc: 0.8536 - val_loss: 0.5422 - val_acc: 0.8292\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.82040 to 0.82920, saving model to cifar10_model_10.h5\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4278 - acc: 0.8543 - val_loss: 0.5120 - val_acc: 0.8338\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.82920 to 0.83380, saving model to cifar10_model_10.h5\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4252 - acc: 0.8543 - val_loss: 0.5453 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.83380\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 23s 59ms/step - loss: 0.4130 - acc: 0.8594 - val_loss: 0.5856 - val_acc: 0.8196\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.83380\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.4109 - acc: 0.8602 - val_loss: 0.4483 - val_acc: 0.8566\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.83380 to 0.85660, saving model to cifar10_model_10.h5\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4024 - acc: 0.8626 - val_loss: 0.4986 - val_acc: 0.8405\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.85660\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.4017 - acc: 0.8609 - val_loss: 0.5994 - val_acc: 0.8231\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.85660\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.3929 - acc: 0.8658 - val_loss: 0.5577 - val_acc: 0.8208\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.85660\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.3843 - acc: 0.8692 - val_loss: 0.4856 - val_acc: 0.8406\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.85660\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.3799 - acc: 0.8714 - val_loss: 0.4986 - val_acc: 0.8471\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.85660\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.3292 - acc: 0.8871 - val_loss: 0.4108 - val_acc: 0.8680\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.85660 to 0.86800, saving model to cifar10_model_10.h5\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.3066 - acc: 0.8969 - val_loss: 0.4404 - val_acc: 0.8637\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.86800\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 24s 60ms/step - loss: 0.3054 - acc: 0.8956 - val_loss: 0.4420 - val_acc: 0.8621\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.86800\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2983 - acc: 0.8987 - val_loss: 0.4144 - val_acc: 0.8695\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.86800 to 0.86950, saving model to cifar10_model_10.h5\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2980 - acc: 0.8982 - val_loss: 0.4329 - val_acc: 0.8666\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.86950\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2939 - acc: 0.9002 - val_loss: 0.4291 - val_acc: 0.8657\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.86950\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2869 - acc: 0.9021 - val_loss: 0.4315 - val_acc: 0.8652\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.86950\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2906 - acc: 0.8995 - val_loss: 0.4116 - val_acc: 0.8717\n",
            "\n",
            "Epoch 00046: val_acc improved from 0.86950 to 0.87170, saving model to cifar10_model_10.h5\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2833 - acc: 0.9018 - val_loss: 0.4281 - val_acc: 0.8672\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.87170\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2837 - acc: 0.9046 - val_loss: 0.4467 - val_acc: 0.8636\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.87170\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2800 - acc: 0.9050 - val_loss: 0.4403 - val_acc: 0.8647\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.87170\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 23s 59ms/step - loss: 0.2753 - acc: 0.9056 - val_loss: 0.4083 - val_acc: 0.8739\n",
            "\n",
            "Epoch 00050: val_acc improved from 0.87170 to 0.87390, saving model to cifar10_model_10.h5\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2752 - acc: 0.9050 - val_loss: 0.4360 - val_acc: 0.8649\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.87390\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2715 - acc: 0.9055 - val_loss: 0.4486 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.87390\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2656 - acc: 0.9094 - val_loss: 0.4473 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.87390\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2700 - acc: 0.9065 - val_loss: 0.4256 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.87390\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 24s 60ms/step - loss: 0.2658 - acc: 0.9096 - val_loss: 0.4354 - val_acc: 0.8679\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.87390\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2599 - acc: 0.9095 - val_loss: 0.4250 - val_acc: 0.8703\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.87390\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2524 - acc: 0.9149 - val_loss: 0.4263 - val_acc: 0.8717\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.87390\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2566 - acc: 0.9131 - val_loss: 0.4155 - val_acc: 0.8728\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.87390\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2546 - acc: 0.9123 - val_loss: 0.4172 - val_acc: 0.8744\n",
            "\n",
            "Epoch 00059: val_acc improved from 0.87390 to 0.87440, saving model to cifar10_model_10.h5\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 24s 60ms/step - loss: 0.2523 - acc: 0.9125 - val_loss: 0.4177 - val_acc: 0.8729\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.87440\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2475 - acc: 0.9163 - val_loss: 0.4166 - val_acc: 0.8748\n",
            "\n",
            "Epoch 00061: val_acc improved from 0.87440 to 0.87480, saving model to cifar10_model_10.h5\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2514 - acc: 0.9146 - val_loss: 0.4212 - val_acc: 0.8737\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.87480\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2515 - acc: 0.9142 - val_loss: 0.4227 - val_acc: 0.8732\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.87480\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2521 - acc: 0.9134 - val_loss: 0.4240 - val_acc: 0.8718\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.87480\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2438 - acc: 0.9174 - val_loss: 0.4154 - val_acc: 0.8758\n",
            "\n",
            "Epoch 00065: val_acc improved from 0.87480 to 0.87580, saving model to cifar10_model_10.h5\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2490 - acc: 0.9159 - val_loss: 0.4180 - val_acc: 0.8756\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.87580\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2464 - acc: 0.9162 - val_loss: 0.4221 - val_acc: 0.8731\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.87580\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2412 - acc: 0.9164 - val_loss: 0.4163 - val_acc: 0.8766\n",
            "\n",
            "Epoch 00068: val_acc improved from 0.87580 to 0.87660, saving model to cifar10_model_10.h5\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2441 - acc: 0.9174 - val_loss: 0.4223 - val_acc: 0.8743\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.87660\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2476 - acc: 0.9162 - val_loss: 0.4185 - val_acc: 0.8735\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.87660\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2423 - acc: 0.9168 - val_loss: 0.4199 - val_acc: 0.8748\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.87660\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 24s 61ms/step - loss: 0.2428 - acc: 0.9167 - val_loss: 0.4176 - val_acc: 0.8739\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.87660\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2430 - acc: 0.9163 - val_loss: 0.4168 - val_acc: 0.8751\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.87660\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2428 - acc: 0.9167 - val_loss: 0.4173 - val_acc: 0.8745\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.87660\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2356 - acc: 0.9184 - val_loss: 0.4195 - val_acc: 0.8743\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.87660\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2403 - acc: 0.9180 - val_loss: 0.4197 - val_acc: 0.8738\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.87660\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2398 - acc: 0.9164 - val_loss: 0.4175 - val_acc: 0.8753\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.87660\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 23s 60ms/step - loss: 0.2414 - acc: 0.9175 - val_loss: 0.4193 - val_acc: 0.8740\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.87660\n",
            "\n",
            "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 00078: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c4cc9d4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZdvV9MFPDnI",
        "colab_type": "code",
        "outputId": "a79a4e84-fd5f-4410-c210-31a34691cc76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_10.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 6s 604us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.41626314039230344, 0.8766]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5yLPFt45MOz",
        "colab_type": "text"
      },
      "source": [
        "### MNIST数据集的最后一个卷积网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNxCS4vIPD0z",
        "colab_type": "code",
        "outputId": "d608765b-f643-46c7-9dac-1b7dfd99de84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1961
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Dropout, Dense, GlobalAveragePooling2D, BatchNormalization, concatenate\n",
        "\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "x = Conv2D(32, (1, 1), activation='relu')(x)\n",
        "\n",
        "x1 = Conv2D(32, (1, 3), activation='relu')(inputs)\n",
        "x1 = Conv2D(32, (3, 1), activation='relu')(x1)\n",
        "\n",
        "x2 = Conv2D(32, (1, 1), activation='relu')(inputs)\n",
        "x2 = Conv2D(32, (3, 3), activation='relu')(x2)\n",
        "\n",
        "x = concatenate([x, x1, x2])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "\n",
        "temp = x\n",
        "x = Conv2D(64, (3, 3), activation='relu')(temp)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = Conv2D(64, (1, 1), activation='relu')(x)\n",
        "\n",
        "x1 = Conv2D(64, (1, 3), activation='relu')(temp)\n",
        "x1 = Conv2D(64, (3, 1), activation='relu')(x1)\n",
        "x1 = Conv2D(64, (3, 3), activation='relu')(x1)\n",
        "\n",
        "x2 = Conv2D(64, (1, 1), activation='relu')(temp)\n",
        "x2 = Conv2D(64, (3, 3), activation='relu')(x2)\n",
        "x2 = Conv2D(64, (3, 3), activation='relu')(x2)\n",
        "\n",
        "\n",
        "x3 = Conv2D(64, (1, 1), activation='relu')(temp)\n",
        "x3 = Conv2D(64, (5, 5), activation='relu')(x3)\n",
        "\n",
        "x4 = Conv2D(64, (5, 5), activation='relu')(temp)\n",
        "x4 = Conv2D(64, (1, 1), activation='relu')(x4)\n",
        "\n",
        "x = concatenate([x, x1, x2, x3, x4])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "\n",
        "temp = x\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu')(temp)\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "\n",
        "x1 = Conv2D(128, (2, 2), padding='same', activation='relu')(temp)\n",
        "x1 = Conv2D(128, (2, 2), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(128, (2, 2), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(128, (2, 2), padding='same', activation='relu')(x1)\n",
        "x1 = Conv2D(128, (2, 2), padding='same', activation='relu')(x1)\n",
        "\n",
        "\n",
        "x2 = Conv2D(128, (3, 1), padding='same', activation='relu')(temp)\n",
        "x2 = Conv2D(128, (1, 3), padding='same', activation='relu')(x2)\n",
        "x2 = Conv2D(128, (3, 1), padding='same', activation='relu')(x2)\n",
        "x2 = Conv2D(128, (1, 3), padding='same', activation='relu')(x2)\n",
        "x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n",
        "\n",
        "x = concatenate([x, x1, x2, temp])\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = Dropout(0.5)(x)\n",
        "x = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=x)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, 30, 30, 32)   896         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, 32, 30, 32)   320         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, 32, 32, 32)   128         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, 30, 30, 32)   1056        conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, 30, 30, 32)   3104        conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, 30, 30, 32)   9248        conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 30, 30, 96)   0           conv2d_324[0][0]                 \n",
            "                                                                 conv2d_326[0][0]                 \n",
            "                                                                 conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 30, 30, 96)   384         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_63 (MaxPooling2D) (None, 15, 15, 96)   0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, 13, 13, 64)   55360       max_pooling2d_63[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 15, 13, 64)   18496       max_pooling2d_63[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 15, 15, 64)   6208        max_pooling2d_63[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 11, 11, 64)   36928       conv2d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 13, 13, 64)   12352       conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, 13, 13, 64)   36928       conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, 15, 15, 64)   6208        max_pooling2d_63[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, 11, 11, 64)   153664      max_pooling2d_63[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 11, 11, 64)   4160        conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 11, 11, 64)   36928       conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, 11, 11, 64)   36928       conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, 11, 11, 64)   102464      conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_341 (Conv2D)             (None, 11, 11, 64)   4160        conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 11, 11, 320)  0           conv2d_331[0][0]                 \n",
            "                                                                 conv2d_334[0][0]                 \n",
            "                                                                 conv2d_337[0][0]                 \n",
            "                                                                 conv2d_339[0][0]                 \n",
            "                                                                 conv2d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 11, 11, 320)  1280        concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_64 (MaxPooling2D) (None, 5, 5, 320)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_342 (Conv2D)             (None, 5, 5, 128)    368768      max_pooling2d_64[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_347 (Conv2D)             (None, 5, 5, 128)    163968      max_pooling2d_64[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, 5, 5, 128)    123008      max_pooling2d_64[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_343 (Conv2D)             (None, 5, 5, 128)    147584      conv2d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, 5, 5, 128)    65664       conv2d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, 5, 5, 128)    49280       conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_344 (Conv2D)             (None, 5, 5, 128)    147584      conv2d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, 5, 5, 128)    65664       conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, 5, 5, 128)    49280       conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_345 (Conv2D)             (None, 5, 5, 128)    147584      conv2d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, 5, 5, 128)    65664       conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, 5, 5, 128)    49280       conv2d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_346 (Conv2D)             (None, 5, 5, 128)    147584      conv2d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, 5, 5, 128)    65664       conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, 5, 5, 128)    16512       conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 5, 5, 704)    0           conv2d_346[0][0]                 \n",
            "                                                                 conv2d_351[0][0]                 \n",
            "                                                                 conv2d_356[0][0]                 \n",
            "                                                                 max_pooling2d_64[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 704)    2816        concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_22 (Gl (None, 704)          0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 704)          0           global_average_pooling2d_22[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 10)           7050        dropout_19[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 2,210,154\n",
            "Trainable params: 2,207,914\n",
            "Non-trainable params: 2,240\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynh17hn-2BXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # 在数据集上将输入平均值设置为0\n",
        "        samplewise_center=False,  # 将每个样本均值设置为0\n",
        "        featurewise_std_normalization=False,  # 将输入除以数据集的std\n",
        "        samplewise_std_normalization=False,  # 将每个输入除以其std\n",
        "        zca_whitening=False,  # 应用ZCA白化\n",
        "        rotation_range=20,  # 在一个范围下随机旋转图像(degrees, 0 to 180)\n",
        "        width_shift_range=0.2,  # 水平随机移位图像（总宽度的分数）\n",
        "        height_shift_range=0.2,  # 随机地垂直移动图像（总高度的分数）\n",
        "        horizontal_flip=True,  # 随机翻转图像\n",
        "        vertical_flip=False)  # 随机翻转图像\n",
        "\n",
        "    # 计算特征方向归一化所需的数量\n",
        "    # (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTfk9DcePD7K",
        "colab_type": "code",
        "outputId": "f4121af4-57e1-4550-e7a3-19f72917c1f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5329
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_11.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "optimizer = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=1e-6)\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                        batch_size=128),\n",
        "                        samples_per_epoch=x_train.shape[0],\n",
        "                        nb_epoch=100,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                   callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=390, epochs=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 47s 121ms/step - loss: 1.5806 - acc: 0.4303 - val_loss: 1.5578 - val_acc: 0.4476\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.44760, saving model to cifar10_model_11.h5\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 1.2410 - acc: 0.5565 - val_loss: 1.9781 - val_acc: 0.4850\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.44760 to 0.48500, saving model to cifar10_model_11.h5\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 1.0777 - acc: 0.6209 - val_loss: 0.9724 - val_acc: 0.6718\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.48500 to 0.67180, saving model to cifar10_model_11.h5\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.9617 - acc: 0.6649 - val_loss: 1.0317 - val_acc: 0.6623\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.67180\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.8846 - acc: 0.6944 - val_loss: 0.7468 - val_acc: 0.7477\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.67180 to 0.74770, saving model to cifar10_model_11.h5\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.8205 - acc: 0.7158 - val_loss: 0.7489 - val_acc: 0.7516\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.74770 to 0.75160, saving model to cifar10_model_11.h5\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.7632 - acc: 0.7361 - val_loss: 0.9363 - val_acc: 0.7058\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.75160\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.7341 - acc: 0.7472 - val_loss: 0.6311 - val_acc: 0.7838\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.75160 to 0.78380, saving model to cifar10_model_11.h5\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.6972 - acc: 0.7596 - val_loss: 0.6906 - val_acc: 0.7694\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.78380\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.6643 - acc: 0.7723 - val_loss: 0.8923 - val_acc: 0.7196\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.78380\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.6321 - acc: 0.7836 - val_loss: 1.0151 - val_acc: 0.6969\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.78380\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.6091 - acc: 0.7923 - val_loss: 0.7620 - val_acc: 0.7667\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.78380\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5908 - acc: 0.7984 - val_loss: 0.6172 - val_acc: 0.7962\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.78380 to 0.79620, saving model to cifar10_model_11.h5\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.5616 - acc: 0.8078 - val_loss: 0.7561 - val_acc: 0.7534\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.79620\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5435 - acc: 0.8160 - val_loss: 0.5517 - val_acc: 0.8107\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.79620 to 0.81070, saving model to cifar10_model_11.h5\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.5230 - acc: 0.8194 - val_loss: 0.6317 - val_acc: 0.7966\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.81070\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.5153 - acc: 0.8241 - val_loss: 0.5771 - val_acc: 0.8167\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.81070 to 0.81670, saving model to cifar10_model_11.h5\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5002 - acc: 0.8282 - val_loss: 0.5030 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.81670 to 0.83350, saving model to cifar10_model_11.h5\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4802 - acc: 0.8375 - val_loss: 0.4694 - val_acc: 0.8437\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.83350 to 0.84370, saving model to cifar10_model_11.h5\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.4716 - acc: 0.8400 - val_loss: 0.5312 - val_acc: 0.8334\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.84370\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4507 - acc: 0.8458 - val_loss: 0.5295 - val_acc: 0.8245\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.84370\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4416 - acc: 0.8495 - val_loss: 0.5723 - val_acc: 0.8194\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.84370\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4326 - acc: 0.8529 - val_loss: 0.5294 - val_acc: 0.8284\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.84370\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4197 - acc: 0.8581 - val_loss: 0.6116 - val_acc: 0.8139\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.84370\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.2.\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.3533 - acc: 0.8790 - val_loss: 0.4258 - val_acc: 0.8659\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.84370 to 0.86590, saving model to cifar10_model_11.h5\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.3299 - acc: 0.8876 - val_loss: 0.4078 - val_acc: 0.8718\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.86590 to 0.87180, saving model to cifar10_model_11.h5\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.3170 - acc: 0.8922 - val_loss: 0.4115 - val_acc: 0.8704\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.87180\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.3082 - acc: 0.8943 - val_loss: 0.4043 - val_acc: 0.8716\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.87180\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.3015 - acc: 0.8967 - val_loss: 0.3997 - val_acc: 0.8741\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.87180 to 0.87410, saving model to cifar10_model_11.h5\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2928 - acc: 0.8995 - val_loss: 0.4216 - val_acc: 0.8743\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.87410 to 0.87430, saving model to cifar10_model_11.h5\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2941 - acc: 0.9008 - val_loss: 0.3904 - val_acc: 0.8748\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.87430 to 0.87480, saving model to cifar10_model_11.h5\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2904 - acc: 0.9021 - val_loss: 0.4508 - val_acc: 0.8635\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.87480\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2874 - acc: 0.9019 - val_loss: 0.3913 - val_acc: 0.8770\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.87480 to 0.87700, saving model to cifar10_model_11.h5\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2760 - acc: 0.9053 - val_loss: 0.4144 - val_acc: 0.8741\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.87700\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2723 - acc: 0.9061 - val_loss: 0.3985 - val_acc: 0.8740\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.87700\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2706 - acc: 0.9068 - val_loss: 0.4053 - val_acc: 0.8749\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.87700\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2642 - acc: 0.9083 - val_loss: 0.4128 - val_acc: 0.8764\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.87700\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2641 - acc: 0.9092 - val_loss: 0.4039 - val_acc: 0.8773\n",
            "\n",
            "Epoch 00038: val_acc improved from 0.87700 to 0.87730, saving model to cifar10_model_11.h5\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2590 - acc: 0.9105 - val_loss: 0.4061 - val_acc: 0.8765\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.87730\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2576 - acc: 0.9113 - val_loss: 0.3871 - val_acc: 0.8828\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.87730 to 0.88280, saving model to cifar10_model_11.h5\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2497 - acc: 0.9147 - val_loss: 0.4286 - val_acc: 0.8704\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.88280\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2485 - acc: 0.9157 - val_loss: 0.4270 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.88280\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2428 - acc: 0.9158 - val_loss: 0.4155 - val_acc: 0.8746\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.88280\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2402 - acc: 0.9183 - val_loss: 0.4166 - val_acc: 0.8795\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.88280\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2439 - acc: 0.9160 - val_loss: 0.3973 - val_acc: 0.8791\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.88280\n",
            "\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2312 - acc: 0.9207 - val_loss: 0.3921 - val_acc: 0.8829\n",
            "\n",
            "Epoch 00046: val_acc improved from 0.88280 to 0.88290, saving model to cifar10_model_11.h5\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2200 - acc: 0.9253 - val_loss: 0.3958 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.88290 to 0.88320, saving model to cifar10_model_11.h5\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2212 - acc: 0.9246 - val_loss: 0.3966 - val_acc: 0.8838\n",
            "\n",
            "Epoch 00048: val_acc improved from 0.88320 to 0.88380, saving model to cifar10_model_11.h5\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2173 - acc: 0.9260 - val_loss: 0.3963 - val_acc: 0.8831\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.88380\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2182 - acc: 0.9236 - val_loss: 0.3992 - val_acc: 0.8811\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.88380\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2136 - acc: 0.9263 - val_loss: 0.3912 - val_acc: 0.8835\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.88380\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2163 - acc: 0.9261 - val_loss: 0.3975 - val_acc: 0.8829\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.88380\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2159 - acc: 0.9248 - val_loss: 0.3925 - val_acc: 0.8843\n",
            "\n",
            "Epoch 00053: val_acc improved from 0.88380 to 0.88430, saving model to cifar10_model_11.h5\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2106 - acc: 0.9282 - val_loss: 0.3977 - val_acc: 0.8829\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.88430\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2151 - acc: 0.9267 - val_loss: 0.4064 - val_acc: 0.8820\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.88430\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2104 - acc: 0.9273 - val_loss: 0.3961 - val_acc: 0.8830\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.88430\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2112 - acc: 0.9274 - val_loss: 0.4050 - val_acc: 0.8834\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.88430\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2062 - acc: 0.9296 - val_loss: 0.3983 - val_acc: 0.8838\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.88430\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2064 - acc: 0.9300 - val_loss: 0.3991 - val_acc: 0.8846\n",
            "\n",
            "Epoch 00059: val_acc improved from 0.88430 to 0.88460, saving model to cifar10_model_11.h5\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2048 - acc: 0.9285 - val_loss: 0.3944 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00060: val_acc improved from 0.88460 to 0.88540, saving model to cifar10_model_11.h5\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2058 - acc: 0.9292 - val_loss: 0.3980 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.88540\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2106 - acc: 0.9280 - val_loss: 0.3966 - val_acc: 0.8844\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.88540\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2064 - acc: 0.9302 - val_loss: 0.3941 - val_acc: 0.8845\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.88540\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2005 - acc: 0.9302 - val_loss: 0.3951 - val_acc: 0.8853\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.88540\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2073 - acc: 0.9285 - val_loss: 0.3988 - val_acc: 0.8845\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.88540\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2068 - acc: 0.9295 - val_loss: 0.3961 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.88540\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.2044 - acc: 0.9297 - val_loss: 0.3990 - val_acc: 0.8852\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.88540\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2031 - acc: 0.9303 - val_loss: 0.3971 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.88540\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2054 - acc: 0.9302 - val_loss: 0.3980 - val_acc: 0.8847\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.88540\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.2057 - acc: 0.9293 - val_loss: 0.3971 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.88540\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0003199999686330557.\n",
            "Epoch 00070: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c471d7710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsLnTFVUPD4t",
        "colab_type": "code",
        "outputId": "43a3234e-813c-49a5-e075-fce594f1e208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_11.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 8s 825us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.39441200981140134, 0.8854]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfToMJKyJ9CU",
        "colab_type": "text"
      },
      "source": [
        "### ResNet_18 残差神经网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qinmwcduqMtF",
        "colab_type": "code",
        "outputId": "27d4d9d2-317c-4d6d-f1e5-c3b0f9beecfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2663
        }
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, BatchNormalization, Activation, add, GlobalAvgPool2D\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def conv2d_bn(x, nb_filter, kernel_size, strides=(1, 1), padding='same'):\n",
        "    \"\"\"\n",
        "    conv2d -> batch normalization -> relu activation\n",
        "    \"\"\"\n",
        "    x = Conv2D(nb_filter, kernel_size=kernel_size,\n",
        "                          strides=strides,\n",
        "                          padding=padding,\n",
        "                          kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def shortcut(input, residual):\n",
        "    \"\"\"\n",
        "    shortcut连接，也就是identity mapping部分。\n",
        "    \"\"\"\n",
        "\n",
        "    input_shape = K.int_shape(input)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    stride_height = int(round(input_shape[1] / residual_shape[1]))\n",
        "    stride_width = int(round(input_shape[2] / residual_shape[2]))\n",
        "    equal_channels = input_shape[3] == residual_shape[3]\n",
        "\n",
        "    identity = input\n",
        "    # 如果维度不同，则使用1x1卷积进行调整\n",
        "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "        identity = Conv2D(filters=residual_shape[3],\n",
        "                           kernel_size=(1, 1),\n",
        "                           strides=(stride_width, stride_height),\n",
        "                           padding=\"valid\",\n",
        "                           kernel_regularizer=regularizers.l2(0.0001))(input)\n",
        "\n",
        "    return add([identity, residual])\n",
        "\n",
        "\n",
        "def basic_block(nb_filter, strides=(1, 1)):\n",
        "    \"\"\"\n",
        "    基本的ResNet building block，适用于ResNet-18和ResNet-34.\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        conv1 = conv2d_bn(input, nb_filter, kernel_size=(3, 3), strides=strides)\n",
        "        residual = conv2d_bn(conv1, nb_filter, kernel_size=(3, 3))\n",
        "\n",
        "        return shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def residual_block(nb_filter, repetitions, is_first_layer=False):\n",
        "    \"\"\"\n",
        "    构建每层的residual模块，对应论文参数统计表中的conv2_x -> conv5_x\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        for i in range(repetitions):\n",
        "            strides = (1, 1)\n",
        "            if i == 0 and not is_first_layer:\n",
        "                strides = (2, 2)\n",
        "            input = basic_block(nb_filter, strides)(input)\n",
        "        return input\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def resnet_18(input_shape=(224,224,3), nclass=1000):\n",
        "    \"\"\"\n",
        "    build resnet-18 model using keras with TensorFlow backend.\n",
        "    :param input_shape: input shape of network, default as (224,224,3)\n",
        "    :param nclass: numbers of class(output shape of network), default as 1000\n",
        "    :return: resnet-18 model\n",
        "    \"\"\"\n",
        "    input_ = Input(shape=input_shape)\n",
        "\n",
        "    conv1 = conv2d_bn(input_, 64, kernel_size=(7, 7), strides=(2, 2))\n",
        "    pool1 = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(conv1)\n",
        "\n",
        "    conv2 = residual_block(64, 2, is_first_layer=True)(pool1)\n",
        "    conv3 = residual_block(128, 2, is_first_layer=True)(conv2)\n",
        "    conv4 = residual_block(256, 2, is_first_layer=True)(conv3)\n",
        "    conv5 = residual_block(512, 2, is_first_layer=True)(conv4)\n",
        "\n",
        "    pool2 = GlobalAvgPool2D()(conv5)\n",
        "    output_ = Dense(nclass, activation='softmax')(pool2)\n",
        "\n",
        "    model = Model(inputs=input_, outputs=output_)\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    model = resnet_18(input_shape=(32,32,3), nclass=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   9472        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 64)     36928       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 64)     0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 64)     36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 64)     256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 64)     0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 64)     0           max_pooling2d_2[0][0]            \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 64)     36928       add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 64)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 64)     36928       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 64)     0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 64)     0           add_9[0][0]                      \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 128)    73856       add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 128)    512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 128)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 128)    147584      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 128)    512         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 128)    8320        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 8, 128)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 128)    0           conv2d_28[0][0]                  \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 128)    147584      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 128)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 128)    147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 128)    512         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 128)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 128)    0           add_11[0][0]                     \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 256)    295168      add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 256)    1024        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 256)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 256)    590080      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 256)    1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 256)    33024       add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 256)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 256)    0           conv2d_33[0][0]                  \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 256)    590080      add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 256)    1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 256)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 256)    590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 256)    1024        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 256)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 8, 8, 256)    0           add_13[0][0]                     \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 512)    1180160     add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 512)    2048        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 512)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 512)    2359808     activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 512)    2048        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 512)    131584      add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 512)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 8, 8, 512)    0           conv2d_38[0][0]                  \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 512)    2359808     add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 512)    2048        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 512)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 512)    2359808     activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 512)    2048        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 512)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 512)    0           add_15[0][0]                     \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 512)          0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           5130        global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 11,192,458\n",
            "Trainable params: 11,184,650\n",
            "Non-trainable params: 7,808\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iFmjmYctrX5",
        "colab_type": "code",
        "outputId": "b8baec67-6d23-49d6-c3cb-56af7036808b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6975
        }
      },
      "source": [
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "plot_model(model, to_file='Resnet_18_model.png', show_shapes=True)                                   # 保存模型图片\n",
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))                #  显示在jupyter notebook 上"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"5201pt\" viewBox=\"0.00 0.00 914.50 5201.00\" width=\"915pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 5197)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-5197 910.5,-5197 910.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140524227124360 -->\n<g class=\"node\" id=\"node1\">\n<title>140524227124360</title>\n<polygon fill=\"none\" points=\"223,-5146.5 223,-5192.5 531,-5192.5 531,-5146.5 223,-5146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289.5\" y=\"-5165.8\">input_1: InputLayer</text>\n<polyline fill=\"none\" points=\"356,-5146.5 356,-5192.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"385\" y=\"-5177.3\">input:</text>\n<polyline fill=\"none\" points=\"356,-5169.5 414,-5169.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"385\" y=\"-5154.3\">output:</text>\n<polyline fill=\"none\" points=\"414,-5146.5 414,-5192.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472.5\" y=\"-5177.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"414,-5169.5 531,-5169.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472.5\" y=\"-5154.3\">(None, 32, 32, 3)</text>\n</g>\n<!-- 140524227124752 -->\n<g class=\"node\" id=\"node2\">\n<title>140524227124752</title>\n<polygon fill=\"none\" points=\"219,-5063.5 219,-5109.5 535,-5109.5 535,-5063.5 219,-5063.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285.5\" y=\"-5082.8\">conv2d_1: Conv2D</text>\n<polyline fill=\"none\" points=\"352,-5063.5 352,-5109.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"381\" y=\"-5094.3\">input:</text>\n<polyline fill=\"none\" points=\"352,-5086.5 410,-5086.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"381\" y=\"-5071.3\">output:</text>\n<polyline fill=\"none\" points=\"410,-5063.5 410,-5109.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472.5\" y=\"-5094.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"410,-5086.5 535,-5086.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472.5\" y=\"-5071.3\">(None, 16, 16, 64)</text>\n</g>\n<!-- 140524227124360&#45;&gt;140524227124752 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140524227124360-&gt;140524227124752</title>\n<path d=\"M377,-5146.3799C377,-5138.1745 377,-5128.7679 377,-5119.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"380.5001,-5119.784 377,-5109.784 373.5001,-5119.784 380.5001,-5119.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140524227125144 -->\n<g class=\"node\" id=\"node3\">\n<title>140524227125144</title>\n<polygon fill=\"none\" points=\"150,-4980.5 150,-5026.5 604,-5026.5 604,-4980.5 150,-4980.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285.5\" y=\"-4999.8\">batch_normalization_1: BatchNormalization</text>\n<polyline fill=\"none\" points=\"421,-4980.5 421,-5026.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450\" y=\"-5011.3\">input:</text>\n<polyline fill=\"none\" points=\"421,-5003.5 479,-5003.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450\" y=\"-4988.3\">output:</text>\n<polyline fill=\"none\" points=\"479,-4980.5 479,-5026.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"541.5\" y=\"-5011.3\">(None, 16, 16, 64)</text>\n<polyline fill=\"none\" points=\"479,-5003.5 604,-5003.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"541.5\" y=\"-4988.3\">(None, 16, 16, 64)</text>\n</g>\n<!-- 140524227124752&#45;&gt;140524227125144 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140524227124752-&gt;140524227125144</title>\n<path d=\"M377,-5063.3799C377,-5055.1745 377,-5045.7679 377,-5036.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"380.5001,-5036.784 377,-5026.784 373.5001,-5036.784 380.5001,-5036.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140524227232040 -->\n<g class=\"node\" id=\"node4\">\n<title>140524227232040</title>\n<polygon fill=\"none\" points=\"208.5,-4897.5 208.5,-4943.5 545.5,-4943.5 545.5,-4897.5 208.5,-4897.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285.5\" y=\"-4916.8\">activation_1: Activation</text>\n<polyline fill=\"none\" points=\"362.5,-4897.5 362.5,-4943.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-4928.3\">input:</text>\n<polyline fill=\"none\" points=\"362.5,-4920.5 420.5,-4920.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-4905.3\">output:</text>\n<polyline fill=\"none\" points=\"420.5,-4897.5 420.5,-4943.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"483\" y=\"-4928.3\">(None, 16, 16, 64)</text>\n<polyline fill=\"none\" points=\"420.5,-4920.5 545.5,-4920.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"483\" y=\"-4905.3\">(None, 16, 16, 64)</text>\n</g>\n<!-- 140524227125144&#45;&gt;140524227232040 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140524227125144-&gt;140524227232040</title>\n<path d=\"M377,-4980.3799C377,-4972.1745 377,-4962.7679 377,-4953.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"380.5001,-4953.784 377,-4943.784 373.5001,-4953.784 380.5001,-4953.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140525595992528 -->\n<g class=\"node\" id=\"node5\">\n<title>140525595992528</title>\n<polygon fill=\"none\" points=\"175,-4814.5 175,-4860.5 579,-4860.5 579,-4814.5 175,-4814.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285.5\" y=\"-4833.8\">max_pooling2d_1: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"396,-4814.5 396,-4860.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"425\" y=\"-4845.3\">input:</text>\n<polyline fill=\"none\" points=\"396,-4837.5 454,-4837.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"425\" y=\"-4822.3\">output:</text>\n<polyline fill=\"none\" points=\"454,-4814.5 454,-4860.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"516.5\" y=\"-4845.3\">(None, 16, 16, 64)</text>\n<polyline fill=\"none\" points=\"454,-4837.5 579,-4837.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"516.5\" y=\"-4822.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140524227232040&#45;&gt;140525595992528 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140524227232040-&gt;140525595992528</title>\n<path d=\"M377,-4897.3799C377,-4889.1745 377,-4879.7679 377,-4870.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"380.5001,-4870.784 377,-4860.784 373.5001,-4870.784 380.5001,-4870.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140524227215032 -->\n<g class=\"node\" id=\"node6\">\n<title>140524227215032</title>\n<polygon fill=\"none\" points=\"137.5,-4731.5 137.5,-4777.5 438.5,-4777.5 438.5,-4731.5 137.5,-4731.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"204\" y=\"-4750.8\">conv2d_2: Conv2D</text>\n<polyline fill=\"none\" points=\"270.5,-4731.5 270.5,-4777.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299.5\" y=\"-4762.3\">input:</text>\n<polyline fill=\"none\" points=\"270.5,-4754.5 328.5,-4754.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299.5\" y=\"-4739.3\">output:</text>\n<polyline fill=\"none\" points=\"328.5,-4731.5 328.5,-4777.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"383.5\" y=\"-4762.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"328.5,-4754.5 438.5,-4754.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"383.5\" y=\"-4739.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140525595992528&#45;&gt;140524227215032 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140525595992528-&gt;140524227215032</title>\n<path d=\"M352.2085,-4814.3799C342.3581,-4805.1935 330.893,-4794.5013 320.3994,-4784.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"322.6676,-4782.0446 312.9672,-4777.784 317.8934,-4787.1639 322.6676,-4782.0446\" stroke=\"#000000\"/>\n</g>\n<!-- 140523821586136 -->\n<g class=\"node\" id=\"node12\">\n<title>140523821586136</title>\n<polygon fill=\"none\" points=\"225,-4233.5 225,-4279.5 587,-4279.5 587,-4233.5 225,-4233.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267.5\" y=\"-4252.8\">add_1: Add</text>\n<polyline fill=\"none\" points=\"310,-4233.5 310,-4279.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339\" y=\"-4264.3\">input:</text>\n<polyline fill=\"none\" points=\"310,-4256.5 368,-4256.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339\" y=\"-4241.3\">output:</text>\n<polyline fill=\"none\" points=\"368,-4233.5 368,-4279.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"477.5\" y=\"-4264.3\">[(None, 8, 8, 64), (None, 8, 8, 64)]</text>\n<polyline fill=\"none\" points=\"368,-4256.5 587,-4256.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"477.5\" y=\"-4241.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140525595992528&#45;&gt;140523821586136 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140525595992528-&gt;140523821586136</title>\n<path d=\"M409.9042,-4814.3348C446.6398,-4785.477 501,-4732.473 501,-4671.5 501,-4671.5 501,-4671.5 501,-4422.5 501,-4369.696 464.3422,-4318.4396 436.5692,-4287.1835\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"439.0512,-4284.7109 429.7275,-4279.6792 433.8784,-4289.4271 439.0512,-4284.7109\" stroke=\"#000000\"/>\n</g>\n<!-- 140524016421856 -->\n<g class=\"node\" id=\"node7\">\n<title>140524016421856</title>\n<polygon fill=\"none\" points=\"33.5,-4648.5 33.5,-4694.5 472.5,-4694.5 472.5,-4648.5 33.5,-4648.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-4667.8\">batch_normalization_2: BatchNormalization</text>\n<polyline fill=\"none\" points=\"304.5,-4648.5 304.5,-4694.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-4679.3\">input:</text>\n<polyline fill=\"none\" points=\"304.5,-4671.5 362.5,-4671.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-4656.3\">output:</text>\n<polyline fill=\"none\" points=\"362.5,-4648.5 362.5,-4694.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417.5\" y=\"-4679.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"362.5,-4671.5 472.5,-4671.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417.5\" y=\"-4656.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140524227215032&#45;&gt;140524016421856 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140524227215032-&gt;140524016421856</title>\n<path d=\"M278.2505,-4731.3799C274.6776,-4722.907 270.5646,-4713.1531 266.7093,-4704.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"269.9291,-4702.6383 262.8186,-4694.784 263.4792,-4705.3582 269.9291,-4702.6383\" stroke=\"#000000\"/>\n</g>\n<!-- 140524016422192 -->\n<g class=\"node\" id=\"node8\">\n<title>140524016422192</title>\n<polygon fill=\"none\" points=\"92,-4565.5 92,-4611.5 414,-4611.5 414,-4565.5 92,-4565.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-4584.8\">activation_2: Activation</text>\n<polyline fill=\"none\" points=\"246,-4565.5 246,-4611.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275\" y=\"-4596.3\">input:</text>\n<polyline fill=\"none\" points=\"246,-4588.5 304,-4588.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275\" y=\"-4573.3\">output:</text>\n<polyline fill=\"none\" points=\"304,-4565.5 304,-4611.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359\" y=\"-4596.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"304,-4588.5 414,-4588.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359\" y=\"-4573.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140524016421856&#45;&gt;140524016422192 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140524016421856-&gt;140524016422192</title>\n<path d=\"M253,-4648.3799C253,-4640.1745 253,-4630.7679 253,-4621.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"256.5001,-4621.784 253,-4611.784 249.5001,-4621.784 256.5001,-4621.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140524016259144 -->\n<g class=\"node\" id=\"node9\">\n<title>140524016259144</title>\n<polygon fill=\"none\" points=\"102.5,-4482.5 102.5,-4528.5 403.5,-4528.5 403.5,-4482.5 102.5,-4482.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-4501.8\">conv2d_3: Conv2D</text>\n<polyline fill=\"none\" points=\"235.5,-4482.5 235.5,-4528.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-4513.3\">input:</text>\n<polyline fill=\"none\" points=\"235.5,-4505.5 293.5,-4505.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-4490.3\">output:</text>\n<polyline fill=\"none\" points=\"293.5,-4482.5 293.5,-4528.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-4513.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"293.5,-4505.5 403.5,-4505.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-4490.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140524016422192&#45;&gt;140524016259144 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140524016422192-&gt;140524016259144</title>\n<path d=\"M253,-4565.3799C253,-4557.1745 253,-4547.7679 253,-4538.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"256.5001,-4538.784 253,-4528.784 249.5001,-4538.784 256.5001,-4538.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140524015976232 -->\n<g class=\"node\" id=\"node10\">\n<title>140524015976232</title>\n<polygon fill=\"none\" points=\"33.5,-4399.5 33.5,-4445.5 472.5,-4445.5 472.5,-4399.5 33.5,-4399.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-4418.8\">batch_normalization_3: BatchNormalization</text>\n<polyline fill=\"none\" points=\"304.5,-4399.5 304.5,-4445.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-4430.3\">input:</text>\n<polyline fill=\"none\" points=\"304.5,-4422.5 362.5,-4422.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-4407.3\">output:</text>\n<polyline fill=\"none\" points=\"362.5,-4399.5 362.5,-4445.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417.5\" y=\"-4430.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"362.5,-4422.5 472.5,-4422.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417.5\" y=\"-4407.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140524016259144&#45;&gt;140524015976232 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140524016259144-&gt;140524015976232</title>\n<path d=\"M253,-4482.3799C253,-4474.1745 253,-4464.7679 253,-4455.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"256.5001,-4455.784 253,-4445.784 249.5001,-4455.784 256.5001,-4455.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140524015560968 -->\n<g class=\"node\" id=\"node11\">\n<title>140524015560968</title>\n<polygon fill=\"none\" points=\"121,-4316.5 121,-4362.5 443,-4362.5 443,-4316.5 121,-4316.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-4335.8\">activation_3: Activation</text>\n<polyline fill=\"none\" points=\"275,-4316.5 275,-4362.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-4347.3\">input:</text>\n<polyline fill=\"none\" points=\"275,-4339.5 333,-4339.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-4324.3\">output:</text>\n<polyline fill=\"none\" points=\"333,-4316.5 333,-4362.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388\" y=\"-4347.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"333,-4339.5 443,-4339.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388\" y=\"-4324.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140524015976232&#45;&gt;140524015560968 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140524015976232-&gt;140524015560968</title>\n<path d=\"M261.0781,-4399.3799C264.0074,-4390.9962 267.3748,-4381.3584 270.5399,-4372.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"273.8702,-4373.3788 273.8646,-4362.784 267.262,-4371.0699 273.8702,-4373.3788\" stroke=\"#000000\"/>\n</g>\n<!-- 140524015560968&#45;&gt;140523821586136 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140524015560968-&gt;140523821586136</title>\n<path d=\"M316.5409,-4316.3799C330.7982,-4306.8367 347.4831,-4295.6686 362.5562,-4285.5793\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"364.8509,-4288.2551 371.2143,-4279.784 360.9572,-4282.4379 364.8509,-4288.2551\" stroke=\"#000000\"/>\n</g>\n<!-- 140523821587032 -->\n<g class=\"node\" id=\"node13\">\n<title>140523821587032</title>\n<polygon fill=\"none\" points=\"166.5,-4150.5 166.5,-4196.5 467.5,-4196.5 467.5,-4150.5 166.5,-4150.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233\" y=\"-4169.8\">conv2d_4: Conv2D</text>\n<polyline fill=\"none\" points=\"299.5,-4150.5 299.5,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-4181.3\">input:</text>\n<polyline fill=\"none\" points=\"299.5,-4173.5 357.5,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-4158.3\">output:</text>\n<polyline fill=\"none\" points=\"357.5,-4150.5 357.5,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-4181.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"357.5,-4173.5 467.5,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-4158.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140523821586136&#45;&gt;140523821587032 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140523821586136-&gt;140523821587032</title>\n<path d=\"M381.2085,-4233.3799C371.3581,-4224.1935 359.893,-4213.5013 349.3994,-4203.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"351.6676,-4201.0446 341.9672,-4196.784 346.8934,-4206.1639 351.6676,-4201.0446\" stroke=\"#000000\"/>\n</g>\n<!-- 140523819629816 -->\n<g class=\"node\" id=\"node19\">\n<title>140523819629816</title>\n<polygon fill=\"none\" points=\"239,-3652.5 239,-3698.5 601,-3698.5 601,-3652.5 239,-3652.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-3671.8\">add_2: Add</text>\n<polyline fill=\"none\" points=\"324,-3652.5 324,-3698.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353\" y=\"-3683.3\">input:</text>\n<polyline fill=\"none\" points=\"324,-3675.5 382,-3675.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353\" y=\"-3660.3\">output:</text>\n<polyline fill=\"none\" points=\"382,-3652.5 382,-3698.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"491.5\" y=\"-3683.3\">[(None, 8, 8, 64), (None, 8, 8, 64)]</text>\n<polyline fill=\"none\" points=\"382,-3675.5 601,-3675.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"491.5\" y=\"-3660.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140523821586136&#45;&gt;140523819629816 -->\n<g class=\"edge\" id=\"edge19\">\n<title>140523821586136-&gt;140523819629816</title>\n<path d=\"M438.9042,-4233.3348C475.6398,-4204.477 530,-4151.473 530,-4090.5 530,-4090.5 530,-4090.5 530,-3841.5 530,-3786.7686 487.9349,-3736.2482 455.8303,-3705.6605\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"458.038,-3702.9344 448.3277,-3698.6964 453.2758,-3708.0648 458.038,-3702.9344\" stroke=\"#000000\"/>\n</g>\n<!-- 140523821418984 -->\n<g class=\"node\" id=\"node14\">\n<title>140523821418984</title>\n<polygon fill=\"none\" points=\"62.5,-4067.5 62.5,-4113.5 501.5,-4113.5 501.5,-4067.5 62.5,-4067.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-4086.8\">batch_normalization_4: BatchNormalization</text>\n<polyline fill=\"none\" points=\"333.5,-4067.5 333.5,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362.5\" y=\"-4098.3\">input:</text>\n<polyline fill=\"none\" points=\"333.5,-4090.5 391.5,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362.5\" y=\"-4075.3\">output:</text>\n<polyline fill=\"none\" points=\"391.5,-4067.5 391.5,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446.5\" y=\"-4098.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"391.5,-4090.5 501.5,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446.5\" y=\"-4075.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140523821587032&#45;&gt;140523821418984 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140523821587032-&gt;140523821418984</title>\n<path d=\"M307.2505,-4150.3799C303.6776,-4141.907 299.5646,-4132.1531 295.7093,-4123.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"298.9291,-4121.6383 291.8186,-4113.784 292.4792,-4124.3582 298.9291,-4121.6383\" stroke=\"#000000\"/>\n</g>\n<!-- 140523820880504 -->\n<g class=\"node\" id=\"node15\">\n<title>140523820880504</title>\n<polygon fill=\"none\" points=\"121,-3984.5 121,-4030.5 443,-4030.5 443,-3984.5 121,-3984.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-4003.8\">activation_4: Activation</text>\n<polyline fill=\"none\" points=\"275,-3984.5 275,-4030.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-4015.3\">input:</text>\n<polyline fill=\"none\" points=\"275,-4007.5 333,-4007.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-3992.3\">output:</text>\n<polyline fill=\"none\" points=\"333,-3984.5 333,-4030.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388\" y=\"-4015.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"333,-4007.5 443,-4007.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388\" y=\"-3992.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140523821418984&#45;&gt;140523820880504 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140523821418984-&gt;140523820880504</title>\n<path d=\"M282,-4067.3799C282,-4059.1745 282,-4049.7679 282,-4040.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"285.5001,-4040.784 282,-4030.784 278.5001,-4040.784 285.5001,-4040.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523820561688 -->\n<g class=\"node\" id=\"node16\">\n<title>140523820561688</title>\n<polygon fill=\"none\" points=\"131.5,-3901.5 131.5,-3947.5 432.5,-3947.5 432.5,-3901.5 131.5,-3901.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-3920.8\">conv2d_5: Conv2D</text>\n<polyline fill=\"none\" points=\"264.5,-3901.5 264.5,-3947.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293.5\" y=\"-3932.3\">input:</text>\n<polyline fill=\"none\" points=\"264.5,-3924.5 322.5,-3924.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293.5\" y=\"-3909.3\">output:</text>\n<polyline fill=\"none\" points=\"322.5,-3901.5 322.5,-3947.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"377.5\" y=\"-3932.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"322.5,-3924.5 432.5,-3924.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"377.5\" y=\"-3909.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140523820880504&#45;&gt;140523820561688 -->\n<g class=\"edge\" id=\"edge16\">\n<title>140523820880504-&gt;140523820561688</title>\n<path d=\"M282,-3984.3799C282,-3976.1745 282,-3966.7679 282,-3957.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"285.5001,-3957.784 282,-3947.784 278.5001,-3957.784 285.5001,-3957.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523820051648 -->\n<g class=\"node\" id=\"node17\">\n<title>140523820051648</title>\n<polygon fill=\"none\" points=\"62.5,-3818.5 62.5,-3864.5 501.5,-3864.5 501.5,-3818.5 62.5,-3818.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-3837.8\">batch_normalization_5: BatchNormalization</text>\n<polyline fill=\"none\" points=\"333.5,-3818.5 333.5,-3864.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362.5\" y=\"-3849.3\">input:</text>\n<polyline fill=\"none\" points=\"333.5,-3841.5 391.5,-3841.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362.5\" y=\"-3826.3\">output:</text>\n<polyline fill=\"none\" points=\"391.5,-3818.5 391.5,-3864.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446.5\" y=\"-3849.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"391.5,-3841.5 501.5,-3841.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446.5\" y=\"-3826.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140523820561688&#45;&gt;140523820051648 -->\n<g class=\"edge\" id=\"edge17\">\n<title>140523820561688-&gt;140523820051648</title>\n<path d=\"M282,-3901.3799C282,-3893.1745 282,-3883.7679 282,-3874.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"285.5001,-3874.784 282,-3864.784 278.5001,-3874.784 285.5001,-3874.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523820376864 -->\n<g class=\"node\" id=\"node18\">\n<title>140523820376864</title>\n<polygon fill=\"none\" points=\"150,-3735.5 150,-3781.5 472,-3781.5 472,-3735.5 150,-3735.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"227\" y=\"-3754.8\">activation_5: Activation</text>\n<polyline fill=\"none\" points=\"304,-3735.5 304,-3781.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-3766.3\">input:</text>\n<polyline fill=\"none\" points=\"304,-3758.5 362,-3758.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-3743.3\">output:</text>\n<polyline fill=\"none\" points=\"362,-3735.5 362,-3781.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417\" y=\"-3766.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"362,-3758.5 472,-3758.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417\" y=\"-3743.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140523820051648&#45;&gt;140523820376864 -->\n<g class=\"edge\" id=\"edge18\">\n<title>140523820051648-&gt;140523820376864</title>\n<path d=\"M290.0781,-3818.3799C293.0074,-3809.9962 296.3748,-3800.3584 299.5399,-3791.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"302.8702,-3792.3788 302.8646,-3781.784 296.262,-3790.0699 302.8702,-3792.3788\" stroke=\"#000000\"/>\n</g>\n<!-- 140523820376864&#45;&gt;140523819629816 -->\n<g class=\"edge\" id=\"edge20\">\n<title>140523820376864-&gt;140523819629816</title>\n<path d=\"M341.3626,-3735.3799C353.778,-3725.9259 368.2878,-3714.8772 381.4396,-3704.8625\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"383.5866,-3707.6269 389.4222,-3698.784 379.3458,-3702.0577 383.5866,-3707.6269\" stroke=\"#000000\"/>\n</g>\n<!-- 140523819536056 -->\n<g class=\"node\" id=\"node20\">\n<title>140523819536056</title>\n<polygon fill=\"none\" points=\"175,-3569.5 175,-3615.5 483,-3615.5 483,-3569.5 175,-3569.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-3588.8\">conv2d_6: Conv2D</text>\n<polyline fill=\"none\" points=\"308,-3569.5 308,-3615.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"337\" y=\"-3600.3\">input:</text>\n<polyline fill=\"none\" points=\"308,-3592.5 366,-3592.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"337\" y=\"-3577.3\">output:</text>\n<polyline fill=\"none\" points=\"366,-3569.5 366,-3615.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.5\" y=\"-3600.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"366,-3592.5 483,-3592.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.5\" y=\"-3577.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523819629816&#45;&gt;140523819536056 -->\n<g class=\"edge\" id=\"edge21\">\n<title>140523819629816-&gt;140523819536056</title>\n<path d=\"M394.6514,-3652.3799C384.5796,-3643.1935 372.8569,-3632.5013 362.1275,-3622.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"364.2752,-3619.9369 354.5282,-3615.784 359.558,-3625.1088 364.2752,-3619.9369\" stroke=\"#000000\"/>\n</g>\n<!-- 140523817142144 -->\n<g class=\"node\" id=\"node25\">\n<title>140523817142144</title>\n<polygon fill=\"none\" points=\"464,-3486.5 464,-3532.5 772,-3532.5 772,-3486.5 464,-3486.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-3505.8\">conv2d_8: Conv2D</text>\n<polyline fill=\"none\" points=\"597,-3486.5 597,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"626\" y=\"-3517.3\">input:</text>\n<polyline fill=\"none\" points=\"597,-3509.5 655,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"626\" y=\"-3494.3\">output:</text>\n<polyline fill=\"none\" points=\"655,-3486.5 655,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"713.5\" y=\"-3517.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"655,-3509.5 772,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"713.5\" y=\"-3494.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523819629816&#45;&gt;140523817142144 -->\n<g class=\"edge\" id=\"edge26\">\n<title>140523819629816-&gt;140523817142144</title>\n<path d=\"M448.0979,-3652.4017C461.4304,-3641.4105 477.5667,-3628.0629 492,-3616 522.7381,-3590.31 557.4988,-3560.902 582.7117,-3539.5067\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"585.1868,-3541.9967 590.545,-3532.8566 580.6565,-3536.6603 585.1868,-3541.9967\" stroke=\"#000000\"/>\n</g>\n<!-- 140523819444320 -->\n<g class=\"node\" id=\"node21\">\n<title>140523819444320</title>\n<polygon fill=\"none\" points=\"0,-3486.5 0,-3532.5 446,-3532.5 446,-3486.5 0,-3486.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-3505.8\">batch_normalization_6: BatchNormalization</text>\n<polyline fill=\"none\" points=\"271,-3486.5 271,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-3517.3\">input:</text>\n<polyline fill=\"none\" points=\"271,-3509.5 329,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-3494.3\">output:</text>\n<polyline fill=\"none\" points=\"329,-3486.5 329,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"387.5\" y=\"-3517.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"329,-3509.5 446,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"387.5\" y=\"-3494.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523819536056&#45;&gt;140523819444320 -->\n<g class=\"edge\" id=\"edge22\">\n<title>140523819536056-&gt;140523819444320</title>\n<path d=\"M299.4731,-3569.3799C287.5133,-3560.0151 273.555,-3549.0855 260.8614,-3539.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"262.7675,-3536.1934 252.7362,-3532.784 258.4519,-3541.7049 262.7675,-3536.1934\" stroke=\"#000000\"/>\n</g>\n<!-- 140523818866504 -->\n<g class=\"node\" id=\"node22\">\n<title>140523818866504</title>\n<polygon fill=\"none\" points=\"130.5,-3403.5 130.5,-3449.5 459.5,-3449.5 459.5,-3403.5 130.5,-3403.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"207.5\" y=\"-3422.8\">activation_6: Activation</text>\n<polyline fill=\"none\" points=\"284.5,-3403.5 284.5,-3449.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-3434.3\">input:</text>\n<polyline fill=\"none\" points=\"284.5,-3426.5 342.5,-3426.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-3411.3\">output:</text>\n<polyline fill=\"none\" points=\"342.5,-3403.5 342.5,-3449.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401\" y=\"-3434.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"342.5,-3426.5 459.5,-3426.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401\" y=\"-3411.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523819444320&#45;&gt;140523818866504 -->\n<g class=\"edge\" id=\"edge23\">\n<title>140523819444320-&gt;140523818866504</title>\n<path d=\"M243.056,-3486.3799C250.7928,-3477.461 259.7609,-3467.1229 268.0455,-3457.5725\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"270.8929,-3459.6314 274.8018,-3449.784 265.6052,-3455.0444 270.8929,-3459.6314\" stroke=\"#000000\"/>\n</g>\n<!-- 140523818604248 -->\n<g class=\"node\" id=\"node23\">\n<title>140523818604248</title>\n<polygon fill=\"none\" points=\"177,-3320.5 177,-3366.5 485,-3366.5 485,-3320.5 177,-3320.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.5\" y=\"-3339.8\">conv2d_7: Conv2D</text>\n<polyline fill=\"none\" points=\"310,-3320.5 310,-3366.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339\" y=\"-3351.3\">input:</text>\n<polyline fill=\"none\" points=\"310,-3343.5 368,-3343.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"339\" y=\"-3328.3\">output:</text>\n<polyline fill=\"none\" points=\"368,-3320.5 368,-3366.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-3351.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"368,-3343.5 485,-3343.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-3328.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523818866504&#45;&gt;140523818604248 -->\n<g class=\"edge\" id=\"edge24\">\n<title>140523818866504-&gt;140523818604248</title>\n<path d=\"M305.028,-3403.3799C308.703,-3394.907 312.9336,-3385.1531 316.899,-3376.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"320.1327,-3377.351 320.9009,-3366.784 313.7107,-3374.5655 320.1327,-3377.351\" stroke=\"#000000\"/>\n</g>\n<!-- 140523818404160 -->\n<g class=\"node\" id=\"node24\">\n<title>140523818404160</title>\n<polygon fill=\"none\" points=\"126,-3237.5 126,-3283.5 572,-3283.5 572,-3237.5 126,-3237.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261.5\" y=\"-3256.8\">batch_normalization_7: BatchNormalization</text>\n<polyline fill=\"none\" points=\"397,-3237.5 397,-3283.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426\" y=\"-3268.3\">input:</text>\n<polyline fill=\"none\" points=\"397,-3260.5 455,-3260.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426\" y=\"-3245.3\">output:</text>\n<polyline fill=\"none\" points=\"455,-3237.5 455,-3283.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"513.5\" y=\"-3268.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"455,-3260.5 572,-3260.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"513.5\" y=\"-3245.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523818604248&#45;&gt;140523818404160 -->\n<g class=\"edge\" id=\"edge25\">\n<title>140523818604248-&gt;140523818404160</title>\n<path d=\"M336.014,-3320.3799C337.8128,-3312.0854 339.8778,-3302.5633 341.8241,-3293.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"345.2515,-3294.2987 343.9505,-3283.784 338.4105,-3292.815 345.2515,-3294.2987\" stroke=\"#000000\"/>\n</g>\n<!-- 140523817998096 -->\n<g class=\"node\" id=\"node26\">\n<title>140523817998096</title>\n<polygon fill=\"none\" points=\"223.5,-3154.5 223.5,-3200.5 552.5,-3200.5 552.5,-3154.5 223.5,-3154.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300.5\" y=\"-3173.8\">activation_7: Activation</text>\n<polyline fill=\"none\" points=\"377.5,-3154.5 377.5,-3200.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"406.5\" y=\"-3185.3\">input:</text>\n<polyline fill=\"none\" points=\"377.5,-3177.5 435.5,-3177.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"406.5\" y=\"-3162.3\">output:</text>\n<polyline fill=\"none\" points=\"435.5,-3154.5 435.5,-3200.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"494\" y=\"-3185.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"435.5,-3177.5 552.5,-3177.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"494\" y=\"-3162.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523818404160&#45;&gt;140523817998096 -->\n<g class=\"edge\" id=\"edge27\">\n<title>140523818404160-&gt;140523817998096</title>\n<path d=\"M359.8637,-3237.3799C363.8449,-3228.907 368.428,-3219.1531 372.7239,-3210.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"375.9743,-3211.3231 377.0593,-3200.784 369.6388,-3208.3462 375.9743,-3211.3231\" stroke=\"#000000\"/>\n</g>\n<!-- 140523816965288 -->\n<g class=\"node\" id=\"node27\">\n<title>140523816965288</title>\n<polygon fill=\"none\" points=\"295.5,-3071.5 295.5,-3117.5 672.5,-3117.5 672.5,-3071.5 295.5,-3071.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-3090.8\">add_3: Add</text>\n<polyline fill=\"none\" points=\"380.5,-3071.5 380.5,-3117.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409.5\" y=\"-3102.3\">input:</text>\n<polyline fill=\"none\" points=\"380.5,-3094.5 438.5,-3094.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409.5\" y=\"-3079.3\">output:</text>\n<polyline fill=\"none\" points=\"438.5,-3071.5 438.5,-3117.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555.5\" y=\"-3102.3\">[(None, 8, 8, 128), (None, 8, 8, 128)]</text>\n<polyline fill=\"none\" points=\"438.5,-3094.5 672.5,-3094.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555.5\" y=\"-3079.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523817142144&#45;&gt;140523816965288 -->\n<g class=\"edge\" id=\"edge28\">\n<title>140523817142144-&gt;140523816965288</title>\n<path d=\"M615.9578,-3486.4266C613.3024,-3454.3843 609,-3394.5853 609,-3343.5 609,-3343.5 609,-3343.5 609,-3260.5 609,-3208.5813 593.1664,-3194.7539 561,-3154 552.1564,-3142.7954 540.7627,-3132.5055 529.4655,-3123.747\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"531.402,-3120.8249 521.2943,-3117.649 527.2153,-3126.4349 531.402,-3120.8249\" stroke=\"#000000\"/>\n</g>\n<!-- 140523817998096&#45;&gt;140523816965288 -->\n<g class=\"edge\" id=\"edge29\">\n<title>140523817998096-&gt;140523816965288</title>\n<path d=\"M414.7414,-3154.3799C425.4697,-3145.1043 437.9737,-3134.2936 449.3817,-3124.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"451.7935,-3126.972 457.0691,-3117.784 447.2153,-3121.6767 451.7935,-3126.972\" stroke=\"#000000\"/>\n</g>\n<!-- 140523817099336 -->\n<g class=\"node\" id=\"node28\">\n<title>140523817099336</title>\n<polygon fill=\"none\" points=\"239,-2988.5 239,-3034.5 547,-3034.5 547,-2988.5 239,-2988.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305.5\" y=\"-3007.8\">conv2d_9: Conv2D</text>\n<polyline fill=\"none\" points=\"372,-2988.5 372,-3034.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401\" y=\"-3019.3\">input:</text>\n<polyline fill=\"none\" points=\"372,-3011.5 430,-3011.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401\" y=\"-2996.3\">output:</text>\n<polyline fill=\"none\" points=\"430,-2988.5 430,-3034.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"488.5\" y=\"-3019.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"430,-3011.5 547,-3011.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"488.5\" y=\"-2996.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523816965288&#45;&gt;140523817099336 -->\n<g class=\"edge\" id=\"edge30\">\n<title>140523816965288-&gt;140523817099336</title>\n<path d=\"M458.6514,-3071.3799C448.5796,-3062.1935 436.8569,-3051.5013 426.1275,-3041.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"428.2752,-3038.9369 418.5282,-3034.784 423.558,-3044.1088 428.2752,-3038.9369\" stroke=\"#000000\"/>\n</g>\n<!-- 140523814676912 -->\n<g class=\"node\" id=\"node34\">\n<title>140523814676912</title>\n<polygon fill=\"none\" points=\"295.5,-2490.5 295.5,-2536.5 672.5,-2536.5 672.5,-2490.5 295.5,-2490.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-2509.8\">add_4: Add</text>\n<polyline fill=\"none\" points=\"380.5,-2490.5 380.5,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409.5\" y=\"-2521.3\">input:</text>\n<polyline fill=\"none\" points=\"380.5,-2513.5 438.5,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409.5\" y=\"-2498.3\">output:</text>\n<polyline fill=\"none\" points=\"438.5,-2490.5 438.5,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555.5\" y=\"-2521.3\">[(None, 8, 8, 128), (None, 8, 8, 128)]</text>\n<polyline fill=\"none\" points=\"438.5,-2513.5 672.5,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555.5\" y=\"-2498.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523816965288&#45;&gt;140523814676912 -->\n<g class=\"edge\" id=\"edge36\">\n<title>140523816965288-&gt;140523814676912</title>\n<path d=\"M517.1695,-3071.3952C554.2014,-3042.5963 609,-2989.6496 609,-2928.5 609,-2928.5 609,-2928.5 609,-2679.5 609,-2627.5813 593.1664,-2613.7539 561,-2573 552.1564,-2561.7954 540.7627,-2551.5055 529.4655,-2542.747\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"531.402,-2539.8249 521.2943,-2536.649 527.2153,-2545.4349 531.402,-2539.8249\" stroke=\"#000000\"/>\n</g>\n<!-- 140523816241024 -->\n<g class=\"node\" id=\"node29\">\n<title>140523816241024</title>\n<polygon fill=\"none\" points=\"135,-2905.5 135,-2951.5 581,-2951.5 581,-2905.5 135,-2905.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270.5\" y=\"-2924.8\">batch_normalization_8: BatchNormalization</text>\n<polyline fill=\"none\" points=\"406,-2905.5 406,-2951.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435\" y=\"-2936.3\">input:</text>\n<polyline fill=\"none\" points=\"406,-2928.5 464,-2928.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435\" y=\"-2913.3\">output:</text>\n<polyline fill=\"none\" points=\"464,-2905.5 464,-2951.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"522.5\" y=\"-2936.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"464,-2928.5 581,-2928.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"522.5\" y=\"-2913.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523817099336&#45;&gt;140523816241024 -->\n<g class=\"edge\" id=\"edge31\">\n<title>140523817099336-&gt;140523816241024</title>\n<path d=\"M383.2505,-2988.3799C379.6776,-2979.907 375.5646,-2970.1531 371.7093,-2961.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"374.9291,-2959.6383 367.8186,-2951.784 368.4792,-2962.3582 374.9291,-2959.6383\" stroke=\"#000000\"/>\n</g>\n<!-- 140523816239736 -->\n<g class=\"node\" id=\"node30\">\n<title>140523816239736</title>\n<polygon fill=\"none\" points=\"193.5,-2822.5 193.5,-2868.5 522.5,-2868.5 522.5,-2822.5 193.5,-2822.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270.5\" y=\"-2841.8\">activation_8: Activation</text>\n<polyline fill=\"none\" points=\"347.5,-2822.5 347.5,-2868.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376.5\" y=\"-2853.3\">input:</text>\n<polyline fill=\"none\" points=\"347.5,-2845.5 405.5,-2845.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376.5\" y=\"-2830.3\">output:</text>\n<polyline fill=\"none\" points=\"405.5,-2822.5 405.5,-2868.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"464\" y=\"-2853.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"405.5,-2845.5 522.5,-2845.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"464\" y=\"-2830.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523816241024&#45;&gt;140523816239736 -->\n<g class=\"edge\" id=\"edge32\">\n<title>140523816241024-&gt;140523816239736</title>\n<path d=\"M358,-2905.3799C358,-2897.1745 358,-2887.7679 358,-2878.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"361.5001,-2878.784 358,-2868.784 354.5001,-2878.784 361.5001,-2878.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523815912336 -->\n<g class=\"node\" id=\"node31\">\n<title>140523815912336</title>\n<polygon fill=\"none\" points=\"200.5,-2739.5 200.5,-2785.5 515.5,-2785.5 515.5,-2739.5 200.5,-2739.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270.5\" y=\"-2758.8\">conv2d_10: Conv2D</text>\n<polyline fill=\"none\" points=\"340.5,-2739.5 340.5,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369.5\" y=\"-2770.3\">input:</text>\n<polyline fill=\"none\" points=\"340.5,-2762.5 398.5,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369.5\" y=\"-2747.3\">output:</text>\n<polyline fill=\"none\" points=\"398.5,-2739.5 398.5,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"457\" y=\"-2770.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"398.5,-2762.5 515.5,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"457\" y=\"-2747.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523816239736&#45;&gt;140523815912336 -->\n<g class=\"edge\" id=\"edge33\">\n<title>140523816239736-&gt;140523815912336</title>\n<path d=\"M358,-2822.3799C358,-2814.1745 358,-2804.7679 358,-2795.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"361.5001,-2795.784 358,-2785.784 354.5001,-2795.784 361.5001,-2795.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523815386024 -->\n<g class=\"node\" id=\"node32\">\n<title>140523815386024</title>\n<polygon fill=\"none\" points=\"135,-2656.5 135,-2702.5 581,-2702.5 581,-2656.5 135,-2656.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270.5\" y=\"-2675.8\">batch_normalization_9: BatchNormalization</text>\n<polyline fill=\"none\" points=\"406,-2656.5 406,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435\" y=\"-2687.3\">input:</text>\n<polyline fill=\"none\" points=\"406,-2679.5 464,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435\" y=\"-2664.3\">output:</text>\n<polyline fill=\"none\" points=\"464,-2656.5 464,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"522.5\" y=\"-2687.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"464,-2679.5 581,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"522.5\" y=\"-2664.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523815912336&#45;&gt;140523815386024 -->\n<g class=\"edge\" id=\"edge34\">\n<title>140523815912336-&gt;140523815386024</title>\n<path d=\"M358,-2739.3799C358,-2731.1745 358,-2721.7679 358,-2712.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"361.5001,-2712.784 358,-2702.784 354.5001,-2712.784 361.5001,-2712.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523815703328 -->\n<g class=\"node\" id=\"node33\">\n<title>140523815703328</title>\n<polygon fill=\"none\" points=\"223.5,-2573.5 223.5,-2619.5 552.5,-2619.5 552.5,-2573.5 223.5,-2573.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300.5\" y=\"-2592.8\">activation_9: Activation</text>\n<polyline fill=\"none\" points=\"377.5,-2573.5 377.5,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"406.5\" y=\"-2604.3\">input:</text>\n<polyline fill=\"none\" points=\"377.5,-2596.5 435.5,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"406.5\" y=\"-2581.3\">output:</text>\n<polyline fill=\"none\" points=\"435.5,-2573.5 435.5,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"494\" y=\"-2604.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"435.5,-2596.5 552.5,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"494\" y=\"-2581.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140523815386024&#45;&gt;140523815703328 -->\n<g class=\"edge\" id=\"edge35\">\n<title>140523815386024-&gt;140523815703328</title>\n<path d=\"M366.3567,-2656.3799C369.3869,-2647.9962 372.8705,-2638.3584 376.1447,-2629.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"379.4764,-2630.3783 379.5841,-2619.784 372.8932,-2627.9988 379.4764,-2630.3783\" stroke=\"#000000\"/>\n</g>\n<!-- 140523815703328&#45;&gt;140523814676912 -->\n<g class=\"edge\" id=\"edge37\">\n<title>140523815703328-&gt;140523814676912</title>\n<path d=\"M414.7414,-2573.3799C425.4697,-2564.1043 437.9737,-2553.2936 449.3817,-2543.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"451.7935,-2545.972 457.0691,-2536.784 447.2153,-2540.6767 451.7935,-2545.972\" stroke=\"#000000\"/>\n</g>\n<!-- 140523814881376 -->\n<g class=\"node\" id=\"node35\">\n<title>140523814881376</title>\n<polygon fill=\"none\" points=\"233.5,-2407.5 233.5,-2453.5 548.5,-2453.5 548.5,-2407.5 233.5,-2407.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-2426.8\">conv2d_11: Conv2D</text>\n<polyline fill=\"none\" points=\"373.5,-2407.5 373.5,-2453.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402.5\" y=\"-2438.3\">input:</text>\n<polyline fill=\"none\" points=\"373.5,-2430.5 431.5,-2430.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402.5\" y=\"-2415.3\">output:</text>\n<polyline fill=\"none\" points=\"431.5,-2407.5 431.5,-2453.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490\" y=\"-2438.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"431.5,-2430.5 548.5,-2430.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490\" y=\"-2415.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523814676912&#45;&gt;140523814881376 -->\n<g class=\"edge\" id=\"edge38\">\n<title>140523814676912-&gt;140523814881376</title>\n<path d=\"M458.0943,-2490.3799C447.8011,-2481.1935 435.8208,-2470.5013 424.8556,-2460.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"426.8806,-2457.8313 417.0893,-2453.784 422.2196,-2463.0539 426.8806,-2457.8313\" stroke=\"#000000\"/>\n</g>\n<!-- 140523476706864 -->\n<g class=\"node\" id=\"node40\">\n<title>140523476706864</title>\n<polygon fill=\"none\" points=\"527.5,-2324.5 527.5,-2370.5 842.5,-2370.5 842.5,-2324.5 527.5,-2324.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"597.5\" y=\"-2343.8\">conv2d_13: Conv2D</text>\n<polyline fill=\"none\" points=\"667.5,-2324.5 667.5,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"696.5\" y=\"-2355.3\">input:</text>\n<polyline fill=\"none\" points=\"667.5,-2347.5 725.5,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"696.5\" y=\"-2332.3\">output:</text>\n<polyline fill=\"none\" points=\"725.5,-2324.5 725.5,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"784\" y=\"-2355.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"725.5,-2347.5 842.5,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"784\" y=\"-2332.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523814676912&#45;&gt;140523476706864 -->\n<g class=\"edge\" id=\"edge43\">\n<title>140523814676912-&gt;140523476706864</title>\n<path d=\"M512.9284,-2490.467C526.6422,-2479.49 543.2216,-2466.1356 558,-2454 589.3036,-2428.2944 624.5803,-2398.6575 649.9962,-2377.1849\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"652.5077,-2379.6448 657.884,-2370.5155 647.988,-2374.2995 652.5077,-2379.6448\" stroke=\"#000000\"/>\n</g>\n<!-- 140523814270792 -->\n<g class=\"node\" id=\"node36\">\n<title>140523814270792</title>\n<polygon fill=\"none\" points=\"56.5,-2324.5 56.5,-2370.5 509.5,-2370.5 509.5,-2324.5 56.5,-2324.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-2343.8\">batch_normalization_10: BatchNormalization</text>\n<polyline fill=\"none\" points=\"334.5,-2324.5 334.5,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363.5\" y=\"-2355.3\">input:</text>\n<polyline fill=\"none\" points=\"334.5,-2347.5 392.5,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363.5\" y=\"-2332.3\">output:</text>\n<polyline fill=\"none\" points=\"392.5,-2324.5 392.5,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451\" y=\"-2355.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"392.5,-2347.5 509.5,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451\" y=\"-2332.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523814881376&#45;&gt;140523814270792 -->\n<g class=\"edge\" id=\"edge39\">\n<title>140523814881376-&gt;140523814270792</title>\n<path d=\"M360.916,-2407.3799C348.7305,-2398.0151 334.5089,-2387.0855 321.5757,-2377.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"323.359,-2374.1025 313.2973,-2370.784 319.0935,-2379.6527 323.359,-2374.1025\" stroke=\"#000000\"/>\n</g>\n<!-- 140523814217208 -->\n<g class=\"node\" id=\"node37\">\n<title>140523814217208</title>\n<polygon fill=\"none\" points=\"189,-2241.5 189,-2287.5 525,-2287.5 525,-2241.5 189,-2241.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269.5\" y=\"-2260.8\">activation_10: Activation</text>\n<polyline fill=\"none\" points=\"350,-2241.5 350,-2287.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379\" y=\"-2272.3\">input:</text>\n<polyline fill=\"none\" points=\"350,-2264.5 408,-2264.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379\" y=\"-2249.3\">output:</text>\n<polyline fill=\"none\" points=\"408,-2241.5 408,-2287.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"466.5\" y=\"-2272.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"408,-2264.5 525,-2264.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"466.5\" y=\"-2249.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523814270792&#45;&gt;140523814217208 -->\n<g class=\"edge\" id=\"edge40\">\n<title>140523814270792-&gt;140523814217208</title>\n<path d=\"M303.6131,-2324.3799C311.6444,-2315.3718 320.9665,-2304.916 329.552,-2295.2863\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"332.1984,-2297.5774 336.2408,-2287.784 326.9735,-2292.919 332.1984,-2297.5774\" stroke=\"#000000\"/>\n</g>\n<!-- 140523478136368 -->\n<g class=\"node\" id=\"node38\">\n<title>140523478136368</title>\n<polygon fill=\"none\" points=\"236.5,-2158.5 236.5,-2204.5 551.5,-2204.5 551.5,-2158.5 236.5,-2158.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"306.5\" y=\"-2177.8\">conv2d_12: Conv2D</text>\n<polyline fill=\"none\" points=\"376.5,-2158.5 376.5,-2204.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-2189.3\">input:</text>\n<polyline fill=\"none\" points=\"376.5,-2181.5 434.5,-2181.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-2166.3\">output:</text>\n<polyline fill=\"none\" points=\"434.5,-2158.5 434.5,-2204.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"493\" y=\"-2189.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"434.5,-2181.5 551.5,-2181.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"493\" y=\"-2166.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523814217208&#45;&gt;140523478136368 -->\n<g class=\"edge\" id=\"edge41\">\n<title>140523814217208-&gt;140523478136368</title>\n<path d=\"M367.3066,-2241.3799C371.0836,-2232.907 375.4317,-2223.1531 379.5073,-2214.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"382.7455,-2215.3427 383.6204,-2204.784 376.352,-2212.4925 382.7455,-2215.3427\" stroke=\"#000000\"/>\n</g>\n<!-- 140523477424168 -->\n<g class=\"node\" id=\"node39\">\n<title>140523477424168</title>\n<polygon fill=\"none\" points=\"185.5,-2075.5 185.5,-2121.5 638.5,-2121.5 638.5,-2075.5 185.5,-2075.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.5\" y=\"-2094.8\">batch_normalization_11: BatchNormalization</text>\n<polyline fill=\"none\" points=\"463.5,-2075.5 463.5,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-2106.3\">input:</text>\n<polyline fill=\"none\" points=\"463.5,-2098.5 521.5,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-2083.3\">output:</text>\n<polyline fill=\"none\" points=\"521.5,-2075.5 521.5,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"580\" y=\"-2106.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"521.5,-2098.5 638.5,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"580\" y=\"-2083.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523478136368&#45;&gt;140523477424168 -->\n<g class=\"edge\" id=\"edge42\">\n<title>140523478136368-&gt;140523477424168</title>\n<path d=\"M399.014,-2158.3799C400.8128,-2150.0854 402.8778,-2140.5633 404.8241,-2131.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.2515,-2132.2987 406.9505,-2121.784 401.4105,-2130.815 408.2515,-2132.2987\" stroke=\"#000000\"/>\n</g>\n<!-- 140523477542392 -->\n<g class=\"node\" id=\"node41\">\n<title>140523477542392</title>\n<polygon fill=\"none\" points=\"282,-1992.5 282,-2038.5 618,-2038.5 618,-1992.5 282,-1992.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362.5\" y=\"-2011.8\">activation_11: Activation</text>\n<polyline fill=\"none\" points=\"443,-1992.5 443,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472\" y=\"-2023.3\">input:</text>\n<polyline fill=\"none\" points=\"443,-2015.5 501,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472\" y=\"-2000.3\">output:</text>\n<polyline fill=\"none\" points=\"501,-1992.5 501,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559.5\" y=\"-2023.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"501,-2015.5 618,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559.5\" y=\"-2000.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523477424168&#45;&gt;140523477542392 -->\n<g class=\"edge\" id=\"edge44\">\n<title>140523477424168-&gt;140523477542392</title>\n<path d=\"M422.5851,-2075.3799C426.4643,-2066.907 430.9299,-2057.1531 435.1156,-2048.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"438.3594,-2049.3334 439.3399,-2038.784 431.9947,-2046.4194 438.3594,-2049.3334\" stroke=\"#000000\"/>\n</g>\n<!-- 140523476175448 -->\n<g class=\"node\" id=\"node42\">\n<title>140523476175448</title>\n<polygon fill=\"none\" points=\"359.5,-1909.5 359.5,-1955.5 736.5,-1955.5 736.5,-1909.5 359.5,-1909.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-1928.8\">add_5: Add</text>\n<polyline fill=\"none\" points=\"444.5,-1909.5 444.5,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473.5\" y=\"-1940.3\">input:</text>\n<polyline fill=\"none\" points=\"444.5,-1932.5 502.5,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473.5\" y=\"-1917.3\">output:</text>\n<polyline fill=\"none\" points=\"502.5,-1909.5 502.5,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"619.5\" y=\"-1940.3\">[(None, 8, 8, 256), (None, 8, 8, 256)]</text>\n<polyline fill=\"none\" points=\"502.5,-1932.5 736.5,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"619.5\" y=\"-1917.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523476706864&#45;&gt;140523476175448 -->\n<g class=\"edge\" id=\"edge45\">\n<title>140523476706864-&gt;140523476175448</title>\n<path d=\"M682.7308,-2324.4316C679.7804,-2292.3951 675,-2232.6029 675,-2181.5 675,-2181.5 675,-2181.5 675,-2098.5 675,-2046.5813 659.4178,-2032.5542 627,-1992 618.0279,-1980.776 606.4794,-1970.5318 594.9978,-1961.8263\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"596.8294,-1958.8302 586.687,-1955.7672 592.7056,-1964.4866 596.8294,-1958.8302\" stroke=\"#000000\"/>\n</g>\n<!-- 140523477542392&#45;&gt;140523476175448 -->\n<g class=\"edge\" id=\"edge46\">\n<title>140523477542392-&gt;140523476175448</title>\n<path d=\"M477.2985,-1992.3799C488.2504,-1983.1043 501.0148,-1972.2936 512.6605,-1962.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"515.1391,-1964.9178 520.508,-1955.784 510.6151,-1959.5761 515.1391,-1964.9178\" stroke=\"#000000\"/>\n</g>\n<!-- 140523476518448 -->\n<g class=\"node\" id=\"node43\">\n<title>140523476518448</title>\n<polygon fill=\"none\" points=\"297.5,-1826.5 297.5,-1872.5 612.5,-1872.5 612.5,-1826.5 297.5,-1826.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"367.5\" y=\"-1845.8\">conv2d_14: Conv2D</text>\n<polyline fill=\"none\" points=\"437.5,-1826.5 437.5,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"466.5\" y=\"-1857.3\">input:</text>\n<polyline fill=\"none\" points=\"437.5,-1849.5 495.5,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"466.5\" y=\"-1834.3\">output:</text>\n<polyline fill=\"none\" points=\"495.5,-1826.5 495.5,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"554\" y=\"-1857.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"495.5,-1849.5 612.5,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"554\" y=\"-1834.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523476175448&#45;&gt;140523476518448 -->\n<g class=\"edge\" id=\"edge47\">\n<title>140523476175448-&gt;140523476518448</title>\n<path d=\"M522.0943,-1909.3799C511.8011,-1900.1935 499.8208,-1889.5013 488.8556,-1879.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"490.8806,-1876.8313 481.0893,-1872.784 486.2196,-1882.0539 490.8806,-1876.8313\" stroke=\"#000000\"/>\n</g>\n<!-- 140523477113320 -->\n<g class=\"node\" id=\"node49\">\n<title>140523477113320</title>\n<polygon fill=\"none\" points=\"359.5,-1328.5 359.5,-1374.5 736.5,-1374.5 736.5,-1328.5 359.5,-1328.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-1347.8\">add_6: Add</text>\n<polyline fill=\"none\" points=\"444.5,-1328.5 444.5,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473.5\" y=\"-1359.3\">input:</text>\n<polyline fill=\"none\" points=\"444.5,-1351.5 502.5,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473.5\" y=\"-1336.3\">output:</text>\n<polyline fill=\"none\" points=\"502.5,-1328.5 502.5,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"619.5\" y=\"-1359.3\">[(None, 8, 8, 256), (None, 8, 8, 256)]</text>\n<polyline fill=\"none\" points=\"502.5,-1351.5 736.5,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"619.5\" y=\"-1336.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523476175448&#45;&gt;140523477113320 -->\n<g class=\"edge\" id=\"edge53\">\n<title>140523476175448-&gt;140523477113320</title>\n<path d=\"M582.0337,-1909.2627C619.6526,-1880.525 675,-1827.824 675,-1766.5 675,-1766.5 675,-1766.5 675,-1517.5 675,-1465.5813 659.4178,-1451.5542 627,-1411 618.0279,-1399.776 606.4794,-1389.5318 594.9978,-1380.8263\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"596.8294,-1377.8302 586.687,-1374.7672 592.7056,-1383.4866 596.8294,-1377.8302\" stroke=\"#000000\"/>\n</g>\n<!-- 140523475781168 -->\n<g class=\"node\" id=\"node44\">\n<title>140523475781168</title>\n<polygon fill=\"none\" points=\"194.5,-1743.5 194.5,-1789.5 647.5,-1789.5 647.5,-1743.5 194.5,-1743.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1762.8\">batch_normalization_12: BatchNormalization</text>\n<polyline fill=\"none\" points=\"472.5,-1743.5 472.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501.5\" y=\"-1774.3\">input:</text>\n<polyline fill=\"none\" points=\"472.5,-1766.5 530.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501.5\" y=\"-1751.3\">output:</text>\n<polyline fill=\"none\" points=\"530.5,-1743.5 530.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589\" y=\"-1774.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"530.5,-1766.5 647.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589\" y=\"-1751.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523476518448&#45;&gt;140523475781168 -->\n<g class=\"edge\" id=\"edge48\">\n<title>140523476518448-&gt;140523475781168</title>\n<path d=\"M445.5291,-1826.3799C442.0948,-1817.9962 438.1468,-1808.3584 434.436,-1799.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"437.5676,-1797.7109 430.538,-1789.784 431.09,-1800.3645 437.5676,-1797.7109\" stroke=\"#000000\"/>\n</g>\n<!-- 140523475779880 -->\n<g class=\"node\" id=\"node45\">\n<title>140523475779880</title>\n<polygon fill=\"none\" points=\"253,-1660.5 253,-1706.5 589,-1706.5 589,-1660.5 253,-1660.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1679.8\">activation_12: Activation</text>\n<polyline fill=\"none\" points=\"414,-1660.5 414,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-1691.3\">input:</text>\n<polyline fill=\"none\" points=\"414,-1683.5 472,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-1668.3\">output:</text>\n<polyline fill=\"none\" points=\"472,-1660.5 472,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-1691.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"472,-1683.5 589,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-1668.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523475781168&#45;&gt;140523475779880 -->\n<g class=\"edge\" id=\"edge49\">\n<title>140523475781168-&gt;140523475779880</title>\n<path d=\"M421,-1743.3799C421,-1735.1745 421,-1725.7679 421,-1716.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"424.5001,-1716.784 421,-1706.784 417.5001,-1716.784 424.5001,-1716.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523475460672 -->\n<g class=\"node\" id=\"node46\">\n<title>140523475460672</title>\n<polygon fill=\"none\" points=\"263.5,-1577.5 263.5,-1623.5 578.5,-1623.5 578.5,-1577.5 263.5,-1577.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1596.8\">conv2d_15: Conv2D</text>\n<polyline fill=\"none\" points=\"403.5,-1577.5 403.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"432.5\" y=\"-1608.3\">input:</text>\n<polyline fill=\"none\" points=\"403.5,-1600.5 461.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"432.5\" y=\"-1585.3\">output:</text>\n<polyline fill=\"none\" points=\"461.5,-1577.5 461.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"520\" y=\"-1608.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"461.5,-1600.5 578.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"520\" y=\"-1585.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523475779880&#45;&gt;140523475460672 -->\n<g class=\"edge\" id=\"edge50\">\n<title>140523475779880-&gt;140523475460672</title>\n<path d=\"M421,-1660.3799C421,-1652.1745 421,-1642.7679 421,-1633.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"424.5001,-1633.784 421,-1623.784 417.5001,-1633.784 424.5001,-1633.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523474950744 -->\n<g class=\"node\" id=\"node47\">\n<title>140523474950744</title>\n<polygon fill=\"none\" points=\"194.5,-1494.5 194.5,-1540.5 647.5,-1540.5 647.5,-1494.5 194.5,-1494.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1513.8\">batch_normalization_13: BatchNormalization</text>\n<polyline fill=\"none\" points=\"472.5,-1494.5 472.5,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501.5\" y=\"-1525.3\">input:</text>\n<polyline fill=\"none\" points=\"472.5,-1517.5 530.5,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501.5\" y=\"-1502.3\">output:</text>\n<polyline fill=\"none\" points=\"530.5,-1494.5 530.5,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589\" y=\"-1525.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"530.5,-1517.5 647.5,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589\" y=\"-1502.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523475460672&#45;&gt;140523474950744 -->\n<g class=\"edge\" id=\"edge51\">\n<title>140523475460672-&gt;140523474950744</title>\n<path d=\"M421,-1577.3799C421,-1569.1745 421,-1559.7679 421,-1550.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"424.5001,-1550.784 421,-1540.784 417.5001,-1550.784 424.5001,-1550.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523475272648 -->\n<g class=\"node\" id=\"node48\">\n<title>140523475272648</title>\n<polygon fill=\"none\" points=\"282,-1411.5 282,-1457.5 618,-1457.5 618,-1411.5 282,-1411.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"362.5\" y=\"-1430.8\">activation_13: Activation</text>\n<polyline fill=\"none\" points=\"443,-1411.5 443,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472\" y=\"-1442.3\">input:</text>\n<polyline fill=\"none\" points=\"443,-1434.5 501,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472\" y=\"-1419.3\">output:</text>\n<polyline fill=\"none\" points=\"501,-1411.5 501,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559.5\" y=\"-1442.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"501,-1434.5 618,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559.5\" y=\"-1419.3\">(None, 8, 8, 256)</text>\n</g>\n<!-- 140523474950744&#45;&gt;140523475272648 -->\n<g class=\"edge\" id=\"edge52\">\n<title>140523474950744-&gt;140523475272648</title>\n<path d=\"M429.0781,-1494.3799C432.0074,-1485.9962 435.3748,-1476.3584 438.5399,-1467.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"441.8702,-1468.3788 441.8646,-1457.784 435.262,-1466.0699 441.8702,-1468.3788\" stroke=\"#000000\"/>\n</g>\n<!-- 140523475272648&#45;&gt;140523477113320 -->\n<g class=\"edge\" id=\"edge54\">\n<title>140523475272648-&gt;140523477113320</title>\n<path d=\"M477.2985,-1411.3799C488.2504,-1402.1043 501.0148,-1391.2936 512.6605,-1381.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"515.1391,-1383.9178 520.508,-1374.784 510.6151,-1378.5761 515.1391,-1383.9178\" stroke=\"#000000\"/>\n</g>\n<!-- 140523474419048 -->\n<g class=\"node\" id=\"node50\">\n<title>140523474419048</title>\n<polygon fill=\"none\" points=\"297.5,-1245.5 297.5,-1291.5 612.5,-1291.5 612.5,-1245.5 297.5,-1245.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"367.5\" y=\"-1264.8\">conv2d_16: Conv2D</text>\n<polyline fill=\"none\" points=\"437.5,-1245.5 437.5,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"466.5\" y=\"-1276.3\">input:</text>\n<polyline fill=\"none\" points=\"437.5,-1268.5 495.5,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"466.5\" y=\"-1253.3\">output:</text>\n<polyline fill=\"none\" points=\"495.5,-1245.5 495.5,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"554\" y=\"-1276.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"495.5,-1268.5 612.5,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"554\" y=\"-1253.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523477113320&#45;&gt;140523474419048 -->\n<g class=\"edge\" id=\"edge55\">\n<title>140523477113320-&gt;140523474419048</title>\n<path d=\"M522.0943,-1328.3799C511.8011,-1319.1935 499.8208,-1308.5013 488.8556,-1298.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"490.8806,-1295.8313 481.0893,-1291.784 486.2196,-1301.0539 490.8806,-1295.8313\" stroke=\"#000000\"/>\n</g>\n<!-- 140523471975648 -->\n<g class=\"node\" id=\"node55\">\n<title>140523471975648</title>\n<polygon fill=\"none\" points=\"591.5,-1162.5 591.5,-1208.5 906.5,-1208.5 906.5,-1162.5 591.5,-1162.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"661.5\" y=\"-1181.8\">conv2d_18: Conv2D</text>\n<polyline fill=\"none\" points=\"731.5,-1162.5 731.5,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"760.5\" y=\"-1193.3\">input:</text>\n<polyline fill=\"none\" points=\"731.5,-1185.5 789.5,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"760.5\" y=\"-1170.3\">output:</text>\n<polyline fill=\"none\" points=\"789.5,-1162.5 789.5,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848\" y=\"-1193.3\">(None, 8, 8, 256)</text>\n<polyline fill=\"none\" points=\"789.5,-1185.5 906.5,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"848\" y=\"-1170.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523477113320&#45;&gt;140523471975648 -->\n<g class=\"edge\" id=\"edge60\">\n<title>140523477113320-&gt;140523471975648</title>\n<path d=\"M576.9284,-1328.467C590.6422,-1317.49 607.2216,-1304.1356 622,-1292 653.3036,-1266.2944 688.5803,-1236.6575 713.9962,-1215.1849\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"716.5077,-1217.6448 721.884,-1208.5155 711.988,-1212.2995 716.5077,-1217.6448\" stroke=\"#000000\"/>\n</g>\n<!-- 140523473819464 -->\n<g class=\"node\" id=\"node51\">\n<title>140523473819464</title>\n<polygon fill=\"none\" points=\"120.5,-1162.5 120.5,-1208.5 573.5,-1208.5 573.5,-1162.5 120.5,-1162.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.5\" y=\"-1181.8\">batch_normalization_14: BatchNormalization</text>\n<polyline fill=\"none\" points=\"398.5,-1162.5 398.5,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"427.5\" y=\"-1193.3\">input:</text>\n<polyline fill=\"none\" points=\"398.5,-1185.5 456.5,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"427.5\" y=\"-1170.3\">output:</text>\n<polyline fill=\"none\" points=\"456.5,-1162.5 456.5,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"515\" y=\"-1193.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"456.5,-1185.5 573.5,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"515\" y=\"-1170.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523474419048&#45;&gt;140523473819464 -->\n<g class=\"edge\" id=\"edge56\">\n<title>140523474419048-&gt;140523473819464</title>\n<path d=\"M424.916,-1245.3799C412.7305,-1236.0151 398.5089,-1225.0855 385.5757,-1215.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"387.359,-1212.1025 377.2973,-1208.784 383.0935,-1217.6527 387.359,-1212.1025\" stroke=\"#000000\"/>\n</g>\n<!-- 140523473257752 -->\n<g class=\"node\" id=\"node52\">\n<title>140523473257752</title>\n<polygon fill=\"none\" points=\"253,-1079.5 253,-1125.5 589,-1125.5 589,-1079.5 253,-1079.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-1098.8\">activation_14: Activation</text>\n<polyline fill=\"none\" points=\"414,-1079.5 414,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-1110.3\">input:</text>\n<polyline fill=\"none\" points=\"414,-1102.5 472,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-1087.3\">output:</text>\n<polyline fill=\"none\" points=\"472,-1079.5 472,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-1110.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"472,-1102.5 589,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-1087.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523473819464&#45;&gt;140523473257752 -->\n<g class=\"edge\" id=\"edge57\">\n<title>140523473819464-&gt;140523473257752</title>\n<path d=\"M367.6131,-1162.3799C375.6444,-1153.3718 384.9665,-1142.916 393.552,-1133.2863\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"396.1984,-1135.5774 400.2408,-1125.784 390.9735,-1130.919 396.1984,-1135.5774\" stroke=\"#000000\"/>\n</g>\n<!-- 140523472968000 -->\n<g class=\"node\" id=\"node53\">\n<title>140523472968000</title>\n<polygon fill=\"none\" points=\"300.5,-996.5 300.5,-1042.5 615.5,-1042.5 615.5,-996.5 300.5,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"370.5\" y=\"-1015.8\">conv2d_17: Conv2D</text>\n<polyline fill=\"none\" points=\"440.5,-996.5 440.5,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"469.5\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"440.5,-1019.5 498.5,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"469.5\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"498.5,-996.5 498.5,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557\" y=\"-1027.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"498.5,-1019.5 615.5,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557\" y=\"-1004.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523473257752&#45;&gt;140523472968000 -->\n<g class=\"edge\" id=\"edge58\">\n<title>140523473257752-&gt;140523472968000</title>\n<path d=\"M431.3066,-1079.3799C435.0836,-1070.907 439.4317,-1061.1531 443.5073,-1052.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"446.7455,-1053.3427 447.6204,-1042.784 440.352,-1050.4925 446.7455,-1053.3427\" stroke=\"#000000\"/>\n</g>\n<!-- 140523472787104 -->\n<g class=\"node\" id=\"node54\">\n<title>140523472787104</title>\n<polygon fill=\"none\" points=\"249.5,-913.5 249.5,-959.5 702.5,-959.5 702.5,-913.5 249.5,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388.5\" y=\"-932.8\">batch_normalization_15: BatchNormalization</text>\n<polyline fill=\"none\" points=\"527.5,-913.5 527.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"556.5\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"527.5,-936.5 585.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"556.5\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"585.5,-913.5 585.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"644\" y=\"-944.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"585.5,-936.5 702.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"644\" y=\"-921.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523472968000&#45;&gt;140523472787104 -->\n<g class=\"edge\" id=\"edge59\">\n<title>140523472968000-&gt;140523472787104</title>\n<path d=\"M463.014,-996.3799C464.8128,-988.0854 466.8778,-978.5633 468.8241,-969.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"472.2515,-970.2987 470.9505,-959.784 465.4105,-968.815 472.2515,-970.2987\" stroke=\"#000000\"/>\n</g>\n<!-- 140523472909424 -->\n<g class=\"node\" id=\"node56\">\n<title>140523472909424</title>\n<polygon fill=\"none\" points=\"346,-830.5 346,-876.5 682,-876.5 682,-830.5 346,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-849.8\">activation_15: Activation</text>\n<polyline fill=\"none\" points=\"507,-830.5 507,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"536\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"507,-853.5 565,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"536\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"565,-830.5 565,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623.5\" y=\"-861.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"565,-853.5 682,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623.5\" y=\"-838.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523472787104&#45;&gt;140523472909424 -->\n<g class=\"edge\" id=\"edge61\">\n<title>140523472787104-&gt;140523472909424</title>\n<path d=\"M486.5851,-913.3799C490.4643,-904.907 494.9299,-895.1531 499.1156,-886.0107\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"502.3594,-887.3334 503.3399,-876.784 495.9947,-884.4194 502.3594,-887.3334\" stroke=\"#000000\"/>\n</g>\n<!-- 140523471513864 -->\n<g class=\"node\" id=\"node57\">\n<title>140523471513864</title>\n<polygon fill=\"none\" points=\"423.5,-747.5 423.5,-793.5 800.5,-793.5 800.5,-747.5 423.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"466\" y=\"-766.8\">add_7: Add</text>\n<polyline fill=\"none\" points=\"508.5,-747.5 508.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"537.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"508.5,-770.5 566.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"537.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"566.5,-747.5 566.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"683.5\" y=\"-778.3\">[(None, 8, 8, 512), (None, 8, 8, 512)]</text>\n<polyline fill=\"none\" points=\"566.5,-770.5 800.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"683.5\" y=\"-755.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523471975648&#45;&gt;140523471513864 -->\n<g class=\"edge\" id=\"edge62\">\n<title>140523471975648-&gt;140523471513864</title>\n<path d=\"M746.7308,-1162.4316C743.7804,-1130.3951 739,-1070.6029 739,-1019.5 739,-1019.5 739,-1019.5 739,-936.5 739,-884.5813 723.4178,-870.5542 691,-830 682.0279,-818.776 670.4794,-808.5318 658.9978,-799.8263\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"660.8294,-796.8302 650.687,-793.7672 656.7056,-802.4866 660.8294,-796.8302\" stroke=\"#000000\"/>\n</g>\n<!-- 140523472909424&#45;&gt;140523471513864 -->\n<g class=\"edge\" id=\"edge63\">\n<title>140523472909424-&gt;140523471513864</title>\n<path d=\"M541.2985,-830.3799C552.2504,-821.1043 565.0148,-810.2936 576.6605,-800.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"579.1391,-802.9178 584.508,-793.784 574.6151,-797.5761 579.1391,-802.9178\" stroke=\"#000000\"/>\n</g>\n<!-- 140523471826616 -->\n<g class=\"node\" id=\"node58\">\n<title>140523471826616</title>\n<polygon fill=\"none\" points=\"361.5,-664.5 361.5,-710.5 676.5,-710.5 676.5,-664.5 361.5,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"431.5\" y=\"-683.8\">conv2d_19: Conv2D</text>\n<polyline fill=\"none\" points=\"501.5,-664.5 501.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"501.5,-687.5 559.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"559.5,-664.5 559.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"618\" y=\"-695.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"559.5,-687.5 676.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"618\" y=\"-672.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523471513864&#45;&gt;140523471826616 -->\n<g class=\"edge\" id=\"edge64\">\n<title>140523471513864-&gt;140523471826616</title>\n<path d=\"M586.0943,-747.3799C575.8011,-738.1935 563.8208,-727.5013 552.8556,-717.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"554.8806,-714.8313 545.0893,-710.784 550.2196,-720.0539 554.8806,-714.8313\" stroke=\"#000000\"/>\n</g>\n<!-- 140523469765152 -->\n<g class=\"node\" id=\"node64\">\n<title>140523469765152</title>\n<polygon fill=\"none\" points=\"423.5,-166.5 423.5,-212.5 800.5,-212.5 800.5,-166.5 423.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"466\" y=\"-185.8\">add_8: Add</text>\n<polyline fill=\"none\" points=\"508.5,-166.5 508.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"537.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"508.5,-189.5 566.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"537.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"566.5,-166.5 566.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"683.5\" y=\"-197.3\">[(None, 8, 8, 512), (None, 8, 8, 512)]</text>\n<polyline fill=\"none\" points=\"566.5,-189.5 800.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"683.5\" y=\"-174.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523471513864&#45;&gt;140523469765152 -->\n<g class=\"edge\" id=\"edge70\">\n<title>140523471513864-&gt;140523469765152</title>\n<path d=\"M646.0337,-747.2627C683.6526,-718.525 739,-665.824 739,-604.5 739,-604.5 739,-604.5 739,-355.5 739,-303.5813 723.4178,-289.5542 691,-249 682.0279,-237.776 670.4794,-227.5318 658.9978,-218.8263\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"660.8294,-215.8302 650.687,-212.7672 656.7056,-221.4866 660.8294,-215.8302\" stroke=\"#000000\"/>\n</g>\n<!-- 140523470590360 -->\n<g class=\"node\" id=\"node59\">\n<title>140523470590360</title>\n<polygon fill=\"none\" points=\"258.5,-581.5 258.5,-627.5 711.5,-627.5 711.5,-581.5 258.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-600.8\">batch_normalization_16: BatchNormalization</text>\n<polyline fill=\"none\" points=\"536.5,-581.5 536.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"565.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"536.5,-604.5 594.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"565.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"594.5,-581.5 594.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"653\" y=\"-612.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"594.5,-604.5 711.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"653\" y=\"-589.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523471826616&#45;&gt;140523470590360 -->\n<g class=\"edge\" id=\"edge65\">\n<title>140523471826616-&gt;140523470590360</title>\n<path d=\"M509.5291,-664.3799C506.0948,-655.9962 502.1468,-646.3584 498.436,-637.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"501.5676,-635.7109 494.538,-627.784 495.09,-638.3645 501.5676,-635.7109\" stroke=\"#000000\"/>\n</g>\n<!-- 140523470590248 -->\n<g class=\"node\" id=\"node60\">\n<title>140523470590248</title>\n<polygon fill=\"none\" points=\"317,-498.5 317,-544.5 653,-544.5 653,-498.5 317,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-517.8\">activation_16: Activation</text>\n<polyline fill=\"none\" points=\"478,-498.5 478,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"507\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"478,-521.5 536,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"507\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"536,-498.5 536,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"594.5\" y=\"-529.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"536,-521.5 653,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"594.5\" y=\"-506.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523470590360&#45;&gt;140523470590248 -->\n<g class=\"edge\" id=\"edge66\">\n<title>140523470590360-&gt;140523470590248</title>\n<path d=\"M485,-581.3799C485,-573.1745 485,-563.7679 485,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"488.5001,-554.784 485,-544.784 481.5001,-554.784 488.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523470692136 -->\n<g class=\"node\" id=\"node61\">\n<title>140523470692136</title>\n<polygon fill=\"none\" points=\"327.5,-415.5 327.5,-461.5 642.5,-461.5 642.5,-415.5 327.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-434.8\">conv2d_20: Conv2D</text>\n<polyline fill=\"none\" points=\"467.5,-415.5 467.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"496.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"467.5,-438.5 525.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"496.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"525.5,-415.5 525.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"584\" y=\"-446.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"525.5,-438.5 642.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"584\" y=\"-423.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523470590248&#45;&gt;140523470692136 -->\n<g class=\"edge\" id=\"edge67\">\n<title>140523470590248-&gt;140523470692136</title>\n<path d=\"M485,-498.3799C485,-490.1745 485,-480.7679 485,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"488.5001,-471.784 485,-461.784 481.5001,-471.784 488.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523470317832 -->\n<g class=\"node\" id=\"node62\">\n<title>140523470317832</title>\n<polygon fill=\"none\" points=\"258.5,-332.5 258.5,-378.5 711.5,-378.5 711.5,-332.5 258.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-351.8\">batch_normalization_17: BatchNormalization</text>\n<polyline fill=\"none\" points=\"536.5,-332.5 536.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"565.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"536.5,-355.5 594.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"565.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"594.5,-332.5 594.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"653\" y=\"-363.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"594.5,-355.5 711.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"653\" y=\"-340.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523470692136&#45;&gt;140523470317832 -->\n<g class=\"edge\" id=\"edge68\">\n<title>140523470692136-&gt;140523470317832</title>\n<path d=\"M485,-415.3799C485,-407.1745 485,-397.7679 485,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"488.5001,-388.784 485,-378.784 481.5001,-388.784 488.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523470103104 -->\n<g class=\"node\" id=\"node63\">\n<title>140523470103104</title>\n<polygon fill=\"none\" points=\"346,-249.5 346,-295.5 682,-295.5 682,-249.5 346,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-268.8\">activation_17: Activation</text>\n<polyline fill=\"none\" points=\"507,-249.5 507,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"536\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"507,-272.5 565,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"536\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"565,-249.5 565,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623.5\" y=\"-280.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"565,-272.5 682,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623.5\" y=\"-257.3\">(None, 8, 8, 512)</text>\n</g>\n<!-- 140523470317832&#45;&gt;140523470103104 -->\n<g class=\"edge\" id=\"edge69\">\n<title>140523470317832-&gt;140523470103104</title>\n<path d=\"M493.0781,-332.3799C496.0074,-323.9962 499.3748,-314.3584 502.5399,-305.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"505.8702,-306.3788 505.8646,-295.784 499.262,-304.0699 505.8702,-306.3788\" stroke=\"#000000\"/>\n</g>\n<!-- 140523470103104&#45;&gt;140523469765152 -->\n<g class=\"edge\" id=\"edge71\">\n<title>140523470103104-&gt;140523469765152</title>\n<path d=\"M541.2985,-249.3799C552.2504,-240.1043 565.0148,-229.2936 576.6605,-219.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"579.1391,-221.9178 584.508,-212.784 574.6151,-216.5761 579.1391,-221.9178\" stroke=\"#000000\"/>\n</g>\n<!-- 140523469450824 -->\n<g class=\"node\" id=\"node65\">\n<title>140523469450824</title>\n<polygon fill=\"none\" points=\"352.5,-83.5 352.5,-129.5 871.5,-129.5 871.5,-83.5 352.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524.5\" y=\"-102.8\">global_average_pooling2d_1: GlobalAveragePooling2D</text>\n<polyline fill=\"none\" points=\"696.5,-83.5 696.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"725.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"696.5,-106.5 754.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"725.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"754.5,-83.5 754.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"813\" y=\"-114.3\">(None, 8, 8, 512)</text>\n<polyline fill=\"none\" points=\"754.5,-106.5 871.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"813\" y=\"-91.3\">(None, 512)</text>\n</g>\n<!-- 140523469765152&#45;&gt;140523469450824 -->\n<g class=\"edge\" id=\"edge72\">\n<title>140523469765152-&gt;140523469450824</title>\n<path d=\"M612,-166.3799C612,-158.1745 612,-148.7679 612,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"615.5001,-139.784 612,-129.784 608.5001,-139.784 615.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140523469766048 -->\n<g class=\"node\" id=\"node66\">\n<title>140523469766048</title>\n<polygon fill=\"none\" points=\"486,-.5 486,-46.5 738,-46.5 738,-.5 486,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"539.5\" y=\"-19.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"593,-.5 593,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"593,-23.5 651,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"651,-.5 651,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"694.5\" y=\"-31.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"651,-23.5 738,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"694.5\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 140523469450824&#45;&gt;140523469766048 -->\n<g class=\"edge\" id=\"edge73\">\n<title>140523469450824-&gt;140523469766048</title>\n<path d=\"M612,-83.3799C612,-75.1745 612,-65.7679 612,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"615.5001,-56.784 612,-46.784 608.5001,-56.784 615.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILi8XpZg2fdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # 在数据集上将输入平均值设置为0\n",
        "        samplewise_center=False,  # 将每个样本均值设置为0\n",
        "        featurewise_std_normalization=False,  # 将输入除以数据集的std\n",
        "        samplewise_std_normalization=False,  # 将每个输入除以其std\n",
        "        zca_whitening=False,  # 应用ZCA白化\n",
        "        rotation_range=20,  # 在一个范围下随机旋转图像(degrees, 0 to 180)\n",
        "        width_shift_range=0.2,  # 水平随机移位图像（总宽度的分数）\n",
        "        height_shift_range=0.2,  # 随机地垂直移动图像（总高度的分数）\n",
        "        horizontal_flip=True,  # 随机翻转图像\n",
        "        vertical_flip=False)  # 随机翻转图像\n",
        "\n",
        "    # 计算特征方向归一化所需的数量\n",
        "    # (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdjWGfWJ2fXx",
        "colab_type": "code",
        "outputId": "11394963-7870-4d17-ce9b-4e96b6570a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4573
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_12.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "# optimizer = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=1e-6)\n",
        "# optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-5, amsgrad=False)\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                        batch_size=128),\n",
        "                        samples_per_epoch=x_train.shape[0],\n",
        "                        nb_epoch=100,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                   callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=390, epochs=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 46s 117ms/step - loss: 2.1594 - acc: 0.4026 - val_loss: 1.9702 - val_acc: 0.4529\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.45290, saving model to cifar10_model_12.h5\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 1.6121 - acc: 0.5200 - val_loss: 2.5118 - val_acc: 0.3477\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.45290\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 1.4047 - acc: 0.5748 - val_loss: 1.4246 - val_acc: 0.5698\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.45290 to 0.56980, saving model to cifar10_model_12.h5\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 1.2652 - acc: 0.6183 - val_loss: 1.2798 - val_acc: 0.6241\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.56980 to 0.62410, saving model to cifar10_model_12.h5\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 1.1672 - acc: 0.6563 - val_loss: 2.7716 - val_acc: 0.4014\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.62410\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 1.1055 - acc: 0.6777 - val_loss: 1.4557 - val_acc: 0.5647\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.62410\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 1.0603 - acc: 0.6932 - val_loss: 1.3218 - val_acc: 0.6343\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.62410 to 0.63430, saving model to cifar10_model_12.h5\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 1.0192 - acc: 0.7071 - val_loss: 1.5178 - val_acc: 0.5906\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.63430\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 38s 99ms/step - loss: 0.9736 - acc: 0.7215 - val_loss: 1.1888 - val_acc: 0.6461\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.63430 to 0.64610, saving model to cifar10_model_12.h5\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.9494 - acc: 0.7332 - val_loss: 1.0456 - val_acc: 0.6991\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.64610 to 0.69910, saving model to cifar10_model_12.h5\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.9202 - acc: 0.7419 - val_loss: 1.3351 - val_acc: 0.5951\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.69910\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.9042 - acc: 0.7467 - val_loss: 1.0584 - val_acc: 0.6934\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.69910\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.8852 - acc: 0.7544 - val_loss: 1.1215 - val_acc: 0.6912\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.69910\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.8739 - acc: 0.7606 - val_loss: 1.1208 - val_acc: 0.6834\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.69910\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.8559 - acc: 0.7674 - val_loss: 1.1564 - val_acc: 0.6883\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.69910\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.7097 - acc: 0.8153 - val_loss: 0.7063 - val_acc: 0.8152\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.69910 to 0.81520, saving model to cifar10_model_12.h5\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.6634 - acc: 0.8274 - val_loss: 0.7822 - val_acc: 0.7917\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.81520\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.6437 - acc: 0.8324 - val_loss: 0.6685 - val_acc: 0.8227\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.81520 to 0.82270, saving model to cifar10_model_12.h5\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.6240 - acc: 0.8386 - val_loss: 0.6854 - val_acc: 0.8214\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.82270\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.6101 - acc: 0.8423 - val_loss: 0.7248 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.82270\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.6070 - acc: 0.8431 - val_loss: 0.7311 - val_acc: 0.8063\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.82270\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.5947 - acc: 0.8471 - val_loss: 0.6884 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.82270 to 0.82280, saving model to cifar10_model_12.h5\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.5766 - acc: 0.8523 - val_loss: 0.7568 - val_acc: 0.7996\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.82280\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.5381 - acc: 0.8646 - val_loss: 0.6428 - val_acc: 0.8354\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.82280 to 0.83540, saving model to cifar10_model_12.h5\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.5211 - acc: 0.8684 - val_loss: 0.6292 - val_acc: 0.8412\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.83540 to 0.84120, saving model to cifar10_model_12.h5\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.5202 - acc: 0.8676 - val_loss: 0.6301 - val_acc: 0.8386\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.84120\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.5126 - acc: 0.8713 - val_loss: 0.6158 - val_acc: 0.8430\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.84120 to 0.84300, saving model to cifar10_model_12.h5\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.5092 - acc: 0.8729 - val_loss: 0.6268 - val_acc: 0.8411\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.84300\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.5088 - acc: 0.8737 - val_loss: 0.6127 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.84300 to 0.84440, saving model to cifar10_model_12.h5\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.5000 - acc: 0.8733 - val_loss: 0.6222 - val_acc: 0.8449\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.84440 to 0.84490, saving model to cifar10_model_12.h5\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4954 - acc: 0.8769 - val_loss: 0.6470 - val_acc: 0.8351\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.84490\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4906 - acc: 0.8774 - val_loss: 0.6148 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.84490 to 0.84620, saving model to cifar10_model_12.h5\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4840 - acc: 0.8807 - val_loss: 0.6382 - val_acc: 0.8392\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.84620\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4851 - acc: 0.8793 - val_loss: 0.6086 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.84620\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4803 - acc: 0.8795 - val_loss: 0.6053 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.84620 to 0.84870, saving model to cifar10_model_12.h5\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4788 - acc: 0.8801 - val_loss: 0.6245 - val_acc: 0.8435\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.84870\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4755 - acc: 0.8814 - val_loss: 0.6248 - val_acc: 0.8449\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.84870\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4714 - acc: 0.8839 - val_loss: 0.6070 - val_acc: 0.8485\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.84870\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4690 - acc: 0.8848 - val_loss: 0.6546 - val_acc: 0.8374\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.84870\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4657 - acc: 0.8861 - val_loss: 0.6517 - val_acc: 0.8345\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.84870\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4547 - acc: 0.8886 - val_loss: 0.6157 - val_acc: 0.8468\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.84870\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4550 - acc: 0.8887 - val_loss: 0.6037 - val_acc: 0.8496\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.84870 to 0.84960, saving model to cifar10_model_12.h5\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4504 - acc: 0.8911 - val_loss: 0.6102 - val_acc: 0.8493\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.84960\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4508 - acc: 0.8903 - val_loss: 0.6088 - val_acc: 0.8497\n",
            "\n",
            "Epoch 00044: val_acc improved from 0.84960 to 0.84970, saving model to cifar10_model_12.h5\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 38s 97ms/step - loss: 0.4560 - acc: 0.8886 - val_loss: 0.6064 - val_acc: 0.8490\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.84970\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 39s 99ms/step - loss: 0.4439 - acc: 0.8918 - val_loss: 0.6069 - val_acc: 0.8497\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.84970\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4467 - acc: 0.8912 - val_loss: 0.6137 - val_acc: 0.8484\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.84970\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4430 - acc: 0.8915 - val_loss: 0.6106 - val_acc: 0.8499\n",
            "\n",
            "Epoch 00048: val_acc improved from 0.84970 to 0.84990, saving model to cifar10_model_12.h5\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4425 - acc: 0.8940 - val_loss: 0.6114 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.84990 to 0.85020, saving model to cifar10_model_12.h5\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4428 - acc: 0.8927 - val_loss: 0.6109 - val_acc: 0.8497\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.85020\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4387 - acc: 0.8930 - val_loss: 0.6118 - val_acc: 0.8496\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.85020\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4416 - acc: 0.8932 - val_loss: 0.6115 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.85020\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4417 - acc: 0.8929 - val_loss: 0.6159 - val_acc: 0.8486\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.85020\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4387 - acc: 0.8938 - val_loss: 0.6128 - val_acc: 0.8498\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.85020\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4419 - acc: 0.8926 - val_loss: 0.6146 - val_acc: 0.8499\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.85020\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4350 - acc: 0.8954 - val_loss: 0.6140 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.85020\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4356 - acc: 0.8950 - val_loss: 0.6145 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.85020\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4412 - acc: 0.8928 - val_loss: 0.6129 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.85020\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 38s 98ms/step - loss: 0.4359 - acc: 0.8950 - val_loss: 0.6129 - val_acc: 0.8496\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.85020\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "Epoch 00059: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce24d452e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plEi4hQW2fR2",
        "colab_type": "code",
        "outputId": "11a15517-847a-4280-d236-c2ea729658a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_12.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 326us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.611445458316803, 0.8502]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9V2quKlTE9F",
        "colab_type": "text"
      },
      "source": [
        "参考这里\n",
        "\n",
        "[Pytorch实战2：ResNet-18实现Cifar-10图像分类（测试集分类准确率95.170%）](https://blog.csdn.net/sunqiande88/article/details/80100891)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NxKd3k72fAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDVLhc-oJDTi",
        "colab_type": "text"
      },
      "source": [
        "## 超越90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_v7CZheJF1d",
        "colab_type": "code",
        "outputId": "133903cd-32dd-4704-ba7f-482179c992bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2105
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, add, Conv2D, SeparableConv2D, MaxPool2D, Dropout, Dense, GlobalAveragePooling2D, BatchNormalization, concatenate\n",
        "from keras import layers, models\n",
        "from keras.layers import LeakyReLU, ThresholdedReLU, Softmax, ReLU, Activation, Reshape, Lambda, ActivityRegularization\n",
        "\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "temp = inputs\n",
        "x = Conv2D(16, (3, 3), padding='same')(inputs)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "temp = x\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = concatenate([x, temp])\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "temp = x\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = concatenate([x, temp])\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "temp = x\n",
        "x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = concatenate([x, temp])\n",
        "x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(128, (1, 1), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=x)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 32, 32, 16)   0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 32, 32, 16)   0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 32)   4640        leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 32, 32, 32)   0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 35)   0           leaky_re_lu_19[0][0]             \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 35)   140         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 35)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 32)   10112       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 16, 16, 32)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 16, 16, 32)   0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 16, 16, 67)   0           leaky_re_lu_21[0][0]             \n",
            "                                                                 max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 32)   19328       concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 16, 16, 32)   0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 64)   18496       leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, 16, 16, 64)   0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 16, 16, 99)   0           leaky_re_lu_23[0][0]             \n",
            "                                                                 max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 99)   396         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 99)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 64)     57088       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, 8, 8, 64)     0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, 8, 8, 64)     0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 8, 8, 163)    0           leaky_re_lu_25[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 64)     93952       concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, 8, 8, 64)     0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 128)    73856       leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, 8, 8, 128)    0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 8, 8, 227)    0           leaky_re_lu_27[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 8, 8, 227)    908         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 4, 4, 227)    0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 4, 4, 128)    261632      max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, 4, 4, 128)    0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 4, 4, 128)    147584      leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, 4, 4, 128)    0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 4, 4, 355)    0           leaky_re_lu_29[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 4, 4, 128)    409088      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, 4, 4, 128)    0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 4, 4, 256)    295168      leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, 4, 4, 256)    0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 4, 4, 483)    0           leaky_re_lu_31[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 4, 4, 483)    1932        concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 2, 2, 483)    0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 2, 2, 128)    61952       max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, 2, 2, 128)    0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 2, 2, 128)    512         leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 128)          0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1290        global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 1,507,018\n",
            "Trainable params: 1,505,074\n",
            "Non-trainable params: 1,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q94j0hDH6VsX",
        "colab_type": "code",
        "outputId": "0f7fa144-386d-4f3c-f1a8-d9b4b79f0ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5627
        }
      },
      "source": [
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "plot_model(model, to_file='cifar10_model.png', show_shapes=True)                                   # 保存模型图片\n",
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))                #  显示在jupyter notebook 上"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"4205pt\" viewBox=\"0.00 0.00 665.50 4205.00\" width=\"666pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 4201)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-4201 661.5,-4201 661.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139695595895496 -->\n<g class=\"node\" id=\"node1\">\n<title>139695595895496</title>\n<polygon fill=\"none\" points=\"255,-4150.5 255,-4196.5 563,-4196.5 563,-4150.5 255,-4150.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321.5\" y=\"-4169.8\">input_2: InputLayer</text>\n<polyline fill=\"none\" points=\"388,-4150.5 388,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417\" y=\"-4181.3\">input:</text>\n<polyline fill=\"none\" points=\"388,-4173.5 446,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417\" y=\"-4158.3\">output:</text>\n<polyline fill=\"none\" points=\"446,-4150.5 446,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504.5\" y=\"-4181.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"446,-4173.5 563,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504.5\" y=\"-4158.3\">(None, 32, 32, 3)</text>\n</g>\n<!-- 139695595895776 -->\n<g class=\"node\" id=\"node2\">\n<title>139695595895776</title>\n<polygon fill=\"none\" points=\"152.5,-4067.5 152.5,-4113.5 475.5,-4113.5 475.5,-4067.5 152.5,-4067.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"222.5\" y=\"-4086.8\">conv2d_17: Conv2D</text>\n<polyline fill=\"none\" points=\"292.5,-4067.5 292.5,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321.5\" y=\"-4098.3\">input:</text>\n<polyline fill=\"none\" points=\"292.5,-4090.5 350.5,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321.5\" y=\"-4075.3\">output:</text>\n<polyline fill=\"none\" points=\"350.5,-4067.5 350.5,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"413\" y=\"-4098.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"350.5,-4090.5 475.5,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"413\" y=\"-4075.3\">(None, 32, 32, 16)</text>\n</g>\n<!-- 139695595895496&#45;&gt;139695595895776 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139695595895496-&gt;139695595895776</title>\n<path d=\"M382.5372,-4150.3799C371.9206,-4141.1043 359.5468,-4130.2936 348.2577,-4120.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"350.4839,-4117.7277 340.6504,-4113.784 345.8783,-4122.9992 350.4839,-4117.7277\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595677456 -->\n<g class=\"node\" id=\"node8\">\n<title>139695595677456</title>\n<polygon fill=\"none\" points=\"171.5,-3569.5 171.5,-3615.5 646.5,-3615.5 646.5,-3569.5 171.5,-3569.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259\" y=\"-3588.8\">concatenate_8: Concatenate</text>\n<polyline fill=\"none\" points=\"346.5,-3569.5 346.5,-3615.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375.5\" y=\"-3600.3\">input:</text>\n<polyline fill=\"none\" points=\"346.5,-3592.5 404.5,-3592.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375.5\" y=\"-3577.3\">output:</text>\n<polyline fill=\"none\" points=\"404.5,-3569.5 404.5,-3615.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"525.5\" y=\"-3600.3\">[(None, 32, 32, 32), (None, 32, 32, 3)]</text>\n<polyline fill=\"none\" points=\"404.5,-3592.5 646.5,-3592.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"525.5\" y=\"-3577.3\">(None, 32, 32, 35)</text>\n</g>\n<!-- 139695595895496&#45;&gt;139695595677456 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139695595895496-&gt;139695595677456</title>\n<path d=\"M447.1145,-4150.3711C460.4454,-4140.6161 474.4514,-4128.209 484,-4114 511.4967,-4073.083 515,-4056.7978 515,-4007.5 515,-4007.5 515,-4007.5 515,-3758.5 515,-3710.4193 522.0975,-3692.3816 496,-3652 488.2474,-3640.0041 477.1344,-3629.792 465.431,-3621.391\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"467.0908,-3618.2886 456.8443,-3615.5943 463.1741,-3624.0904 467.0908,-3618.2886\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595895608 -->\n<g class=\"node\" id=\"node3\">\n<title>139695595895608</title>\n<polygon fill=\"none\" points=\"119,-3984.5 119,-4030.5 487,-4030.5 487,-3984.5 119,-3984.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-4003.8\">leaky_re_lu_17: LeakyReLU</text>\n<polyline fill=\"none\" points=\"304,-3984.5 304,-4030.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-4015.3\">input:</text>\n<polyline fill=\"none\" points=\"304,-4007.5 362,-4007.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-3992.3\">output:</text>\n<polyline fill=\"none\" points=\"362,-3984.5 362,-4030.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.5\" y=\"-4015.3\">(None, 32, 32, 16)</text>\n<polyline fill=\"none\" points=\"362,-4007.5 487,-4007.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.5\" y=\"-3992.3\">(None, 32, 32, 16)</text>\n</g>\n<!-- 139695595895776&#45;&gt;139695595895608 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139695595895776-&gt;139695595895608</title>\n<path d=\"M310.9359,-4067.3799C309.8484,-4059.1745 308.6018,-4049.7679 307.4237,-4040.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"310.8694,-4040.2375 306.0858,-4030.784 303.9301,-4041.1572 310.8694,-4040.2375\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595896784 -->\n<g class=\"node\" id=\"node4\">\n<title>139695595896784</title>\n<polygon fill=\"none\" points=\"141.5,-3901.5 141.5,-3947.5 464.5,-3947.5 464.5,-3901.5 141.5,-3901.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-3920.8\">conv2d_18: Conv2D</text>\n<polyline fill=\"none\" points=\"281.5,-3901.5 281.5,-3947.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-3932.3\">input:</text>\n<polyline fill=\"none\" points=\"281.5,-3924.5 339.5,-3924.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-3909.3\">output:</text>\n<polyline fill=\"none\" points=\"339.5,-3901.5 339.5,-3947.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3932.3\">(None, 32, 32, 16)</text>\n<polyline fill=\"none\" points=\"339.5,-3924.5 464.5,-3924.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3909.3\">(None, 32, 32, 16)</text>\n</g>\n<!-- 139695595895608&#45;&gt;139695595896784 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139695595895608-&gt;139695595896784</title>\n<path d=\"M303,-3984.3799C303,-3976.1745 303,-3966.7679 303,-3957.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"306.5001,-3957.784 303,-3947.784 299.5001,-3957.784 306.5001,-3957.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595896280 -->\n<g class=\"node\" id=\"node5\">\n<title>139695595896280</title>\n<polygon fill=\"none\" points=\"119,-3818.5 119,-3864.5 487,-3864.5 487,-3818.5 119,-3818.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-3837.8\">leaky_re_lu_18: LeakyReLU</text>\n<polyline fill=\"none\" points=\"304,-3818.5 304,-3864.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-3849.3\">input:</text>\n<polyline fill=\"none\" points=\"304,-3841.5 362,-3841.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-3826.3\">output:</text>\n<polyline fill=\"none\" points=\"362,-3818.5 362,-3864.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.5\" y=\"-3849.3\">(None, 32, 32, 16)</text>\n<polyline fill=\"none\" points=\"362,-3841.5 487,-3841.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.5\" y=\"-3826.3\">(None, 32, 32, 16)</text>\n</g>\n<!-- 139695595896784&#45;&gt;139695595896280 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139695595896784-&gt;139695595896280</title>\n<path d=\"M303,-3901.3799C303,-3893.1745 303,-3883.7679 303,-3874.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"306.5001,-3874.784 303,-3864.784 299.5001,-3874.784 306.5001,-3874.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595476640 -->\n<g class=\"node\" id=\"node6\">\n<title>139695595476640</title>\n<polygon fill=\"none\" points=\"141.5,-3735.5 141.5,-3781.5 464.5,-3781.5 464.5,-3735.5 141.5,-3735.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-3754.8\">conv2d_19: Conv2D</text>\n<polyline fill=\"none\" points=\"281.5,-3735.5 281.5,-3781.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-3766.3\">input:</text>\n<polyline fill=\"none\" points=\"281.5,-3758.5 339.5,-3758.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-3743.3\">output:</text>\n<polyline fill=\"none\" points=\"339.5,-3735.5 339.5,-3781.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3766.3\">(None, 32, 32, 16)</text>\n<polyline fill=\"none\" points=\"339.5,-3758.5 464.5,-3758.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3743.3\">(None, 32, 32, 32)</text>\n</g>\n<!-- 139695595896280&#45;&gt;139695595476640 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139695595896280-&gt;139695595476640</title>\n<path d=\"M303,-3818.3799C303,-3810.1745 303,-3800.7679 303,-3791.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"306.5001,-3791.784 303,-3781.784 299.5001,-3791.784 306.5001,-3791.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595476808 -->\n<g class=\"node\" id=\"node7\">\n<title>139695595476808</title>\n<polygon fill=\"none\" points=\"119,-3652.5 119,-3698.5 487,-3698.5 487,-3652.5 119,-3652.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-3671.8\">leaky_re_lu_19: LeakyReLU</text>\n<polyline fill=\"none\" points=\"304,-3652.5 304,-3698.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-3683.3\">input:</text>\n<polyline fill=\"none\" points=\"304,-3675.5 362,-3675.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333\" y=\"-3660.3\">output:</text>\n<polyline fill=\"none\" points=\"362,-3652.5 362,-3698.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.5\" y=\"-3683.3\">(None, 32, 32, 32)</text>\n<polyline fill=\"none\" points=\"362,-3675.5 487,-3675.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424.5\" y=\"-3660.3\">(None, 32, 32, 32)</text>\n</g>\n<!-- 139695595476640&#45;&gt;139695595476808 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139695595476640-&gt;139695595476808</title>\n<path d=\"M303,-3735.3799C303,-3727.1745 303,-3717.7679 303,-3708.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"306.5001,-3708.784 303,-3698.784 299.5001,-3708.784 306.5001,-3708.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595476808&#45;&gt;139695595677456 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139695595476808-&gt;139695595677456</title>\n<path d=\"M332.5269,-3652.3799C344.4867,-3643.0151 358.445,-3632.0855 371.1386,-3622.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"373.5481,-3624.7049 379.2638,-3615.784 369.2325,-3619.1934 373.5481,-3624.7049\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595895440 -->\n<g class=\"node\" id=\"node9\">\n<title>139695595895440</title>\n<polygon fill=\"none\" points=\"182,-3486.5 182,-3532.5 636,-3532.5 636,-3486.5 182,-3486.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-3505.8\">batch_normalization_6: BatchNormalization</text>\n<polyline fill=\"none\" points=\"453,-3486.5 453,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"482\" y=\"-3517.3\">input:</text>\n<polyline fill=\"none\" points=\"453,-3509.5 511,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"482\" y=\"-3494.3\">output:</text>\n<polyline fill=\"none\" points=\"511,-3486.5 511,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573.5\" y=\"-3517.3\">(None, 32, 32, 35)</text>\n<polyline fill=\"none\" points=\"511,-3509.5 636,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573.5\" y=\"-3494.3\">(None, 32, 32, 35)</text>\n</g>\n<!-- 139695595677456&#45;&gt;139695595895440 -->\n<g class=\"edge\" id=\"edge9\">\n<title>139695595677456-&gt;139695595895440</title>\n<path d=\"M409,-3569.3799C409,-3561.1745 409,-3551.7679 409,-3542.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"412.5001,-3542.784 409,-3532.784 405.5001,-3542.784 412.5001,-3542.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595585264 -->\n<g class=\"node\" id=\"node10\">\n<title>139695595585264</title>\n<polygon fill=\"none\" points=\"207,-3403.5 207,-3449.5 611,-3449.5 611,-3403.5 207,-3403.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-3422.8\">max_pooling2d_5: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"428,-3403.5 428,-3449.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"457\" y=\"-3434.3\">input:</text>\n<polyline fill=\"none\" points=\"428,-3426.5 486,-3426.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"457\" y=\"-3411.3\">output:</text>\n<polyline fill=\"none\" points=\"486,-3403.5 486,-3449.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"548.5\" y=\"-3434.3\">(None, 32, 32, 35)</text>\n<polyline fill=\"none\" points=\"486,-3426.5 611,-3426.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"548.5\" y=\"-3411.3\">(None, 16, 16, 35)</text>\n</g>\n<!-- 139695595895440&#45;&gt;139695595585264 -->\n<g class=\"edge\" id=\"edge10\">\n<title>139695595895440-&gt;139695595585264</title>\n<path d=\"M409,-3486.3799C409,-3478.1745 409,-3468.7679 409,-3459.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"412.5001,-3459.784 409,-3449.784 405.5001,-3459.784 412.5001,-3459.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595585376 -->\n<g class=\"node\" id=\"node11\">\n<title>139695595585376</title>\n<polygon fill=\"none\" points=\"141.5,-3320.5 141.5,-3366.5 464.5,-3366.5 464.5,-3320.5 141.5,-3320.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-3339.8\">conv2d_20: Conv2D</text>\n<polyline fill=\"none\" points=\"281.5,-3320.5 281.5,-3366.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-3351.3\">input:</text>\n<polyline fill=\"none\" points=\"281.5,-3343.5 339.5,-3343.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-3328.3\">output:</text>\n<polyline fill=\"none\" points=\"339.5,-3320.5 339.5,-3366.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3351.3\">(None, 16, 16, 35)</text>\n<polyline fill=\"none\" points=\"339.5,-3343.5 464.5,-3343.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-3328.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139695595585264&#45;&gt;139695595585376 -->\n<g class=\"edge\" id=\"edge11\">\n<title>139695595585264-&gt;139695595585376</title>\n<path d=\"M379.4731,-3403.3799C367.5133,-3394.0151 353.555,-3383.0855 340.8614,-3373.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"342.7675,-3370.1934 332.7362,-3366.784 338.4519,-3375.7049 342.7675,-3370.1934\" stroke=\"#000000\"/>\n</g>\n<!-- 139695594645936 -->\n<g class=\"node\" id=\"node15\">\n<title>139695594645936</title>\n<polygon fill=\"none\" points=\"1,-2988.5 1,-3034.5 483,-3034.5 483,-2988.5 1,-2988.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.5\" y=\"-3007.8\">concatenate_9: Concatenate</text>\n<polyline fill=\"none\" points=\"176,-2988.5 176,-3034.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205\" y=\"-3019.3\">input:</text>\n<polyline fill=\"none\" points=\"176,-3011.5 234,-3011.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205\" y=\"-2996.3\">output:</text>\n<polyline fill=\"none\" points=\"234,-2988.5 234,-3034.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"358.5\" y=\"-3019.3\">[(None, 16, 16, 32), (None, 16, 16, 35)]</text>\n<polyline fill=\"none\" points=\"234,-3011.5 483,-3011.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"358.5\" y=\"-2996.3\">(None, 16, 16, 67)</text>\n</g>\n<!-- 139695595585264&#45;&gt;139695594645936 -->\n<g class=\"edge\" id=\"edge16\">\n<title>139695595585264-&gt;139695594645936</title>\n<path d=\"M442.1488,-3403.2613C453.7406,-3393.4154 465.6763,-3380.9752 473,-3367 496.5348,-3322.0905 540.1741,-3146.7853 511,-3094.5\" fill=\"none\" stroke=\"#000000\"/>\n<path d=\"M511,-3094.5C496.0634,-3070.1934 438.8057,-3050.7946 380.9335,-3036.8825\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"381.4269,-3033.4032 370.8914,-3034.5232 379.8258,-3040.2176 381.4269,-3033.4032\" stroke=\"#000000\"/>\n</g>\n<!-- 139695563080144 -->\n<g class=\"node\" id=\"node20\">\n<title>139695563080144</title>\n<polygon fill=\"none\" points=\"158.5,-2573.5 158.5,-2619.5 647.5,-2619.5 647.5,-2573.5 158.5,-2573.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-2592.8\">concatenate_10: Concatenate</text>\n<polyline fill=\"none\" points=\"340.5,-2573.5 340.5,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369.5\" y=\"-2604.3\">input:</text>\n<polyline fill=\"none\" points=\"340.5,-2596.5 398.5,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369.5\" y=\"-2581.3\">output:</text>\n<polyline fill=\"none\" points=\"398.5,-2573.5 398.5,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"523\" y=\"-2604.3\">[(None, 16, 16, 64), (None, 16, 16, 35)]</text>\n<polyline fill=\"none\" points=\"398.5,-2596.5 647.5,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"523\" y=\"-2581.3\">(None, 16, 16, 99)</text>\n</g>\n<!-- 139695595585264&#45;&gt;139695563080144 -->\n<g class=\"edge\" id=\"edge22\">\n<title>139695595585264-&gt;139695563080144</title>\n<path d=\"M511,-3094.5C472.3733,-3031.6419 511,-3002.2778 511,-2928.5 511,-2928.5 511,-2928.5 511,-2762.5 511,-2714.0754 514.7958,-2696.3351 488,-2656 480.1396,-2644.1679 469.0561,-2633.9794 457.4812,-2625.5447\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"459.2277,-2622.498 449.005,-2619.7144 455.2606,-2628.2653 459.2277,-2622.498\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595228128 -->\n<g class=\"node\" id=\"node12\">\n<title>139695595228128</title>\n<polygon fill=\"none\" points=\"108,-3237.5 108,-3283.5 476,-3283.5 476,-3237.5 108,-3237.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.5\" y=\"-3256.8\">leaky_re_lu_20: LeakyReLU</text>\n<polyline fill=\"none\" points=\"293,-3237.5 293,-3283.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-3268.3\">input:</text>\n<polyline fill=\"none\" points=\"293,-3260.5 351,-3260.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322\" y=\"-3245.3\">output:</text>\n<polyline fill=\"none\" points=\"351,-3237.5 351,-3283.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"413.5\" y=\"-3268.3\">(None, 16, 16, 32)</text>\n<polyline fill=\"none\" points=\"351,-3260.5 476,-3260.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"413.5\" y=\"-3245.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139695595585376&#45;&gt;139695595228128 -->\n<g class=\"edge\" id=\"edge12\">\n<title>139695595585376-&gt;139695595228128</title>\n<path d=\"M299.9359,-3320.3799C298.8484,-3312.1745 297.6018,-3302.7679 296.4237,-3293.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"299.8694,-3293.2375 295.0858,-3283.784 292.9301,-3294.1572 299.8694,-3293.2375\" stroke=\"#000000\"/>\n</g>\n<!-- 139695594901064 -->\n<g class=\"node\" id=\"node13\">\n<title>139695594901064</title>\n<polygon fill=\"none\" points=\"102.5,-3154.5 102.5,-3200.5 425.5,-3200.5 425.5,-3154.5 102.5,-3154.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172.5\" y=\"-3173.8\">conv2d_21: Conv2D</text>\n<polyline fill=\"none\" points=\"242.5,-3154.5 242.5,-3200.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-3185.3\">input:</text>\n<polyline fill=\"none\" points=\"242.5,-3177.5 300.5,-3177.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-3162.3\">output:</text>\n<polyline fill=\"none\" points=\"300.5,-3154.5 300.5,-3200.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-3185.3\">(None, 16, 16, 32)</text>\n<polyline fill=\"none\" points=\"300.5,-3177.5 425.5,-3177.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-3162.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139695595228128&#45;&gt;139695594901064 -->\n<g class=\"edge\" id=\"edge13\">\n<title>139695595228128-&gt;139695594901064</title>\n<path d=\"M284.2004,-3237.3799C281.3722,-3228.9962 278.1209,-3219.3584 275.0649,-3210.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"278.3678,-3209.1406 271.8548,-3200.784 271.735,-3211.3782 278.3678,-3209.1406\" stroke=\"#000000\"/>\n</g>\n<!-- 139695594899328 -->\n<g class=\"node\" id=\"node14\">\n<title>139695594899328</title>\n<polygon fill=\"none\" points=\"66,-3071.5 66,-3117.5 434,-3117.5 434,-3071.5 66,-3071.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"158.5\" y=\"-3090.8\">leaky_re_lu_21: LeakyReLU</text>\n<polyline fill=\"none\" points=\"251,-3071.5 251,-3117.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280\" y=\"-3102.3\">input:</text>\n<polyline fill=\"none\" points=\"251,-3094.5 309,-3094.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280\" y=\"-3079.3\">output:</text>\n<polyline fill=\"none\" points=\"309,-3071.5 309,-3117.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"371.5\" y=\"-3102.3\">(None, 16, 16, 32)</text>\n<polyline fill=\"none\" points=\"309,-3094.5 434,-3094.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"371.5\" y=\"-3079.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139695594901064&#45;&gt;139695594899328 -->\n<g class=\"edge\" id=\"edge14\">\n<title>139695594901064-&gt;139695594899328</title>\n<path d=\"M260.1002,-3154.3799C258.7162,-3146.1745 257.1295,-3136.7679 255.6301,-3127.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"259.042,-3127.0625 253.9274,-3117.784 252.1395,-3128.2269 259.042,-3127.0625\" stroke=\"#000000\"/>\n</g>\n<!-- 139695594899328&#45;&gt;139695594645936 -->\n<g class=\"edge\" id=\"edge15\">\n<title>139695594899328-&gt;139695594645936</title>\n<path d=\"M247.7716,-3071.3799C246.9807,-3063.1745 246.074,-3053.7679 245.2172,-3044.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"248.6876,-3044.4021 244.2442,-3034.784 241.7199,-3045.0737 248.6876,-3044.4021\" stroke=\"#000000\"/>\n</g>\n<!-- 139695594647056 -->\n<g class=\"node\" id=\"node16\">\n<title>139695594647056</title>\n<polygon fill=\"none\" points=\"108.5,-2905.5 108.5,-2951.5 431.5,-2951.5 431.5,-2905.5 108.5,-2905.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.5\" y=\"-2924.8\">conv2d_22: Conv2D</text>\n<polyline fill=\"none\" points=\"248.5,-2905.5 248.5,-2951.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-2936.3\">input:</text>\n<polyline fill=\"none\" points=\"248.5,-2928.5 306.5,-2928.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-2913.3\">output:</text>\n<polyline fill=\"none\" points=\"306.5,-2905.5 306.5,-2951.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369\" y=\"-2936.3\">(None, 16, 16, 67)</text>\n<polyline fill=\"none\" points=\"306.5,-2928.5 431.5,-2928.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369\" y=\"-2913.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139695594645936&#45;&gt;139695594647056 -->\n<g class=\"edge\" id=\"edge17\">\n<title>139695594645936-&gt;139695594647056</title>\n<path d=\"M249.7996,-2988.3799C252.6278,-2979.9962 255.8791,-2970.3584 258.9351,-2961.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"262.265,-2962.3782 262.1452,-2951.784 255.6322,-2960.1406 262.265,-2962.3782\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595228016 -->\n<g class=\"node\" id=\"node17\">\n<title>139695595228016</title>\n<polygon fill=\"none\" points=\"100,-2822.5 100,-2868.5 468,-2868.5 468,-2822.5 100,-2822.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-2841.8\">leaky_re_lu_22: LeakyReLU</text>\n<polyline fill=\"none\" points=\"285,-2822.5 285,-2868.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-2853.3\">input:</text>\n<polyline fill=\"none\" points=\"285,-2845.5 343,-2845.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-2830.3\">output:</text>\n<polyline fill=\"none\" points=\"343,-2822.5 343,-2868.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-2853.3\">(None, 16, 16, 32)</text>\n<polyline fill=\"none\" points=\"343,-2845.5 468,-2845.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-2830.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139695594647056&#45;&gt;139695595228016 -->\n<g class=\"edge\" id=\"edge18\">\n<title>139695594647056-&gt;139695595228016</title>\n<path d=\"M273.8998,-2905.3799C275.2838,-2897.1745 276.8705,-2887.7679 278.3699,-2878.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"281.8605,-2879.2269 280.0726,-2868.784 274.958,-2878.0625 281.8605,-2879.2269\" stroke=\"#000000\"/>\n</g>\n<!-- 139695594291552 -->\n<g class=\"node\" id=\"node18\">\n<title>139695594291552</title>\n<polygon fill=\"none\" points=\"129.5,-2739.5 129.5,-2785.5 452.5,-2785.5 452.5,-2739.5 129.5,-2739.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-2758.8\">conv2d_23: Conv2D</text>\n<polyline fill=\"none\" points=\"269.5,-2739.5 269.5,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.5\" y=\"-2770.3\">input:</text>\n<polyline fill=\"none\" points=\"269.5,-2762.5 327.5,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.5\" y=\"-2747.3\">output:</text>\n<polyline fill=\"none\" points=\"327.5,-2739.5 327.5,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390\" y=\"-2770.3\">(None, 16, 16, 32)</text>\n<polyline fill=\"none\" points=\"327.5,-2762.5 452.5,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390\" y=\"-2747.3\">(None, 16, 16, 64)</text>\n</g>\n<!-- 139695595228016&#45;&gt;139695594291552 -->\n<g class=\"edge\" id=\"edge19\">\n<title>139695595228016-&gt;139695594291552</title>\n<path d=\"M285.9499,-2822.3799C286.6419,-2814.1745 287.4352,-2804.7679 288.1849,-2795.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"291.6834,-2796.0428 289.0363,-2785.784 284.7082,-2795.4545 291.6834,-2796.0428\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595583136 -->\n<g class=\"node\" id=\"node19\">\n<title>139695595583136</title>\n<polygon fill=\"none\" points=\"111,-2656.5 111,-2702.5 479,-2702.5 479,-2656.5 111,-2656.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-2675.8\">leaky_re_lu_23: LeakyReLU</text>\n<polyline fill=\"none\" points=\"296,-2656.5 296,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"325\" y=\"-2687.3\">input:</text>\n<polyline fill=\"none\" points=\"296,-2679.5 354,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"325\" y=\"-2664.3\">output:</text>\n<polyline fill=\"none\" points=\"354,-2656.5 354,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416.5\" y=\"-2687.3\">(None, 16, 16, 64)</text>\n<polyline fill=\"none\" points=\"354,-2679.5 479,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416.5\" y=\"-2664.3\">(None, 16, 16, 64)</text>\n</g>\n<!-- 139695594291552&#45;&gt;139695595583136 -->\n<g class=\"edge\" id=\"edge20\">\n<title>139695594291552-&gt;139695595583136</title>\n<path d=\"M292.1142,-2739.3799C292.5097,-2731.1745 292.963,-2721.7679 293.3914,-2712.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"296.8924,-2712.9409 293.8779,-2702.784 289.9005,-2712.6039 296.8924,-2712.9409\" stroke=\"#000000\"/>\n</g>\n<!-- 139695595583136&#45;&gt;139695563080144 -->\n<g class=\"edge\" id=\"edge21\">\n<title>139695595583136-&gt;139695563080144</title>\n<path d=\"M325.084,-2656.3799C337.2695,-2647.0151 351.4911,-2636.0855 364.4243,-2626.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"366.9065,-2628.6527 372.7027,-2619.784 362.641,-2623.1025 366.9065,-2628.6527\" stroke=\"#000000\"/>\n</g>\n<!-- 139695562436904 -->\n<g class=\"node\" id=\"node21\">\n<title>139695562436904</title>\n<polygon fill=\"none\" points=\"176,-2490.5 176,-2536.5 630,-2536.5 630,-2490.5 176,-2490.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-2509.8\">batch_normalization_7: BatchNormalization</text>\n<polyline fill=\"none\" points=\"447,-2490.5 447,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476\" y=\"-2521.3\">input:</text>\n<polyline fill=\"none\" points=\"447,-2513.5 505,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476\" y=\"-2498.3\">output:</text>\n<polyline fill=\"none\" points=\"505,-2490.5 505,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-2521.3\">(None, 16, 16, 99)</text>\n<polyline fill=\"none\" points=\"505,-2513.5 630,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-2498.3\">(None, 16, 16, 99)</text>\n</g>\n<!-- 139695563080144&#45;&gt;139695562436904 -->\n<g class=\"edge\" id=\"edge23\">\n<title>139695563080144-&gt;139695562436904</title>\n<path d=\"M403,-2573.3799C403,-2565.1745 403,-2555.7679 403,-2546.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"406.5001,-2546.784 403,-2536.784 399.5001,-2546.784 406.5001,-2546.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695563082888 -->\n<g class=\"node\" id=\"node22\">\n<title>139695563082888</title>\n<polygon fill=\"none\" points=\"201,-2407.5 201,-2453.5 605,-2453.5 605,-2407.5 201,-2407.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-2426.8\">max_pooling2d_6: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"422,-2407.5 422,-2453.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451\" y=\"-2438.3\">input:</text>\n<polyline fill=\"none\" points=\"422,-2430.5 480,-2430.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"451\" y=\"-2415.3\">output:</text>\n<polyline fill=\"none\" points=\"480,-2407.5 480,-2453.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"542.5\" y=\"-2438.3\">(None, 16, 16, 99)</text>\n<polyline fill=\"none\" points=\"480,-2430.5 605,-2430.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"542.5\" y=\"-2415.3\">(None, 8, 8, 99)</text>\n</g>\n<!-- 139695562436904&#45;&gt;139695563082888 -->\n<g class=\"edge\" id=\"edge24\">\n<title>139695562436904-&gt;139695563082888</title>\n<path d=\"M403,-2490.3799C403,-2482.1745 403,-2472.7679 403,-2463.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"406.5001,-2463.784 403,-2453.784 399.5001,-2463.784 406.5001,-2463.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695563163184 -->\n<g class=\"node\" id=\"node23\">\n<title>139695563163184</title>\n<polygon fill=\"none\" points=\"147,-2324.5 147,-2370.5 455,-2370.5 455,-2324.5 147,-2324.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217\" y=\"-2343.8\">conv2d_24: Conv2D</text>\n<polyline fill=\"none\" points=\"287,-2324.5 287,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316\" y=\"-2355.3\">input:</text>\n<polyline fill=\"none\" points=\"287,-2347.5 345,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316\" y=\"-2332.3\">output:</text>\n<polyline fill=\"none\" points=\"345,-2324.5 345,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"400\" y=\"-2355.3\">(None, 8, 8, 99)</text>\n<polyline fill=\"none\" points=\"345,-2347.5 455,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"400\" y=\"-2332.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139695563082888&#45;&gt;139695563163184 -->\n<g class=\"edge\" id=\"edge25\">\n<title>139695563082888-&gt;139695563163184</title>\n<path d=\"M374.5873,-2407.3799C363.0788,-2398.0151 349.6473,-2387.0855 337.4327,-2377.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"339.5797,-2374.3809 329.6141,-2370.784 335.1615,-2379.8105 339.5797,-2374.3809\" stroke=\"#000000\"/>\n</g>\n<!-- 139695593303288 -->\n<g class=\"node\" id=\"node27\">\n<title>139695593303288</title>\n<polygon fill=\"none\" points=\"14.5,-1992.5 14.5,-2038.5 473.5,-2038.5 473.5,-1992.5 14.5,-1992.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.5\" y=\"-2011.8\">concatenate_11: Concatenate</text>\n<polyline fill=\"none\" points=\"196.5,-1992.5 196.5,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.5\" y=\"-2023.3\">input:</text>\n<polyline fill=\"none\" points=\"196.5,-2015.5 254.5,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.5\" y=\"-2000.3\">output:</text>\n<polyline fill=\"none\" points=\"254.5,-1992.5 254.5,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"364\" y=\"-2023.3\">[(None, 8, 8, 64), (None, 8, 8, 99)]</text>\n<polyline fill=\"none\" points=\"254.5,-2015.5 473.5,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"364\" y=\"-2000.3\">(None, 8, 8, 163)</text>\n</g>\n<!-- 139695563082888&#45;&gt;139695593303288 -->\n<g class=\"edge\" id=\"edge30\">\n<title>139695563082888-&gt;139695593303288</title>\n<path d=\"M434.3155,-2407.2861C445.4684,-2397.3623 456.99,-2384.8619 464,-2371 519.1841,-2261.8769 560.5755,-2205.8408 502,-2098.5\" fill=\"none\" stroke=\"#000000\"/>\n<path d=\"M502,-2098.5C484.5402,-2075.5955 424.7818,-2055.617 367.1712,-2041.0037\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"367.7523,-2037.5416 357.2029,-2038.5218 366.061,-2044.3342 367.7523,-2037.5416\" stroke=\"#000000\"/>\n</g>\n<!-- 139695592601752 -->\n<g class=\"node\" id=\"node32\">\n<title>139695592601752</title>\n<polygon fill=\"none\" points=\"161.5,-1577.5 161.5,-1623.5 628.5,-1623.5 628.5,-1577.5 161.5,-1577.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252.5\" y=\"-1596.8\">concatenate_12: Concatenate</text>\n<polyline fill=\"none\" points=\"343.5,-1577.5 343.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-1608.3\">input:</text>\n<polyline fill=\"none\" points=\"343.5,-1600.5 401.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-1585.3\">output:</text>\n<polyline fill=\"none\" points=\"401.5,-1577.5 401.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"515\" y=\"-1608.3\">[(None, 8, 8, 128), (None, 8, 8, 99)]</text>\n<polyline fill=\"none\" points=\"401.5,-1600.5 628.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"515\" y=\"-1585.3\">(None, 8, 8, 227)</text>\n</g>\n<!-- 139695563082888&#45;&gt;139695592601752 -->\n<g class=\"edge\" id=\"edge36\">\n<title>139695563082888-&gt;139695592601752</title>\n<path d=\"M502,-2098.5C457.2733,-2039.8256 502,-2006.2778 502,-1932.5 502,-1932.5 502,-1932.5 502,-1766.5 502,-1718.1673 506.5638,-1700.3784 480,-1660 472.1929,-1648.1327 461.1298,-1637.9307 449.5577,-1629.4941\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"451.3036,-1626.447 441.0807,-1623.6644 447.337,-1632.2148 451.3036,-1626.447\" stroke=\"#000000\"/>\n</g>\n<!-- 139695773739216 -->\n<g class=\"node\" id=\"node24\">\n<title>139695773739216</title>\n<polygon fill=\"none\" points=\"113.5,-2241.5 113.5,-2287.5 466.5,-2287.5 466.5,-2241.5 113.5,-2241.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-2260.8\">leaky_re_lu_24: LeakyReLU</text>\n<polyline fill=\"none\" points=\"298.5,-2241.5 298.5,-2287.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327.5\" y=\"-2272.3\">input:</text>\n<polyline fill=\"none\" points=\"298.5,-2264.5 356.5,-2264.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327.5\" y=\"-2249.3\">output:</text>\n<polyline fill=\"none\" points=\"356.5,-2241.5 356.5,-2287.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"411.5\" y=\"-2272.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"356.5,-2264.5 466.5,-2264.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"411.5\" y=\"-2249.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139695563163184&#45;&gt;139695773739216 -->\n<g class=\"edge\" id=\"edge26\">\n<title>139695563163184-&gt;139695773739216</title>\n<path d=\"M297.9359,-2324.3799C296.8484,-2316.1745 295.6018,-2306.7679 294.4237,-2297.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"297.8694,-2297.2375 293.0858,-2287.784 290.9301,-2298.1572 297.8694,-2297.2375\" stroke=\"#000000\"/>\n</g>\n<!-- 139695593555672 -->\n<g class=\"node\" id=\"node25\">\n<title>139695593555672</title>\n<polygon fill=\"none\" points=\"110,-2158.5 110,-2204.5 418,-2204.5 418,-2158.5 110,-2158.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-2177.8\">conv2d_25: Conv2D</text>\n<polyline fill=\"none\" points=\"250,-2158.5 250,-2204.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-2189.3\">input:</text>\n<polyline fill=\"none\" points=\"250,-2181.5 308,-2181.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-2166.3\">output:</text>\n<polyline fill=\"none\" points=\"308,-2158.5 308,-2204.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-2189.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"308,-2181.5 418,-2181.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-2166.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139695773739216&#45;&gt;139695593555672 -->\n<g class=\"edge\" id=\"edge27\">\n<title>139695773739216-&gt;139695593555672</title>\n<path d=\"M282.7576,-2241.3799C280.1593,-2233.0854 277.1764,-2223.5633 274.3652,-2214.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"277.6231,-2213.2805 271.2938,-2204.784 270.9432,-2215.373 277.6231,-2213.2805\" stroke=\"#000000\"/>\n</g>\n<!-- 139695593556512 -->\n<g class=\"node\" id=\"node26\">\n<title>139695593556512</title>\n<polygon fill=\"none\" points=\"74.5,-2075.5 74.5,-2121.5 427.5,-2121.5 427.5,-2075.5 74.5,-2075.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167\" y=\"-2094.8\">leaky_re_lu_25: LeakyReLU</text>\n<polyline fill=\"none\" points=\"259.5,-2075.5 259.5,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-2106.3\">input:</text>\n<polyline fill=\"none\" points=\"259.5,-2098.5 317.5,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-2083.3\">output:</text>\n<polyline fill=\"none\" points=\"317.5,-2075.5 317.5,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-2106.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"317.5,-2098.5 427.5,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-2083.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139695593555672&#45;&gt;139695593556512 -->\n<g class=\"edge\" id=\"edge28\">\n<title>139695593555672-&gt;139695593556512</title>\n<path d=\"M260.3788,-2158.3799C259.0936,-2150.1745 257.6203,-2140.7679 256.228,-2131.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"259.6522,-2131.1219 254.6469,-2121.784 252.7365,-2132.2052 259.6522,-2131.1219\" stroke=\"#000000\"/>\n</g>\n<!-- 139695593556512&#45;&gt;139695593303288 -->\n<g class=\"edge\" id=\"edge29\">\n<title>139695593556512-&gt;139695593303288</title>\n<path d=\"M249.0501,-2075.3799C248.3581,-2067.1745 247.5648,-2057.7679 246.8151,-2048.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"250.2918,-2048.4545 245.9637,-2038.784 243.3166,-2049.0428 250.2918,-2048.4545\" stroke=\"#000000\"/>\n</g>\n<!-- 139695593304016 -->\n<g class=\"node\" id=\"node28\">\n<title>139695593304016</title>\n<polygon fill=\"none\" points=\"111.5,-1909.5 111.5,-1955.5 426.5,-1955.5 426.5,-1909.5 111.5,-1909.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181.5\" y=\"-1928.8\">conv2d_26: Conv2D</text>\n<polyline fill=\"none\" points=\"251.5,-1909.5 251.5,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280.5\" y=\"-1940.3\">input:</text>\n<polyline fill=\"none\" points=\"251.5,-1932.5 309.5,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280.5\" y=\"-1917.3\">output:</text>\n<polyline fill=\"none\" points=\"309.5,-1909.5 309.5,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368\" y=\"-1940.3\">(None, 8, 8, 163)</text>\n<polyline fill=\"none\" points=\"309.5,-1932.5 426.5,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368\" y=\"-1917.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139695593303288&#45;&gt;139695593304016 -->\n<g class=\"edge\" id=\"edge31\">\n<title>139695593303288-&gt;139695593304016</title>\n<path d=\"M250.9639,-1992.3799C253.4622,-1984.0854 256.3303,-1974.5633 259.0335,-1965.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"262.4539,-1966.3685 261.9867,-1955.784 255.7513,-1964.3496 262.4539,-1966.3685\" stroke=\"#000000\"/>\n</g>\n<!-- 139695773739272 -->\n<g class=\"node\" id=\"node29\">\n<title>139695773739272</title>\n<polygon fill=\"none\" points=\"104.5,-1826.5 104.5,-1872.5 457.5,-1872.5 457.5,-1826.5 104.5,-1826.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197\" y=\"-1845.8\">leaky_re_lu_26: LeakyReLU</text>\n<polyline fill=\"none\" points=\"289.5,-1826.5 289.5,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318.5\" y=\"-1857.3\">input:</text>\n<polyline fill=\"none\" points=\"289.5,-1849.5 347.5,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318.5\" y=\"-1834.3\">output:</text>\n<polyline fill=\"none\" points=\"347.5,-1826.5 347.5,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402.5\" y=\"-1857.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"347.5,-1849.5 457.5,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402.5\" y=\"-1834.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139695593304016&#45;&gt;139695773739272 -->\n<g class=\"edge\" id=\"edge32\">\n<title>139695593304016-&gt;139695773739272</title>\n<path d=\"M272.3427,-1909.3799C273.529,-1901.1745 274.889,-1891.7679 276.1742,-1882.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"279.6666,-1883.1819 277.6336,-1872.784 272.7387,-1882.1803 279.6666,-1883.1819\" stroke=\"#000000\"/>\n</g>\n<!-- 139695592963320 -->\n<g class=\"node\" id=\"node30\">\n<title>139695592963320</title>\n<polygon fill=\"none\" points=\"129.5,-1743.5 129.5,-1789.5 444.5,-1789.5 444.5,-1743.5 129.5,-1743.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-1762.8\">conv2d_27: Conv2D</text>\n<polyline fill=\"none\" points=\"269.5,-1743.5 269.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.5\" y=\"-1774.3\">input:</text>\n<polyline fill=\"none\" points=\"269.5,-1766.5 327.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.5\" y=\"-1751.3\">output:</text>\n<polyline fill=\"none\" points=\"327.5,-1743.5 327.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"386\" y=\"-1774.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"327.5,-1766.5 444.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"386\" y=\"-1751.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 139695773739272&#45;&gt;139695592963320 -->\n<g class=\"edge\" id=\"edge33\">\n<title>139695773739272-&gt;139695592963320</title>\n<path d=\"M282.6713,-1826.3799C283.2645,-1818.1745 283.9445,-1808.7679 284.5871,-1799.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"288.0866,-1800.0104 285.3168,-1789.784 281.1048,-1799.5056 288.0866,-1800.0104\" stroke=\"#000000\"/>\n</g>\n<!-- 139695592960912 -->\n<g class=\"node\" id=\"node31\">\n<title>139695592960912</title>\n<polygon fill=\"none\" points=\"111,-1660.5 111,-1706.5 471,-1706.5 471,-1660.5 111,-1660.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-1679.8\">leaky_re_lu_27: LeakyReLU</text>\n<polyline fill=\"none\" points=\"296,-1660.5 296,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"325\" y=\"-1691.3\">input:</text>\n<polyline fill=\"none\" points=\"296,-1683.5 354,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"325\" y=\"-1668.3\">output:</text>\n<polyline fill=\"none\" points=\"354,-1660.5 354,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-1691.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"354,-1683.5 471,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-1668.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 139695592963320&#45;&gt;139695592960912 -->\n<g class=\"edge\" id=\"edge34\">\n<title>139695592963320-&gt;139695592960912</title>\n<path d=\"M288.1142,-1743.3799C288.5097,-1735.1745 288.963,-1725.7679 289.3914,-1716.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"292.8924,-1716.9409 289.8779,-1706.784 285.9005,-1716.6039 292.8924,-1716.9409\" stroke=\"#000000\"/>\n</g>\n<!-- 139695592960912&#45;&gt;139695592601752 -->\n<g class=\"edge\" id=\"edge35\">\n<title>139695592960912-&gt;139695592601752</title>\n<path d=\"M319.9698,-1660.3799C331.704,-1651.0151 345.3989,-1640.0855 357.853,-1630.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"360.1921,-1632.7574 365.8249,-1623.784 355.8256,-1627.2862 360.1921,-1632.7574\" stroke=\"#000000\"/>\n</g>\n<!-- 139695593302784 -->\n<g class=\"node\" id=\"node33\">\n<title>139695593302784</title>\n<polygon fill=\"none\" points=\"172,-1494.5 172,-1540.5 618,-1540.5 618,-1494.5 172,-1494.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307.5\" y=\"-1513.8\">batch_normalization_8: BatchNormalization</text>\n<polyline fill=\"none\" points=\"443,-1494.5 443,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472\" y=\"-1525.3\">input:</text>\n<polyline fill=\"none\" points=\"443,-1517.5 501,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472\" y=\"-1502.3\">output:</text>\n<polyline fill=\"none\" points=\"501,-1494.5 501,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559.5\" y=\"-1525.3\">(None, 8, 8, 227)</text>\n<polyline fill=\"none\" points=\"501,-1517.5 618,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559.5\" y=\"-1502.3\">(None, 8, 8, 227)</text>\n</g>\n<!-- 139695592601752&#45;&gt;139695593302784 -->\n<g class=\"edge\" id=\"edge37\">\n<title>139695592601752-&gt;139695593302784</title>\n<path d=\"M395,-1577.3799C395,-1569.1745 395,-1559.7679 395,-1550.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.5001,-1550.784 395,-1540.784 391.5001,-1550.784 398.5001,-1550.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695592599904 -->\n<g class=\"node\" id=\"node34\">\n<title>139695592599904</title>\n<polygon fill=\"none\" points=\"197,-1411.5 197,-1457.5 593,-1457.5 593,-1411.5 197,-1411.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307.5\" y=\"-1430.8\">max_pooling2d_7: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"418,-1411.5 418,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"447\" y=\"-1442.3\">input:</text>\n<polyline fill=\"none\" points=\"418,-1434.5 476,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"447\" y=\"-1419.3\">output:</text>\n<polyline fill=\"none\" points=\"476,-1411.5 476,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"534.5\" y=\"-1442.3\">(None, 8, 8, 227)</text>\n<polyline fill=\"none\" points=\"476,-1434.5 593,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"534.5\" y=\"-1419.3\">(None, 4, 4, 227)</text>\n</g>\n<!-- 139695593302784&#45;&gt;139695592599904 -->\n<g class=\"edge\" id=\"edge38\">\n<title>139695593302784-&gt;139695592599904</title>\n<path d=\"M395,-1494.3799C395,-1486.1745 395,-1476.7679 395,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"398.5001,-1467.784 395,-1457.784 391.5001,-1467.784 398.5001,-1467.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695592602032 -->\n<g class=\"node\" id=\"node35\">\n<title>139695592602032</title>\n<polygon fill=\"none\" points=\"144.5,-1328.5 144.5,-1374.5 459.5,-1374.5 459.5,-1328.5 144.5,-1328.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214.5\" y=\"-1347.8\">conv2d_28: Conv2D</text>\n<polyline fill=\"none\" points=\"284.5,-1328.5 284.5,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-1359.3\">input:</text>\n<polyline fill=\"none\" points=\"284.5,-1351.5 342.5,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-1336.3\">output:</text>\n<polyline fill=\"none\" points=\"342.5,-1328.5 342.5,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401\" y=\"-1359.3\">(None, 4, 4, 227)</text>\n<polyline fill=\"none\" points=\"342.5,-1351.5 459.5,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401\" y=\"-1336.3\">(None, 4, 4, 128)</text>\n</g>\n<!-- 139695592599904&#45;&gt;139695592602032 -->\n<g class=\"edge\" id=\"edge39\">\n<title>139695592599904-&gt;139695592602032</title>\n<path d=\"M369.0943,-1411.3799C358.8011,-1402.1935 346.8208,-1391.5013 335.8556,-1381.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"337.8806,-1378.8313 328.0893,-1374.784 333.2196,-1384.0539 337.8806,-1378.8313\" stroke=\"#000000\"/>\n</g>\n<!-- 139695591717800 -->\n<g class=\"node\" id=\"node39\">\n<title>139695591717800</title>\n<polygon fill=\"none\" points=\"0,-996.5 0,-1042.5 474,-1042.5 474,-996.5 0,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"91\" y=\"-1015.8\">concatenate_13: Concatenate</text>\n<polyline fill=\"none\" points=\"182,-996.5 182,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"182,-1019.5 240,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"240,-996.5 240,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357\" y=\"-1027.3\">[(None, 4, 4, 128), (None, 4, 4, 227)]</text>\n<polyline fill=\"none\" points=\"240,-1019.5 474,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357\" y=\"-1004.3\">(None, 4, 4, 355)</text>\n</g>\n<!-- 139695592599904&#45;&gt;139695591717800 -->\n<g class=\"edge\" id=\"edge44\">\n<title>139695592599904-&gt;139695591717800</title>\n<path d=\"M434.0825,-1411.3662C446.9532,-1401.7572 460.0029,-1389.448 468,-1375 527.1056,-1268.2162 561.1118,-1209.2803 502,-1102.5\" fill=\"none\" stroke=\"#000000\"/>\n<path d=\"M502,-1102.5C483.7835,-1079.4249 422.7783,-1059.498 363.8888,-1044.957\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"364.6242,-1041.5339 354.081,-1042.5789 362.9747,-1048.3368 364.6242,-1041.5339\" stroke=\"#000000\"/>\n</g>\n<!-- 139695591460648 -->\n<g class=\"node\" id=\"node44\">\n<title>139695591460648</title>\n<polygon fill=\"none\" points=\"161,-581.5 161,-627.5 635,-627.5 635,-581.5 161,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252\" y=\"-600.8\">concatenate_14: Concatenate</text>\n<polyline fill=\"none\" points=\"343,-581.5 343,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"343,-604.5 401,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"401,-581.5 401,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"518\" y=\"-612.3\">[(None, 4, 4, 256), (None, 4, 4, 227)]</text>\n<polyline fill=\"none\" points=\"401,-604.5 635,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"518\" y=\"-589.3\">(None, 4, 4, 483)</text>\n</g>\n<!-- 139695592599904&#45;&gt;139695591460648 -->\n<g class=\"edge\" id=\"edge50\">\n<title>139695592599904-&gt;139695591460648</title>\n<path d=\"M502,-1102.5C479.1426,-1073.5461 502,-973.3889 502,-936.5 502,-936.5 502,-936.5 502,-770.5 502,-722.4193 508.8774,-704.523 483,-664 475.3547,-652.0278 464.3539,-641.7855 452.7902,-633.3434\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"454.5342,-630.2951 444.3106,-627.5154 450.5693,-636.064 454.5342,-630.2951\" stroke=\"#000000\"/>\n</g>\n<!-- 139695592717784 -->\n<g class=\"node\" id=\"node36\">\n<title>139695592717784</title>\n<polygon fill=\"none\" points=\"107,-1245.5 107,-1291.5 467,-1291.5 467,-1245.5 107,-1245.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-1264.8\">leaky_re_lu_28: LeakyReLU</text>\n<polyline fill=\"none\" points=\"292,-1245.5 292,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1276.3\">input:</text>\n<polyline fill=\"none\" points=\"292,-1268.5 350,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1253.3\">output:</text>\n<polyline fill=\"none\" points=\"350,-1245.5 350,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-1276.3\">(None, 4, 4, 128)</text>\n<polyline fill=\"none\" points=\"350,-1268.5 467,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-1253.3\">(None, 4, 4, 128)</text>\n</g>\n<!-- 139695592602032&#45;&gt;139695592717784 -->\n<g class=\"edge\" id=\"edge40\">\n<title>139695592602032-&gt;139695592717784</title>\n<path d=\"M297.8217,-1328.3799C296.3388,-1320.1745 294.6388,-1310.7679 293.0323,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"296.4307,-1301.0021 291.208,-1291.784 289.5422,-1302.2471 296.4307,-1301.0021\" stroke=\"#000000\"/>\n</g>\n<!-- 139695592005136 -->\n<g class=\"node\" id=\"node37\">\n<title>139695592005136</title>\n<polygon fill=\"none\" points=\"121.5,-1162.5 121.5,-1208.5 436.5,-1208.5 436.5,-1162.5 121.5,-1162.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191.5\" y=\"-1181.8\">conv2d_29: Conv2D</text>\n<polyline fill=\"none\" points=\"261.5,-1162.5 261.5,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1193.3\">input:</text>\n<polyline fill=\"none\" points=\"261.5,-1185.5 319.5,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1170.3\">output:</text>\n<polyline fill=\"none\" points=\"319.5,-1162.5 319.5,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"378\" y=\"-1193.3\">(None, 4, 4, 128)</text>\n<polyline fill=\"none\" points=\"319.5,-1185.5 436.5,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"378\" y=\"-1170.3\">(None, 4, 4, 128)</text>\n</g>\n<!-- 139695592717784&#45;&gt;139695592005136 -->\n<g class=\"edge\" id=\"edge41\">\n<title>139695592717784-&gt;139695592005136</title>\n<path d=\"M284.7716,-1245.3799C283.9807,-1237.1745 283.074,-1227.7679 282.2172,-1218.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"285.6876,-1218.4021 281.2442,-1208.784 278.7199,-1219.0737 285.6876,-1218.4021\" stroke=\"#000000\"/>\n</g>\n<!-- 139695592001888 -->\n<g class=\"node\" id=\"node38\">\n<title>139695592001888</title>\n<polygon fill=\"none\" points=\"71,-1079.5 71,-1125.5 431,-1125.5 431,-1079.5 71,-1079.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-1098.8\">leaky_re_lu_29: LeakyReLU</text>\n<polyline fill=\"none\" points=\"256,-1079.5 256,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285\" y=\"-1110.3\">input:</text>\n<polyline fill=\"none\" points=\"256,-1102.5 314,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285\" y=\"-1087.3\">output:</text>\n<polyline fill=\"none\" points=\"314,-1079.5 314,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-1110.3\">(None, 4, 4, 128)</text>\n<polyline fill=\"none\" points=\"314,-1102.5 431,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-1087.3\">(None, 4, 4, 128)</text>\n</g>\n<!-- 139695592005136&#45;&gt;139695592001888 -->\n<g class=\"edge\" id=\"edge42\">\n<title>139695592005136-&gt;139695592001888</title>\n<path d=\"M271.2004,-1162.3799C268.3722,-1153.9962 265.1209,-1144.3584 262.0649,-1135.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"265.3678,-1134.1406 258.8548,-1125.784 258.735,-1136.3782 265.3678,-1134.1406\" stroke=\"#000000\"/>\n</g>\n<!-- 139695592001888&#45;&gt;139695591717800 -->\n<g class=\"edge\" id=\"edge43\">\n<title>139695592001888-&gt;139695591717800</title>\n<path d=\"M247.1002,-1079.3799C245.7162,-1071.1745 244.1295,-1061.7679 242.6301,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"246.042,-1052.0625 240.9274,-1042.784 239.1395,-1053.2269 246.042,-1052.0625\" stroke=\"#000000\"/>\n</g>\n<!-- 139695591715616 -->\n<g class=\"node\" id=\"node40\">\n<title>139695591715616</title>\n<polygon fill=\"none\" points=\"94.5,-913.5 94.5,-959.5 409.5,-959.5 409.5,-913.5 94.5,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-932.8\">conv2d_30: Conv2D</text>\n<polyline fill=\"none\" points=\"234.5,-913.5 234.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"234.5,-936.5 292.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"292.5,-913.5 292.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-944.3\">(None, 4, 4, 355)</text>\n<polyline fill=\"none\" points=\"292.5,-936.5 409.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-921.3\">(None, 4, 4, 128)</text>\n</g>\n<!-- 139695591717800&#45;&gt;139695591715616 -->\n<g class=\"edge\" id=\"edge45\">\n<title>139695591717800-&gt;139695591715616</title>\n<path d=\"M241.1783,-996.3799C242.6612,-988.1745 244.3612,-978.7679 245.9677,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"249.4578,-970.2471 247.792,-959.784 242.5693,-969.0021 249.4578,-970.2471\" stroke=\"#000000\"/>\n</g>\n<!-- 139695592715936 -->\n<g class=\"node\" id=\"node41\">\n<title>139695592715936</title>\n<polygon fill=\"none\" points=\"100,-830.5 100,-876.5 460,-876.5 460,-830.5 100,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-849.8\">leaky_re_lu_30: LeakyReLU</text>\n<polyline fill=\"none\" points=\"285,-830.5 285,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"285,-853.5 343,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"343,-830.5 343,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-861.3\">(None, 4, 4, 128)</text>\n<polyline fill=\"none\" points=\"343,-853.5 460,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-838.3\">(None, 4, 4, 128)</text>\n</g>\n<!-- 139695591715616&#45;&gt;139695592715936 -->\n<g class=\"edge\" id=\"edge46\">\n<title>139695591715616-&gt;139695592715936</title>\n<path d=\"M259.7996,-913.3799C262.6278,-904.9962 265.8791,-895.3584 268.9351,-886.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"272.265,-887.3782 272.1452,-876.784 265.6322,-885.1406 272.265,-887.3782\" stroke=\"#000000\"/>\n</g>\n<!-- 139695591362800 -->\n<g class=\"node\" id=\"node42\">\n<title>139695591362800</title>\n<polygon fill=\"none\" points=\"136.5,-747.5 136.5,-793.5 451.5,-793.5 451.5,-747.5 136.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206.5\" y=\"-766.8\">conv2d_31: Conv2D</text>\n<polyline fill=\"none\" points=\"276.5,-747.5 276.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"276.5,-770.5 334.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"334.5,-747.5 334.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-778.3\">(None, 4, 4, 128)</text>\n<polyline fill=\"none\" points=\"334.5,-770.5 451.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-755.3\">(None, 4, 4, 256)</text>\n</g>\n<!-- 139695592715936&#45;&gt;139695591362800 -->\n<g class=\"edge\" id=\"edge47\">\n<title>139695592715936-&gt;139695591362800</title>\n<path d=\"M283.8998,-830.3799C285.2838,-822.1745 286.8705,-812.7679 288.3699,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"291.8605,-804.2269 290.0726,-793.784 284.958,-803.0625 291.8605,-804.2269\" stroke=\"#000000\"/>\n</g>\n<!-- 139695591364536 -->\n<g class=\"node\" id=\"node43\">\n<title>139695591364536</title>\n<polygon fill=\"none\" points=\"114,-664.5 114,-710.5 474,-710.5 474,-664.5 114,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206.5\" y=\"-683.8\">leaky_re_lu_31: LeakyReLU</text>\n<polyline fill=\"none\" points=\"299,-664.5 299,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"299,-687.5 357,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"357,-664.5 357,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"415.5\" y=\"-695.3\">(None, 4, 4, 256)</text>\n<polyline fill=\"none\" points=\"357,-687.5 474,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"415.5\" y=\"-672.3\">(None, 4, 4, 256)</text>\n</g>\n<!-- 139695591362800&#45;&gt;139695591364536 -->\n<g class=\"edge\" id=\"edge48\">\n<title>139695591362800-&gt;139695591364536</title>\n<path d=\"M294,-747.3799C294,-739.1745 294,-729.7679 294,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"297.5001,-720.784 294,-710.784 290.5001,-720.784 297.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695591364536&#45;&gt;139695591460648 -->\n<g class=\"edge\" id=\"edge49\">\n<title>139695591364536-&gt;139695591460648</title>\n<path d=\"M322.9698,-664.3799C334.704,-655.0151 348.3989,-644.0855 360.853,-634.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"363.1921,-636.7574 368.8249,-627.784 358.8256,-631.2862 363.1921,-636.7574\" stroke=\"#000000\"/>\n</g>\n<!-- 139695591715896 -->\n<g class=\"node\" id=\"node45\">\n<title>139695591715896</title>\n<polygon fill=\"none\" points=\"175,-498.5 175,-544.5 621,-544.5 621,-498.5 175,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-517.8\">batch_normalization_9: BatchNormalization</text>\n<polyline fill=\"none\" points=\"446,-498.5 446,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"475\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"446,-521.5 504,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"475\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"504,-498.5 504,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-529.3\">(None, 4, 4, 483)</text>\n<polyline fill=\"none\" points=\"504,-521.5 621,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562.5\" y=\"-506.3\">(None, 4, 4, 483)</text>\n</g>\n<!-- 139695591460648&#45;&gt;139695591715896 -->\n<g class=\"edge\" id=\"edge51\">\n<title>139695591460648-&gt;139695591715896</title>\n<path d=\"M398,-581.3799C398,-573.1745 398,-563.7679 398,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"401.5001,-554.784 398,-544.784 394.5001,-554.784 401.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695591458912 -->\n<g class=\"node\" id=\"node46\">\n<title>139695591458912</title>\n<polygon fill=\"none\" points=\"200,-415.5 200,-461.5 596,-461.5 596,-415.5 200,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-434.8\">max_pooling2d_8: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"421,-415.5 421,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"421,-438.5 479,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"479,-415.5 479,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"537.5\" y=\"-446.3\">(None, 4, 4, 483)</text>\n<polyline fill=\"none\" points=\"479,-438.5 596,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"537.5\" y=\"-423.3\">(None, 2, 2, 483)</text>\n</g>\n<!-- 139695591715896&#45;&gt;139695591458912 -->\n<g class=\"edge\" id=\"edge52\">\n<title>139695591715896-&gt;139695591458912</title>\n<path d=\"M398,-498.3799C398,-490.1745 398,-480.7679 398,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"401.5001,-471.784 398,-461.784 394.5001,-471.784 401.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695591111648 -->\n<g class=\"node\" id=\"node47\">\n<title>139695591111648</title>\n<polygon fill=\"none\" points=\"240.5,-332.5 240.5,-378.5 555.5,-378.5 555.5,-332.5 240.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-351.8\">conv2d_32: Conv2D</text>\n<polyline fill=\"none\" points=\"380.5,-332.5 380.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"380.5,-355.5 438.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"438.5,-332.5 438.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-363.3\">(None, 2, 2, 483)</text>\n<polyline fill=\"none\" points=\"438.5,-355.5 555.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-340.3\">(None, 2, 2, 128)</text>\n</g>\n<!-- 139695591458912&#45;&gt;139695591111648 -->\n<g class=\"edge\" id=\"edge53\">\n<title>139695591458912-&gt;139695591111648</title>\n<path d=\"M398,-415.3799C398,-407.1745 398,-397.7679 398,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"401.5001,-388.784 398,-378.784 394.5001,-388.784 401.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695591460760 -->\n<g class=\"node\" id=\"node48\">\n<title>139695591460760</title>\n<polygon fill=\"none\" points=\"218,-249.5 218,-295.5 578,-295.5 578,-249.5 218,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-268.8\">leaky_re_lu_32: LeakyReLU</text>\n<polyline fill=\"none\" points=\"403,-249.5 403,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"432\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"403,-272.5 461,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"432\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"461,-249.5 461,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"519.5\" y=\"-280.3\">(None, 2, 2, 128)</text>\n<polyline fill=\"none\" points=\"461,-272.5 578,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"519.5\" y=\"-257.3\">(None, 2, 2, 128)</text>\n</g>\n<!-- 139695591111648&#45;&gt;139695591460760 -->\n<g class=\"edge\" id=\"edge54\">\n<title>139695591111648-&gt;139695591460760</title>\n<path d=\"M398,-332.3799C398,-324.1745 398,-314.7679 398,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"401.5001,-305.784 398,-295.784 394.5001,-305.784 401.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695590278536 -->\n<g class=\"node\" id=\"node49\">\n<title>139695590278536</title>\n<polygon fill=\"none\" points=\"171.5,-166.5 171.5,-212.5 624.5,-212.5 624.5,-166.5 171.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-185.8\">batch_normalization_10: BatchNormalization</text>\n<polyline fill=\"none\" points=\"449.5,-166.5 449.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"478.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"449.5,-189.5 507.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"478.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"507.5,-166.5 507.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"566\" y=\"-197.3\">(None, 2, 2, 128)</text>\n<polyline fill=\"none\" points=\"507.5,-189.5 624.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"566\" y=\"-174.3\">(None, 2, 2, 128)</text>\n</g>\n<!-- 139695591460760&#45;&gt;139695590278536 -->\n<g class=\"edge\" id=\"edge55\">\n<title>139695591460760-&gt;139695590278536</title>\n<path d=\"M398,-249.3799C398,-241.1745 398,-231.7679 398,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"401.5001,-222.784 398,-212.784 394.5001,-222.784 401.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695591111760 -->\n<g class=\"node\" id=\"node50\">\n<title>139695591111760</title>\n<polygon fill=\"none\" points=\"138.5,-83.5 138.5,-129.5 657.5,-129.5 657.5,-83.5 138.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-102.8\">global_average_pooling2d_2: GlobalAveragePooling2D</text>\n<polyline fill=\"none\" points=\"482.5,-83.5 482.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"511.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"482.5,-106.5 540.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"511.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"540.5,-83.5 540.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"599\" y=\"-114.3\">(None, 2, 2, 128)</text>\n<polyline fill=\"none\" points=\"540.5,-106.5 657.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"599\" y=\"-91.3\">(None, 128)</text>\n</g>\n<!-- 139695590278536&#45;&gt;139695591111760 -->\n<g class=\"edge\" id=\"edge56\">\n<title>139695590278536-&gt;139695591111760</title>\n<path d=\"M398,-166.3799C398,-158.1745 398,-148.7679 398,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"401.5001,-139.784 398,-129.784 394.5001,-139.784 401.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139695590458200 -->\n<g class=\"node\" id=\"node51\">\n<title>139695590458200</title>\n<polygon fill=\"none\" points=\"272,-.5 272,-46.5 524,-46.5 524,-.5 272,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"325.5\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"379,-.5 379,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"379,-23.5 437,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"437,-.5 437,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480.5\" y=\"-31.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"437,-23.5 524,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480.5\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 139695591111760&#45;&gt;139695590458200 -->\n<g class=\"edge\" id=\"edge57\">\n<title>139695591111760-&gt;139695590458200</title>\n<path d=\"M398,-83.3799C398,-75.1745 398,-65.7679 398,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"401.5001,-56.784 398,-46.784 394.5001,-56.784 401.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP4gOc0MJFvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        zca_whitening=False,  # 应用ZCA白化\n",
        "        rotation_range=10,  # 在一个范围下随机旋转图像(degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # 水平随机移位图像（总宽度的分数）\n",
        "        height_shift_range=0.1,  # 随机地垂直移动图像（总高度的分数）\n",
        "        horizontal_flip=True,  # 随机翻转图像\n",
        "        vertical_flip=False)  # 随机翻转图像\n",
        "\n",
        "    # 计算特征方向归一化所需的数量\n",
        "    # (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTxx83NeJFpU",
        "colab_type": "code",
        "outputId": "95877983-f6c2-4637-a55f-a80754ce5b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4681
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD, Nadam\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_13.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=7, verbose=1, min_lr=1e-7)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "# optimizer = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=1e-6)\n",
        "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                        batch_size=128),\n",
        "                        samples_per_epoch=x_train.shape[0],\n",
        "                        nb_epoch=100,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=390, epochs=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 1.2108 - acc: 0.5678 - val_loss: 1.5500 - val_acc: 0.5730\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.57300, saving model to cifar10_model_13.h5\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 26s 66ms/step - loss: 0.7965 - acc: 0.7222 - val_loss: 0.9563 - val_acc: 0.6899\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.57300 to 0.68990, saving model to cifar10_model_13.h5\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.6715 - acc: 0.7663 - val_loss: 0.6955 - val_acc: 0.7654\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.68990 to 0.76540, saving model to cifar10_model_13.h5\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.6028 - acc: 0.7911 - val_loss: 0.7727 - val_acc: 0.7541\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.76540\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.5515 - acc: 0.8093 - val_loss: 0.8937 - val_acc: 0.7352\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.76540\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.5101 - acc: 0.8245 - val_loss: 0.8840 - val_acc: 0.7278\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.76540\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.4817 - acc: 0.8322 - val_loss: 0.5340 - val_acc: 0.8178\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.76540 to 0.81780, saving model to cifar10_model_13.h5\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.4509 - acc: 0.8440 - val_loss: 0.6096 - val_acc: 0.7894\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.81780\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.4293 - acc: 0.8496 - val_loss: 0.7210 - val_acc: 0.7685\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.81780\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.4118 - acc: 0.8547 - val_loss: 0.5650 - val_acc: 0.8166\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.81780\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3972 - acc: 0.8604 - val_loss: 0.4847 - val_acc: 0.8349\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.81780 to 0.83490, saving model to cifar10_model_13.h5\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.3763 - acc: 0.8684 - val_loss: 0.5950 - val_acc: 0.8218\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.83490\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.3612 - acc: 0.8730 - val_loss: 0.4246 - val_acc: 0.8590\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.83490 to 0.85900, saving model to cifar10_model_13.h5\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.3567 - acc: 0.8748 - val_loss: 0.5008 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.85900\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3386 - acc: 0.8806 - val_loss: 0.5212 - val_acc: 0.8312\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.85900\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.3258 - acc: 0.8871 - val_loss: 0.5469 - val_acc: 0.8312\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.85900\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3161 - acc: 0.8908 - val_loss: 0.4509 - val_acc: 0.8538\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.85900\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.3049 - acc: 0.8930 - val_loss: 0.4513 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.85900\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.2980 - acc: 0.8957 - val_loss: 0.4906 - val_acc: 0.8481\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.85900\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.2912 - acc: 0.8971 - val_loss: 0.5551 - val_acc: 0.8382\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.85900\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.2198 - acc: 0.9240 - val_loss: 0.3754 - val_acc: 0.8802\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.85900 to 0.88020, saving model to cifar10_model_13.h5\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1871 - acc: 0.9350 - val_loss: 0.3547 - val_acc: 0.8870\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.88020 to 0.88700, saving model to cifar10_model_13.h5\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.1755 - acc: 0.9384 - val_loss: 0.3746 - val_acc: 0.8830\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.88700\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.1696 - acc: 0.9406 - val_loss: 0.3344 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.88700 to 0.89190, saving model to cifar10_model_13.h5\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1614 - acc: 0.9436 - val_loss: 0.3704 - val_acc: 0.8843\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.89190\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1502 - acc: 0.9474 - val_loss: 0.3733 - val_acc: 0.8873\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.89190\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1500 - acc: 0.9471 - val_loss: 0.3569 - val_acc: 0.8899\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.89190\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1408 - acc: 0.9501 - val_loss: 0.3447 - val_acc: 0.8960\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.89190 to 0.89600, saving model to cifar10_model_13.h5\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1356 - acc: 0.9515 - val_loss: 0.3609 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.89600\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1307 - acc: 0.9535 - val_loss: 0.3593 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.89600\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1257 - acc: 0.9549 - val_loss: 0.3451 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.89600 to 0.89700, saving model to cifar10_model_13.h5\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1219 - acc: 0.9563 - val_loss: 0.3820 - val_acc: 0.8853\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.89700\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1218 - acc: 0.9579 - val_loss: 0.3574 - val_acc: 0.8948\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.89700\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.1160 - acc: 0.9590 - val_loss: 0.3828 - val_acc: 0.8902\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.89700\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.1146 - acc: 0.9596 - val_loss: 0.3897 - val_acc: 0.8909\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.89700\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1125 - acc: 0.9600 - val_loss: 0.3741 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.89700\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.1077 - acc: 0.9610 - val_loss: 0.3813 - val_acc: 0.8941\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.89700\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.1045 - acc: 0.9635 - val_loss: 0.4274 - val_acc: 0.8870\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.89700\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.0889 - acc: 0.9683 - val_loss: 0.3703 - val_acc: 0.8965\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.89700\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.0869 - acc: 0.9697 - val_loss: 0.3791 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.89700\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.0821 - acc: 0.9719 - val_loss: 0.3723 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00041: val_acc improved from 0.89700 to 0.89740, saving model to cifar10_model_13.h5\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.0772 - acc: 0.9735 - val_loss: 0.3640 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.89740 to 0.89780, saving model to cifar10_model_13.h5\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.0787 - acc: 0.9722 - val_loss: 0.3713 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00043: val_acc improved from 0.89780 to 0.89800, saving model to cifar10_model_13.h5\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.0776 - acc: 0.9726 - val_loss: 0.3740 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.89800\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.0757 - acc: 0.9735 - val_loss: 0.3651 - val_acc: 0.9006\n",
            "\n",
            "Epoch 00045: val_acc improved from 0.89800 to 0.90060, saving model to cifar10_model_13.h5\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.0748 - acc: 0.9737 - val_loss: 0.3741 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.90060\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.0729 - acc: 0.9751 - val_loss: 0.3764 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.90060\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.0723 - acc: 0.9749 - val_loss: 0.3724 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.90060\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.0707 - acc: 0.9752 - val_loss: 0.3814 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.90060\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.0715 - acc: 0.9743 - val_loss: 0.3874 - val_acc: 0.8956\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.90060\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.0684 - acc: 0.9761 - val_loss: 0.3705 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.90060\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.0679 - acc: 0.9764 - val_loss: 0.3714 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00052: val_acc improved from 0.90060 to 0.90130, saving model to cifar10_model_13.h5\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.0668 - acc: 0.9772 - val_loss: 0.3831 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.90130\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.0680 - acc: 0.9762 - val_loss: 0.3786 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.90130\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.0652 - acc: 0.9768 - val_loss: 0.3948 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.90130\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.0670 - acc: 0.9769 - val_loss: 0.3902 - val_acc: 0.8972\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.90130\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.0640 - acc: 0.9781 - val_loss: 0.3993 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.90130\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.0641 - acc: 0.9775 - val_loss: 0.3826 - val_acc: 0.9008\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.90130\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.0664 - acc: 0.9775 - val_loss: 0.3843 - val_acc: 0.9003\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.90130\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.0630 - acc: 0.9777 - val_loss: 0.3825 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.90130\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.0592 - acc: 0.9800 - val_loss: 0.3860 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.90130\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.0608 - acc: 0.9790 - val_loss: 0.3876 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.90130\n",
            "Epoch 00062: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d683e9f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15XxeAQhJFjy",
        "colab_type": "code",
        "outputId": "594eee94-986d-416b-89e4-75d922ba7e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_13.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 136us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37144944324493406, 0.9013]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bUQdBRrVr9m",
        "colab_type": "code",
        "outputId": "3562a86f-ac09-4295-9f6a-a523635589c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2681
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, add, Conv2D, SeparableConv2D, MaxPool2D, Dropout, Dense, GlobalAveragePooling2D, BatchNormalization, concatenate\n",
        "from keras import layers, models\n",
        "from keras.layers import LeakyReLU, ThresholdedReLU, Softmax, ReLU, Activation, Reshape, Lambda, ActivityRegularization\n",
        "\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "temp = inputs\n",
        "x = Conv2D(16, (3, 3), padding='same')(inputs)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "temp = x\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = concatenate([x, temp])\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "\n",
        "x1 = Conv2D(16, (3, 3), padding='same', strides=2)(inputs)\n",
        "x1 = LeakyReLU(0.1)(x1)\n",
        "x = concatenate([x, temp, x1])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "temp = x\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = concatenate([x, temp])\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "\n",
        "x2 = Conv2D(16, (5, 5), padding='same', strides=4)(inputs)\n",
        "x2 = LeakyReLU(0.1)(x2)\n",
        "x3 = Conv2D(16, (3, 3), padding='same', strides=2)(x1)\n",
        "x3 = LeakyReLU(0.1)(x3)\n",
        "x = concatenate([x, x2, x3, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "temp = x\n",
        "x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = concatenate([x, temp])\n",
        "x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x1 = Conv2D(16, (5, 5), padding='same', strides=4)(x1)\n",
        "x1 = LeakyReLU(0.1)(x1)\n",
        "x4 = Conv2D(16, (3, 3), padding='same', strides=2)(x2)\n",
        "x4 = LeakyReLU(0.1)(x4)\n",
        "x5 = Conv2D(16, (3, 3), padding='same', strides=2)(x3)\n",
        "x5 = LeakyReLU(0.1)(x5)\n",
        "x = concatenate([x, x1, x4, x5, temp])\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Conv2D(512, (3, 3))(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = Conv2D(256, (1, 1), padding='same')(x)\n",
        "x = LeakyReLU(0.1)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=x)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 32, 32, 16)   448         input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_207 (LeakyReLU)     (None, 32, 32, 16)   0           conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 32, 32, 16)   2320        leaky_re_lu_207[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_208 (LeakyReLU)     (None, 32, 32, 16)   0           conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 32, 32, 32)   4640        leaky_re_lu_208[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_209 (LeakyReLU)     (None, 32, 32, 32)   0           conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 32, 32, 35)   0           leaky_re_lu_209[0][0]            \n",
            "                                                                 input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 32, 32, 35)   140         concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling2D) (None, 16, 16, 35)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 16, 16, 32)   10112       max_pooling2d_41[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_210 (LeakyReLU)     (None, 16, 16, 32)   0           conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 16, 16, 32)   9248        leaky_re_lu_210[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_211 (LeakyReLU)     (None, 16, 16, 32)   0           conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_79 (Concatenate)    (None, 16, 16, 67)   0           leaky_re_lu_211[0][0]            \n",
            "                                                                 max_pooling2d_41[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 16, 16, 32)   19328       concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_212 (LeakyReLU)     (None, 16, 16, 32)   0           conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 16, 16, 64)   18496       leaky_re_lu_212[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 16, 16, 16)   448         input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_213 (LeakyReLU)     (None, 16, 16, 64)   0           conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_214 (LeakyReLU)     (None, 16, 16, 16)   0           conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_80 (Concatenate)    (None, 16, 16, 115)  0           leaky_re_lu_213[0][0]            \n",
            "                                                                 max_pooling2d_41[0][0]           \n",
            "                                                                 leaky_re_lu_214[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 115)  460         concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling2D) (None, 8, 8, 115)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 8, 8, 64)     66304       max_pooling2d_42[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_215 (LeakyReLU)     (None, 8, 8, 64)     0           conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 8, 8, 64)     36928       leaky_re_lu_215[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_216 (LeakyReLU)     (None, 8, 8, 64)     0           conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_81 (Concatenate)    (None, 8, 8, 179)    0           leaky_re_lu_216[0][0]            \n",
            "                                                                 max_pooling2d_42[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 8, 8, 64)     103168      concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_217 (LeakyReLU)     (None, 8, 8, 64)     0           conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 8, 8, 128)    73856       leaky_re_lu_217[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 8, 8, 16)     1216        input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 8, 8, 16)     2320        leaky_re_lu_214[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_218 (LeakyReLU)     (None, 8, 8, 128)    0           conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_219 (LeakyReLU)     (None, 8, 8, 16)     0           conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_220 (LeakyReLU)     (None, 8, 8, 16)     0           conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_82 (Concatenate)    (None, 8, 8, 275)    0           leaky_re_lu_218[0][0]            \n",
            "                                                                 leaky_re_lu_219[0][0]            \n",
            "                                                                 leaky_re_lu_220[0][0]            \n",
            "                                                                 max_pooling2d_42[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 8, 8, 275)    1100        concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling2D) (None, 4, 4, 275)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 4, 4, 256)    633856      max_pooling2d_43[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_221 (LeakyReLU)     (None, 4, 4, 256)    0           conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 4, 4, 256)    590080      leaky_re_lu_221[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_222 (LeakyReLU)     (None, 4, 4, 256)    0           conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_83 (Concatenate)    (None, 4, 4, 531)    0           leaky_re_lu_222[0][0]            \n",
            "                                                                 max_pooling2d_43[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 4, 4, 512)    2447360     concatenate_83[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_223 (LeakyReLU)     (None, 4, 4, 512)    0           conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 4, 4, 512)    2359808     leaky_re_lu_223[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 4, 4, 16)     6416        leaky_re_lu_214[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 4, 4, 16)     2320        leaky_re_lu_219[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 4, 4, 16)     2320        leaky_re_lu_220[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_224 (LeakyReLU)     (None, 4, 4, 512)    0           conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_225 (LeakyReLU)     (None, 4, 4, 16)     0           conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_226 (LeakyReLU)     (None, 4, 4, 16)     0           conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_227 (LeakyReLU)     (None, 4, 4, 16)     0           conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_84 (Concatenate)    (None, 4, 4, 835)    0           leaky_re_lu_224[0][0]            \n",
            "                                                                 leaky_re_lu_225[0][0]            \n",
            "                                                                 leaky_re_lu_226[0][0]            \n",
            "                                                                 leaky_re_lu_227[0][0]            \n",
            "                                                                 max_pooling2d_43[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 4, 4, 835)    3340        concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 2, 2, 512)    3848192     batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_228 (LeakyReLU)     (None, 2, 2, 512)    0           conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 2, 2, 256)    131328      leaky_re_lu_228[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_229 (LeakyReLU)     (None, 2, 2, 256)    0           conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 2, 2, 256)    1024        leaky_re_lu_229[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_11 (Gl (None, 256)          0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 10)           2570        global_average_pooling2d_11[0][0]\n",
            "==================================================================================================\n",
            "Total params: 10,379,146\n",
            "Trainable params: 10,376,114\n",
            "Non-trainable params: 3,032\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rAXzc9Ig4jf",
        "colab_type": "code",
        "outputId": "c5b90d1f-23f7-4b7d-c4de-3a98441d0406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5757
        }
      },
      "source": [
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "plot_model(model, to_file='cifar10_model_14.png', show_shapes=True)                                   # 保存模型图片\n",
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))                #  显示在jupyter notebook 上"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"4288pt\" viewBox=\"0.00 0.00 1432.50 4288.00\" width=\"1433pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 4284)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-4284 1428.5,-4284 1428.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139686084496128 -->\n<g class=\"node\" id=\"node1\">\n<title>139686084496128</title>\n<polygon fill=\"none\" points=\"669.5,-4233.5 669.5,-4279.5 984.5,-4279.5 984.5,-4233.5 669.5,-4233.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"739.5\" y=\"-4252.8\">input_12: InputLayer</text>\n<polyline fill=\"none\" points=\"809.5,-4233.5 809.5,-4279.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"838.5\" y=\"-4264.3\">input:</text>\n<polyline fill=\"none\" points=\"809.5,-4256.5 867.5,-4256.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"838.5\" y=\"-4241.3\">output:</text>\n<polyline fill=\"none\" points=\"867.5,-4233.5 867.5,-4279.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"926\" y=\"-4264.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"867.5,-4256.5 984.5,-4256.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"926\" y=\"-4241.3\">(None, 32, 32, 3)</text>\n</g>\n<!-- 139686084496240 -->\n<g class=\"node\" id=\"node2\">\n<title>139686084496240</title>\n<polygon fill=\"none\" points=\"487.5,-4150.5 487.5,-4196.5 818.5,-4196.5 818.5,-4150.5 487.5,-4150.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561.5\" y=\"-4169.8\">conv2d_230: Conv2D</text>\n<polyline fill=\"none\" points=\"635.5,-4150.5 635.5,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664.5\" y=\"-4181.3\">input:</text>\n<polyline fill=\"none\" points=\"635.5,-4173.5 693.5,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664.5\" y=\"-4158.3\">output:</text>\n<polyline fill=\"none\" points=\"693.5,-4150.5 693.5,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"756\" y=\"-4181.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"693.5,-4173.5 818.5,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"756\" y=\"-4158.3\">(None, 32, 32, 16)</text>\n</g>\n<!-- 139686084496128&#45;&gt;139686084496240 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139686084496128-&gt;139686084496240</title>\n<path d=\"M778.5313,-4233.3799C757.5023,-4223.3488 732.7095,-4211.5224 710.7358,-4201.0406\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"712.0429,-4197.7864 701.5103,-4196.6399 709.0291,-4204.1044 712.0429,-4197.7864\" stroke=\"#000000\"/>\n</g>\n<!-- 139686084206152 -->\n<g class=\"node\" id=\"node8\">\n<title>139686084206152</title>\n<polygon fill=\"none\" points=\"243,-3652.5 243,-3698.5 725,-3698.5 725,-3652.5 243,-3652.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"334\" y=\"-3671.8\">concatenate_78: Concatenate</text>\n<polyline fill=\"none\" points=\"425,-3652.5 425,-3698.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"454\" y=\"-3683.3\">input:</text>\n<polyline fill=\"none\" points=\"425,-3675.5 483,-3675.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"454\" y=\"-3660.3\">output:</text>\n<polyline fill=\"none\" points=\"483,-3652.5 483,-3698.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"604\" y=\"-3683.3\">[(None, 32, 32, 32), (None, 32, 32, 3)]</text>\n<polyline fill=\"none\" points=\"483,-3675.5 725,-3675.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"604\" y=\"-3660.3\">(None, 32, 32, 35)</text>\n</g>\n<!-- 139686084496128&#45;&gt;139686084206152 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139686084496128-&gt;139686084206152</title>\n<path d=\"M669.273,-4245.9365C590.7741,-4237.5378 506.618,-4222.7421 478,-4197 441.4392,-4164.1133 448,-4139.6754 448,-4090.5 448,-4090.5 448,-4090.5 448,-3841.5 448,-3794.3308 462.0543,-3741.3001 472.6001,-3708.1473\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"475.9651,-3709.1176 475.7409,-3698.5251 469.3106,-3706.9454 475.9651,-3709.1176\" stroke=\"#000000\"/>\n</g>\n<!-- 139686084968232 -->\n<g class=\"node\" id=\"node19\">\n<title>139686084968232</title>\n<polygon fill=\"none\" points=\"836.5,-4150.5 836.5,-4196.5 1167.5,-4196.5 1167.5,-4150.5 836.5,-4150.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910.5\" y=\"-4169.8\">conv2d_237: Conv2D</text>\n<polyline fill=\"none\" points=\"984.5,-4150.5 984.5,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1013.5\" y=\"-4181.3\">input:</text>\n<polyline fill=\"none\" points=\"984.5,-4173.5 1042.5,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1013.5\" y=\"-4158.3\">output:</text>\n<polyline fill=\"none\" points=\"1042.5,-4150.5 1042.5,-4196.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1105\" y=\"-4181.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"1042.5,-4173.5 1167.5,-4173.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1105\" y=\"-4158.3\">(None, 16, 16, 16)</text>\n</g>\n<!-- 139686084496128&#45;&gt;139686084968232 -->\n<g class=\"edge\" id=\"edge20\">\n<title>139686084496128-&gt;139686084968232</title>\n<path d=\"M875.7473,-4233.3799C896.8971,-4223.3488 921.8324,-4211.5224 943.9324,-4201.0406\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"945.6755,-4204.0877 953.211,-4196.6399 942.6758,-4197.763 945.6755,-4204.0877\" stroke=\"#000000\"/>\n</g>\n<!-- 139686080977384 -->\n<g class=\"node\" id=\"node33\">\n<title>139686080977384</title>\n<polygon fill=\"none\" points=\"1057.5,-4067.5 1057.5,-4113.5 1380.5,-4113.5 1380.5,-4067.5 1057.5,-4067.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1131.5\" y=\"-4086.8\">conv2d_242: Conv2D</text>\n<polyline fill=\"none\" points=\"1205.5,-4067.5 1205.5,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1234.5\" y=\"-4098.3\">input:</text>\n<polyline fill=\"none\" points=\"1205.5,-4090.5 1263.5,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1234.5\" y=\"-4075.3\">output:</text>\n<polyline fill=\"none\" points=\"1263.5,-4067.5 1263.5,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1322\" y=\"-4098.3\">(None, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"1263.5,-4090.5 1380.5,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1322\" y=\"-4075.3\">(None, 8, 8, 16)</text>\n</g>\n<!-- 139686084496128&#45;&gt;139686080977384 -->\n<g class=\"edge\" id=\"edge37\">\n<title>139686084496128-&gt;139686080977384</title>\n<path d=\"M984.6542,-4244.7745C1062.9416,-4236.0305 1147.0891,-4221.2756 1177,-4197 1199.0467,-4179.107 1209.5667,-4148.0186 1214.5591,-4124.0342\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1218.0529,-4124.389 1216.4318,-4113.9189 1211.1698,-4123.1146 1218.0529,-4124.389\" stroke=\"#000000\"/>\n</g>\n<!-- 139686084496856 -->\n<g class=\"node\" id=\"node3\">\n<title>139686084496856</title>\n<polygon fill=\"none\" points=\"476,-4067.5 476,-4113.5 852,-4113.5 852,-4067.5 476,-4067.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"572.5\" y=\"-4086.8\">leaky_re_lu_207: LeakyReLU</text>\n<polyline fill=\"none\" points=\"669,-4067.5 669,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"698\" y=\"-4098.3\">input:</text>\n<polyline fill=\"none\" points=\"669,-4090.5 727,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"698\" y=\"-4075.3\">output:</text>\n<polyline fill=\"none\" points=\"727,-4067.5 727,-4113.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"789.5\" y=\"-4098.3\">(None, 32, 32, 16)</text>\n<polyline fill=\"none\" points=\"727,-4090.5 852,-4090.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"789.5\" y=\"-4075.3\">(None, 32, 32, 16)</text>\n</g>\n<!-- 139686084496240&#45;&gt;139686084496856 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139686084496240-&gt;139686084496856</title>\n<path d=\"M656.0641,-4150.3799C657.1516,-4142.1745 658.3982,-4132.7679 659.5763,-4123.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"663.0699,-4124.1572 660.9142,-4113.784 656.1306,-4123.2375 663.0699,-4124.1572\" stroke=\"#000000\"/>\n</g>\n<!-- 139686084497192 -->\n<g class=\"node\" id=\"node4\">\n<title>139686084497192</title>\n<polygon fill=\"none\" points=\"498.5,-3984.5 498.5,-4030.5 829.5,-4030.5 829.5,-3984.5 498.5,-3984.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"572.5\" y=\"-4003.8\">conv2d_231: Conv2D</text>\n<polyline fill=\"none\" points=\"646.5,-3984.5 646.5,-4030.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"675.5\" y=\"-4015.3\">input:</text>\n<polyline fill=\"none\" points=\"646.5,-4007.5 704.5,-4007.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"675.5\" y=\"-3992.3\">output:</text>\n<polyline fill=\"none\" points=\"704.5,-3984.5 704.5,-4030.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"767\" y=\"-4015.3\">(None, 32, 32, 16)</text>\n<polyline fill=\"none\" points=\"704.5,-4007.5 829.5,-4007.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"767\" y=\"-3992.3\">(None, 32, 32, 16)</text>\n</g>\n<!-- 139686084496856&#45;&gt;139686084497192 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139686084496856-&gt;139686084497192</title>\n<path d=\"M664,-4067.3799C664,-4059.1745 664,-4049.7679 664,-4040.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"667.5001,-4040.784 664,-4030.784 660.5001,-4040.784 667.5001,-4040.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686084496576 -->\n<g class=\"node\" id=\"node5\">\n<title>139686084496576</title>\n<polygon fill=\"none\" points=\"476,-3901.5 476,-3947.5 852,-3947.5 852,-3901.5 476,-3901.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"572.5\" y=\"-3920.8\">leaky_re_lu_208: LeakyReLU</text>\n<polyline fill=\"none\" points=\"669,-3901.5 669,-3947.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"698\" y=\"-3932.3\">input:</text>\n<polyline fill=\"none\" points=\"669,-3924.5 727,-3924.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"698\" y=\"-3909.3\">output:</text>\n<polyline fill=\"none\" points=\"727,-3901.5 727,-3947.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"789.5\" y=\"-3932.3\">(None, 32, 32, 16)</text>\n<polyline fill=\"none\" points=\"727,-3924.5 852,-3924.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"789.5\" y=\"-3909.3\">(None, 32, 32, 16)</text>\n</g>\n<!-- 139686084497192&#45;&gt;139686084496576 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139686084497192-&gt;139686084496576</title>\n<path d=\"M664,-3984.3799C664,-3976.1745 664,-3966.7679 664,-3957.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"667.5001,-3957.784 664,-3947.784 660.5001,-3957.784 667.5001,-3957.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686084533832 -->\n<g class=\"node\" id=\"node6\">\n<title>139686084533832</title>\n<polygon fill=\"none\" points=\"498.5,-3818.5 498.5,-3864.5 829.5,-3864.5 829.5,-3818.5 498.5,-3818.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"572.5\" y=\"-3837.8\">conv2d_232: Conv2D</text>\n<polyline fill=\"none\" points=\"646.5,-3818.5 646.5,-3864.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"675.5\" y=\"-3849.3\">input:</text>\n<polyline fill=\"none\" points=\"646.5,-3841.5 704.5,-3841.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"675.5\" y=\"-3826.3\">output:</text>\n<polyline fill=\"none\" points=\"704.5,-3818.5 704.5,-3864.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"767\" y=\"-3849.3\">(None, 32, 32, 16)</text>\n<polyline fill=\"none\" points=\"704.5,-3841.5 829.5,-3841.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"767\" y=\"-3826.3\">(None, 32, 32, 32)</text>\n</g>\n<!-- 139686084496576&#45;&gt;139686084533832 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139686084496576-&gt;139686084533832</title>\n<path d=\"M664,-3901.3799C664,-3893.1745 664,-3883.7679 664,-3874.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"667.5001,-3874.784 664,-3864.784 660.5001,-3874.784 667.5001,-3874.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686084534224 -->\n<g class=\"node\" id=\"node7\">\n<title>139686084534224</title>\n<polygon fill=\"none\" points=\"476,-3735.5 476,-3781.5 852,-3781.5 852,-3735.5 476,-3735.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"572.5\" y=\"-3754.8\">leaky_re_lu_209: LeakyReLU</text>\n<polyline fill=\"none\" points=\"669,-3735.5 669,-3781.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"698\" y=\"-3766.3\">input:</text>\n<polyline fill=\"none\" points=\"669,-3758.5 727,-3758.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"698\" y=\"-3743.3\">output:</text>\n<polyline fill=\"none\" points=\"727,-3735.5 727,-3781.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"789.5\" y=\"-3766.3\">(None, 32, 32, 32)</text>\n<polyline fill=\"none\" points=\"727,-3758.5 852,-3758.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"789.5\" y=\"-3743.3\">(None, 32, 32, 32)</text>\n</g>\n<!-- 139686084533832&#45;&gt;139686084534224 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139686084533832-&gt;139686084534224</title>\n<path d=\"M664,-3818.3799C664,-3810.1745 664,-3800.7679 664,-3791.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"667.5001,-3791.784 664,-3781.784 660.5001,-3791.784 667.5001,-3791.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686084534224&#45;&gt;139686084206152 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139686084534224-&gt;139686084206152</title>\n<path d=\"M613.86,-3735.3799C592.0087,-3725.304 566.229,-3713.4167 543.4224,-3702.9003\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"544.7297,-3699.649 534.183,-3698.6399 541.7985,-3706.0058 544.7297,-3699.649\" stroke=\"#000000\"/>\n</g>\n<!-- 139686084496072 -->\n<g class=\"node\" id=\"node9\">\n<title>139686084496072</title>\n<polygon fill=\"none\" points=\"253.5,-3569.5 253.5,-3615.5 714.5,-3615.5 714.5,-3569.5 253.5,-3569.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"392.5\" y=\"-3588.8\">batch_normalization_54: BatchNormalization</text>\n<polyline fill=\"none\" points=\"531.5,-3569.5 531.5,-3615.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560.5\" y=\"-3600.3\">input:</text>\n<polyline fill=\"none\" points=\"531.5,-3592.5 589.5,-3592.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560.5\" y=\"-3577.3\">output:</text>\n<polyline fill=\"none\" points=\"589.5,-3569.5 589.5,-3615.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"652\" y=\"-3600.3\">(None, 32, 32, 35)</text>\n<polyline fill=\"none\" points=\"589.5,-3592.5 714.5,-3592.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"652\" y=\"-3577.3\">(None, 32, 32, 35)</text>\n</g>\n<!-- 139686084206152&#45;&gt;139686084496072 -->\n<g class=\"edge\" id=\"edge9\">\n<title>139686084206152-&gt;139686084496072</title>\n<path d=\"M484,-3652.3799C484,-3644.1745 484,-3634.7679 484,-3625.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"487.5001,-3625.784 484,-3615.784 480.5001,-3625.784 487.5001,-3625.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686084204416 -->\n<g class=\"node\" id=\"node10\">\n<title>139686084204416</title>\n<polygon fill=\"none\" points=\"278,-3486.5 278,-3532.5 690,-3532.5 690,-3486.5 278,-3486.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"392.5\" y=\"-3505.8\">max_pooling2d_41: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"507,-3486.5 507,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"536\" y=\"-3517.3\">input:</text>\n<polyline fill=\"none\" points=\"507,-3509.5 565,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"536\" y=\"-3494.3\">output:</text>\n<polyline fill=\"none\" points=\"565,-3486.5 565,-3532.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-3517.3\">(None, 32, 32, 35)</text>\n<polyline fill=\"none\" points=\"565,-3509.5 690,-3509.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627.5\" y=\"-3494.3\">(None, 16, 16, 35)</text>\n</g>\n<!-- 139686084496072&#45;&gt;139686084204416 -->\n<g class=\"edge\" id=\"edge10\">\n<title>139686084496072-&gt;139686084204416</title>\n<path d=\"M484,-3569.3799C484,-3561.1745 484,-3551.7679 484,-3542.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"487.5001,-3542.784 484,-3532.784 480.5001,-3542.784 487.5001,-3542.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686084302440 -->\n<g class=\"node\" id=\"node11\">\n<title>139686084302440</title>\n<polygon fill=\"none\" points=\"455.5,-3403.5 455.5,-3449.5 786.5,-3449.5 786.5,-3403.5 455.5,-3403.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"529.5\" y=\"-3422.8\">conv2d_233: Conv2D</text>\n<polyline fill=\"none\" points=\"603.5,-3403.5 603.5,-3449.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"632.5\" y=\"-3434.3\">input:</text>\n<polyline fill=\"none\" points=\"603.5,-3426.5 661.5,-3426.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"632.5\" y=\"-3411.3\">output:</text>\n<polyline fill=\"none\" points=\"661.5,-3403.5 661.5,-3449.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"724\" y=\"-3434.3\">(None, 16, 16, 35)</text>\n<polyline fill=\"none\" points=\"661.5,-3426.5 786.5,-3426.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"724\" y=\"-3411.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139686084204416&#45;&gt;139686084302440 -->\n<g class=\"edge\" id=\"edge11\">\n<title>139686084204416-&gt;139686084302440</title>\n<path d=\"M522.1621,-3486.3799C538.2085,-3476.6583 557.0383,-3465.2505 573.9336,-3455.0147\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"575.8281,-3457.9592 582.5674,-3449.784 572.2009,-3451.9722 575.8281,-3457.9592\" stroke=\"#000000\"/>\n</g>\n<!-- 139686083263624 -->\n<g class=\"node\" id=\"node15\">\n<title>139686083263624</title>\n<polygon fill=\"none\" points=\"171.5,-3071.5 171.5,-3117.5 660.5,-3117.5 660.5,-3071.5 171.5,-3071.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.5\" y=\"-3090.8\">concatenate_79: Concatenate</text>\n<polyline fill=\"none\" points=\"353.5,-3071.5 353.5,-3117.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382.5\" y=\"-3102.3\">input:</text>\n<polyline fill=\"none\" points=\"353.5,-3094.5 411.5,-3094.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382.5\" y=\"-3079.3\">output:</text>\n<polyline fill=\"none\" points=\"411.5,-3071.5 411.5,-3117.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"536\" y=\"-3102.3\">[(None, 16, 16, 32), (None, 16, 16, 35)]</text>\n<polyline fill=\"none\" points=\"411.5,-3094.5 660.5,-3094.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"536\" y=\"-3079.3\">(None, 16, 16, 67)</text>\n</g>\n<!-- 139686084204416&#45;&gt;139686083263624 -->\n<g class=\"edge\" id=\"edge16\">\n<title>139686084204416-&gt;139686083263624</title>\n<path d=\"M416,-3177.5C407.5994,-3162.5602 407.0051,-3143.5852 408.7766,-3127.55\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"412.2614,-3127.9062 410.2241,-3117.5091 405.333,-3126.9073 412.2614,-3127.9062\" stroke=\"#000000\"/>\n</g>\n<!-- 139686082653432 -->\n<g class=\"node\" id=\"node22\">\n<title>139686082653432</title>\n<polygon fill=\"none\" points=\"53.5,-2656.5 53.5,-2702.5 658.5,-2702.5 658.5,-2656.5 53.5,-2656.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"144.5\" y=\"-2675.8\">concatenate_80: Concatenate</text>\n<polyline fill=\"none\" points=\"235.5,-2656.5 235.5,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-2687.3\">input:</text>\n<polyline fill=\"none\" points=\"235.5,-2679.5 293.5,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-2664.3\">output:</text>\n<polyline fill=\"none\" points=\"293.5,-2656.5 293.5,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476\" y=\"-2687.3\">[(None, 16, 16, 64), (None, 16, 16, 35), (None, 16, 16, 16)]</text>\n<polyline fill=\"none\" points=\"293.5,-2679.5 658.5,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476\" y=\"-2664.3\">(None, 16, 16, 115)</text>\n</g>\n<!-- 139686084204416&#45;&gt;139686082653432 -->\n<g class=\"edge\" id=\"edge24\">\n<title>139686084204416-&gt;139686082653432</title>\n<path d=\"M465.9249,-3486.4412C458.5699,-3475.8956 450.708,-3462.8951 446,-3450 433.2382,-3415.0454 439.3012,-3403.962 435,-3367 425.2162,-3282.9228 457.4866,-3251.2804 416,-3177.5\" fill=\"none\" stroke=\"#000000\"/>\n<path d=\"M416,-3177.5C346.5922,-3084.625 241.7608,-3202.1512 162,-3118 128.9243,-3083.1037 143,-3059.5807 143,-3011.5 143,-3011.5 143,-3011.5 143,-2845.5 143,-2793.7623 152.1328,-2774.2543 190,-2739 204.8273,-2725.1959 223.0804,-2714.5526 241.9978,-2706.3584\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"243.4038,-2709.5647 251.3257,-2702.5295 240.7456,-2703.0891 243.4038,-2709.5647\" stroke=\"#000000\"/>\n</g>\n<!-- 139686083836728 -->\n<g class=\"node\" id=\"node12\">\n<title>139686083836728</title>\n<polygon fill=\"none\" points=\"444,-3320.5 444,-3366.5 820,-3366.5 820,-3320.5 444,-3320.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"540.5\" y=\"-3339.8\">leaky_re_lu_210: LeakyReLU</text>\n<polyline fill=\"none\" points=\"637,-3320.5 637,-3366.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"666\" y=\"-3351.3\">input:</text>\n<polyline fill=\"none\" points=\"637,-3343.5 695,-3343.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"666\" y=\"-3328.3\">output:</text>\n<polyline fill=\"none\" points=\"695,-3320.5 695,-3366.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"757.5\" y=\"-3351.3\">(None, 16, 16, 32)</text>\n<polyline fill=\"none\" points=\"695,-3343.5 820,-3343.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"757.5\" y=\"-3328.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139686084302440&#45;&gt;139686083836728 -->\n<g class=\"edge\" id=\"edge12\">\n<title>139686084302440-&gt;139686083836728</title>\n<path d=\"M624.0641,-3403.3799C625.1516,-3395.1745 626.3982,-3385.7679 627.5763,-3376.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"631.0699,-3377.1572 628.9142,-3366.784 624.1306,-3376.2375 631.0699,-3377.1572\" stroke=\"#000000\"/>\n</g>\n<!-- 139686083513760 -->\n<g class=\"node\" id=\"node13\">\n<title>139686083513760</title>\n<polygon fill=\"none\" points=\"466.5,-3237.5 466.5,-3283.5 797.5,-3283.5 797.5,-3237.5 466.5,-3237.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"540.5\" y=\"-3256.8\">conv2d_234: Conv2D</text>\n<polyline fill=\"none\" points=\"614.5,-3237.5 614.5,-3283.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"643.5\" y=\"-3268.3\">input:</text>\n<polyline fill=\"none\" points=\"614.5,-3260.5 672.5,-3260.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"643.5\" y=\"-3245.3\">output:</text>\n<polyline fill=\"none\" points=\"672.5,-3237.5 672.5,-3283.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"735\" y=\"-3268.3\">(None, 16, 16, 32)</text>\n<polyline fill=\"none\" points=\"672.5,-3260.5 797.5,-3260.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"735\" y=\"-3245.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139686083836728&#45;&gt;139686083513760 -->\n<g class=\"edge\" id=\"edge13\">\n<title>139686083836728-&gt;139686083513760</title>\n<path d=\"M632,-3320.3799C632,-3312.1745 632,-3302.7679 632,-3293.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"635.5001,-3293.784 632,-3283.784 628.5001,-3293.784 635.5001,-3293.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686083512024 -->\n<g class=\"node\" id=\"node14\">\n<title>139686083512024</title>\n<polygon fill=\"none\" points=\"444.5,-3154.5 444.5,-3200.5 819.5,-3200.5 819.5,-3154.5 444.5,-3154.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"540.5\" y=\"-3173.8\">leaky_re_lu_211: LeakyReLU</text>\n<polyline fill=\"none\" points=\"636.5,-3154.5 636.5,-3200.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"665.5\" y=\"-3185.3\">input:</text>\n<polyline fill=\"none\" points=\"636.5,-3177.5 694.5,-3177.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"665.5\" y=\"-3162.3\">output:</text>\n<polyline fill=\"none\" points=\"694.5,-3154.5 694.5,-3200.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"757\" y=\"-3185.3\">(None, 16, 16, 32)</text>\n<polyline fill=\"none\" points=\"694.5,-3177.5 819.5,-3177.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"757\" y=\"-3162.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139686083513760&#45;&gt;139686083512024 -->\n<g class=\"edge\" id=\"edge14\">\n<title>139686083513760-&gt;139686083512024</title>\n<path d=\"M632,-3237.3799C632,-3229.1745 632,-3219.7679 632,-3210.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"635.5001,-3210.784 632,-3200.784 628.5001,-3210.784 635.5001,-3210.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686083512024&#45;&gt;139686083263624 -->\n<g class=\"edge\" id=\"edge15\">\n<title>139686083512024-&gt;139686083263624</title>\n<path d=\"M572.1188,-3154.4901C545.3147,-3144.1904 513.54,-3131.9806 485.6759,-3121.2736\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"486.5877,-3117.8745 475.9977,-3117.5547 484.0768,-3124.4087 486.5877,-3117.8745\" stroke=\"#000000\"/>\n</g>\n<!-- 139686083262672 -->\n<g class=\"node\" id=\"node16\">\n<title>139686083262672</title>\n<polygon fill=\"none\" points=\"246.5,-2988.5 246.5,-3034.5 577.5,-3034.5 577.5,-2988.5 246.5,-2988.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"320.5\" y=\"-3007.8\">conv2d_235: Conv2D</text>\n<polyline fill=\"none\" points=\"394.5,-2988.5 394.5,-3034.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"423.5\" y=\"-3019.3\">input:</text>\n<polyline fill=\"none\" points=\"394.5,-3011.5 452.5,-3011.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"423.5\" y=\"-2996.3\">output:</text>\n<polyline fill=\"none\" points=\"452.5,-2988.5 452.5,-3034.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"515\" y=\"-3019.3\">(None, 16, 16, 67)</text>\n<polyline fill=\"none\" points=\"452.5,-3011.5 577.5,-3011.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"515\" y=\"-2996.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139686083263624&#45;&gt;139686083262672 -->\n<g class=\"edge\" id=\"edge17\">\n<title>139686083263624-&gt;139686083262672</title>\n<path d=\"M414.8858,-3071.3799C414.4903,-3063.1745 414.037,-3053.7679 413.6086,-3044.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"417.0995,-3044.6039 413.1221,-3034.784 410.1076,-3044.9409 417.0995,-3044.6039\" stroke=\"#000000\"/>\n</g>\n<!-- 139686083836616 -->\n<g class=\"node\" id=\"node17\">\n<title>139686083836616</title>\n<polygon fill=\"none\" points=\"217,-2905.5 217,-2951.5 593,-2951.5 593,-2905.5 217,-2905.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-2924.8\">leaky_re_lu_212: LeakyReLU</text>\n<polyline fill=\"none\" points=\"410,-2905.5 410,-2951.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"439\" y=\"-2936.3\">input:</text>\n<polyline fill=\"none\" points=\"410,-2928.5 468,-2928.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"439\" y=\"-2913.3\">output:</text>\n<polyline fill=\"none\" points=\"468,-2905.5 468,-2951.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-2936.3\">(None, 16, 16, 32)</text>\n<polyline fill=\"none\" points=\"468,-2928.5 593,-2928.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-2913.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 139686083262672&#45;&gt;139686083836616 -->\n<g class=\"edge\" id=\"edge18\">\n<title>139686083262672-&gt;139686083836616</title>\n<path d=\"M410.0501,-2988.3799C409.3581,-2980.1745 408.5648,-2970.7679 407.8151,-2961.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"411.2918,-2961.4545 406.9637,-2951.784 404.3166,-2962.0428 411.2918,-2961.4545\" stroke=\"#000000\"/>\n</g>\n<!-- 139686082896112 -->\n<g class=\"node\" id=\"node18\">\n<title>139686082896112</title>\n<polygon fill=\"none\" points=\"225.5,-2822.5 225.5,-2868.5 556.5,-2868.5 556.5,-2822.5 225.5,-2822.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299.5\" y=\"-2841.8\">conv2d_236: Conv2D</text>\n<polyline fill=\"none\" points=\"373.5,-2822.5 373.5,-2868.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402.5\" y=\"-2853.3\">input:</text>\n<polyline fill=\"none\" points=\"373.5,-2845.5 431.5,-2845.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402.5\" y=\"-2830.3\">output:</text>\n<polyline fill=\"none\" points=\"431.5,-2822.5 431.5,-2868.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"494\" y=\"-2853.3\">(None, 16, 16, 32)</text>\n<polyline fill=\"none\" points=\"431.5,-2845.5 556.5,-2845.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"494\" y=\"-2830.3\">(None, 16, 16, 64)</text>\n</g>\n<!-- 139686083836616&#45;&gt;139686082896112 -->\n<g class=\"edge\" id=\"edge19\">\n<title>139686083836616-&gt;139686082896112</title>\n<path d=\"M401.1002,-2905.3799C399.7162,-2897.1745 398.1295,-2887.7679 396.6301,-2878.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"400.042,-2878.0625 394.9274,-2868.784 393.1395,-2879.2269 400.042,-2878.0625\" stroke=\"#000000\"/>\n</g>\n<!-- 139686082899024 -->\n<g class=\"node\" id=\"node20\">\n<title>139686082899024</title>\n<polygon fill=\"none\" points=\"199,-2739.5 199,-2785.5 575,-2785.5 575,-2739.5 199,-2739.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"295.5\" y=\"-2758.8\">leaky_re_lu_213: LeakyReLU</text>\n<polyline fill=\"none\" points=\"392,-2739.5 392,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-2770.3\">input:</text>\n<polyline fill=\"none\" points=\"392,-2762.5 450,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-2747.3\">output:</text>\n<polyline fill=\"none\" points=\"450,-2739.5 450,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"512.5\" y=\"-2770.3\">(None, 16, 16, 64)</text>\n<polyline fill=\"none\" points=\"450,-2762.5 575,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"512.5\" y=\"-2747.3\">(None, 16, 16, 64)</text>\n</g>\n<!-- 139686082896112&#45;&gt;139686082899024 -->\n<g class=\"edge\" id=\"edge21\">\n<title>139686082896112-&gt;139686082899024</title>\n<path d=\"M389.8858,-2822.3799C389.4903,-2814.1745 389.037,-2804.7679 388.6086,-2795.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"392.0995,-2795.6039 388.1221,-2785.784 385.1076,-2795.9409 392.0995,-2795.6039\" stroke=\"#000000\"/>\n</g>\n<!-- 139686083262000 -->\n<g class=\"node\" id=\"node21\">\n<title>139686083262000</title>\n<polygon fill=\"none\" points=\"751,-2739.5 751,-2785.5 1127,-2785.5 1127,-2739.5 751,-2739.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"847.5\" y=\"-2758.8\">leaky_re_lu_214: LeakyReLU</text>\n<polyline fill=\"none\" points=\"944,-2739.5 944,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"973\" y=\"-2770.3\">input:</text>\n<polyline fill=\"none\" points=\"944,-2762.5 1002,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"973\" y=\"-2747.3\">output:</text>\n<polyline fill=\"none\" points=\"1002,-2739.5 1002,-2785.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1064.5\" y=\"-2770.3\">(None, 16, 16, 16)</text>\n<polyline fill=\"none\" points=\"1002,-2762.5 1127,-2762.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1064.5\" y=\"-2747.3\">(None, 16, 16, 16)</text>\n</g>\n<!-- 139686084968232&#45;&gt;139686083262000 -->\n<g class=\"edge\" id=\"edge22\">\n<title>139686084968232-&gt;139686083262000</title>\n<path d=\"M990.2772,-4150.2498C975.4987,-4118.7363 952,-4060.3227 952,-4007.5 952,-4007.5 952,-4007.5 952,-2928.5 952,-2882.3301 946.94,-2829.1569 943.1337,-2795.6898\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"946.586,-2795.0768 941.9499,-2785.5502 939.6332,-2795.8886 946.586,-2795.0768\" stroke=\"#000000\"/>\n</g>\n<!-- 139686082899024&#45;&gt;139686082653432 -->\n<g class=\"edge\" id=\"edge23\">\n<title>139686082899024-&gt;139686082653432</title>\n<path d=\"M378.3648,-2739.3799C375.2335,-2730.9962 371.6338,-2721.3584 368.2505,-2712.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"371.4741,-2710.9273 364.6964,-2702.784 364.9166,-2713.3766 371.4741,-2710.9273\" stroke=\"#000000\"/>\n</g>\n<!-- 139686083262000&#45;&gt;139686082653432 -->\n<g class=\"edge\" id=\"edge25\">\n<title>139686083262000-&gt;139686082653432</title>\n<path d=\"M777.3762,-2739.4901C699.7364,-2728.4367 606.6455,-2715.1837 527.7308,-2703.9488\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"528.0789,-2700.4632 517.6854,-2702.5187 527.0922,-2707.3933 528.0789,-2700.4632\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081153736 -->\n<g class=\"node\" id=\"node34\">\n<title>139686081153736</title>\n<polygon fill=\"none\" points=\"676.5,-2656.5 676.5,-2702.5 1007.5,-2702.5 1007.5,-2656.5 676.5,-2656.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"750.5\" y=\"-2675.8\">conv2d_243: Conv2D</text>\n<polyline fill=\"none\" points=\"824.5,-2656.5 824.5,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"853.5\" y=\"-2687.3\">input:</text>\n<polyline fill=\"none\" points=\"824.5,-2679.5 882.5,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"853.5\" y=\"-2664.3\">output:</text>\n<polyline fill=\"none\" points=\"882.5,-2656.5 882.5,-2702.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2687.3\">(None, 16, 16, 16)</text>\n<polyline fill=\"none\" points=\"882.5,-2679.5 1007.5,-2679.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2664.3\">(None, 8, 8, 16)</text>\n</g>\n<!-- 139686083262000&#45;&gt;139686081153736 -->\n<g class=\"edge\" id=\"edge38\">\n<title>139686083262000-&gt;139686081153736</title>\n<path d=\"M911.9801,-2739.3799C901.1399,-2730.1043 888.5057,-2719.2936 876.9789,-2709.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"879.0851,-2706.6262 869.2114,-2702.784 874.534,-2711.9448 879.0851,-2706.6262\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079606344 -->\n<g class=\"node\" id=\"node49\">\n<title>139686079606344</title>\n<polygon fill=\"none\" points=\"870.5,-2573.5 870.5,-2619.5 1201.5,-2619.5 1201.5,-2573.5 870.5,-2573.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"944.5\" y=\"-2592.8\">conv2d_248: Conv2D</text>\n<polyline fill=\"none\" points=\"1018.5,-2573.5 1018.5,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1047.5\" y=\"-2604.3\">input:</text>\n<polyline fill=\"none\" points=\"1018.5,-2596.5 1076.5,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1047.5\" y=\"-2581.3\">output:</text>\n<polyline fill=\"none\" points=\"1076.5,-2573.5 1076.5,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139\" y=\"-2604.3\">(None, 16, 16, 16)</text>\n<polyline fill=\"none\" points=\"1076.5,-2596.5 1201.5,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139\" y=\"-2581.3\">(None, 4, 4, 16)</text>\n</g>\n<!-- 139686083262000&#45;&gt;139686079606344 -->\n<g class=\"edge\" id=\"edge57\">\n<title>139686083262000-&gt;139686079606344</title>\n<path d=\"M980.7104,-2739.3409C994.2866,-2729.7986 1008.129,-2717.5392 1017,-2703 1030.3666,-2681.0926 1034.8772,-2652.2305 1036.1777,-2630.0791\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1039.686,-2629.9339 1036.5829,-2619.8037 1032.6914,-2629.658 1039.686,-2629.9339\" stroke=\"#000000\"/>\n</g>\n<!-- 139686082651472 -->\n<g class=\"node\" id=\"node23\">\n<title>139686082651472</title>\n<polygon fill=\"none\" points=\"122.5,-2573.5 122.5,-2619.5 589.5,-2619.5 589.5,-2573.5 122.5,-2573.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261.5\" y=\"-2592.8\">batch_normalization_55: BatchNormalization</text>\n<polyline fill=\"none\" points=\"400.5,-2573.5 400.5,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"429.5\" y=\"-2604.3\">input:</text>\n<polyline fill=\"none\" points=\"400.5,-2596.5 458.5,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"429.5\" y=\"-2581.3\">output:</text>\n<polyline fill=\"none\" points=\"458.5,-2573.5 458.5,-2619.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-2604.3\">(None, 16, 16, 115)</text>\n<polyline fill=\"none\" points=\"458.5,-2596.5 589.5,-2596.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-2581.3\">(None, 16, 16, 115)</text>\n</g>\n<!-- 139686082653432&#45;&gt;139686082651472 -->\n<g class=\"edge\" id=\"edge26\">\n<title>139686082653432-&gt;139686082651472</title>\n<path d=\"M356,-2656.3799C356,-2648.1745 356,-2638.7679 356,-2629.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"359.5001,-2629.784 356,-2619.784 352.5001,-2629.784 359.5001,-2629.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686082651080 -->\n<g class=\"node\" id=\"node24\">\n<title>139686082651080</title>\n<polygon fill=\"none\" points=\"147,-2490.5 147,-2536.5 565,-2536.5 565,-2490.5 147,-2490.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"261.5\" y=\"-2509.8\">max_pooling2d_42: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"376,-2490.5 376,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405\" y=\"-2521.3\">input:</text>\n<polyline fill=\"none\" points=\"376,-2513.5 434,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405\" y=\"-2498.3\">output:</text>\n<polyline fill=\"none\" points=\"434,-2490.5 434,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"499.5\" y=\"-2521.3\">(None, 16, 16, 115)</text>\n<polyline fill=\"none\" points=\"434,-2513.5 565,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"499.5\" y=\"-2498.3\">(None, 8, 8, 115)</text>\n</g>\n<!-- 139686082651472&#45;&gt;139686082651080 -->\n<g class=\"edge\" id=\"edge27\">\n<title>139686082651472-&gt;139686082651080</title>\n<path d=\"M356,-2573.3799C356,-2565.1745 356,-2555.7679 356,-2546.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"359.5001,-2546.784 356,-2536.784 352.5001,-2546.784 359.5001,-2546.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686082653376 -->\n<g class=\"node\" id=\"node25\">\n<title>139686082653376</title>\n<polygon fill=\"none\" points=\"195,-2407.5 195,-2453.5 517,-2453.5 517,-2407.5 195,-2407.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269\" y=\"-2426.8\">conv2d_238: Conv2D</text>\n<polyline fill=\"none\" points=\"343,-2407.5 343,-2453.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372\" y=\"-2438.3\">input:</text>\n<polyline fill=\"none\" points=\"343,-2430.5 401,-2430.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372\" y=\"-2415.3\">output:</text>\n<polyline fill=\"none\" points=\"401,-2407.5 401,-2453.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459\" y=\"-2438.3\">(None, 8, 8, 115)</text>\n<polyline fill=\"none\" points=\"401,-2430.5 517,-2430.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459\" y=\"-2415.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139686082651080&#45;&gt;139686082653376 -->\n<g class=\"edge\" id=\"edge28\">\n<title>139686082651080-&gt;139686082653376</title>\n<path d=\"M356,-2490.3799C356,-2482.1745 356,-2472.7679 356,-2463.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"359.5001,-2463.784 356,-2453.784 352.5001,-2463.784 359.5001,-2463.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081231504 -->\n<g class=\"node\" id=\"node29\">\n<title>139686081231504</title>\n<polygon fill=\"none\" points=\"70,-2075.5 70,-2121.5 536,-2121.5 536,-2075.5 70,-2075.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161\" y=\"-2094.8\">concatenate_81: Concatenate</text>\n<polyline fill=\"none\" points=\"252,-2075.5 252,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281\" y=\"-2106.3\">input:</text>\n<polyline fill=\"none\" points=\"252,-2098.5 310,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281\" y=\"-2083.3\">output:</text>\n<polyline fill=\"none\" points=\"310,-2075.5 310,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"423\" y=\"-2106.3\">[(None, 8, 8, 64), (None, 8, 8, 115)]</text>\n<polyline fill=\"none\" points=\"310,-2098.5 536,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"423\" y=\"-2083.3\">(None, 8, 8, 179)</text>\n</g>\n<!-- 139686082651080&#45;&gt;139686081231504 -->\n<g class=\"edge\" id=\"edge33\">\n<title>139686082651080-&gt;139686081231504</title>\n<path d=\"M244.4053,-2490.4244C222.9695,-2481.8447 202.1897,-2470.092 186,-2454 150.3562,-2418.5712 148,-2397.7561 148,-2347.5 148,-2347.5 148,-2347.5 148,-2264.5 148,-2216.4954 136.4066,-2195.7978 166,-2158 176.49,-2144.6018 190.6039,-2134.1628 205.7946,-2126.0464\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"207.4585,-2129.1277 214.8438,-2121.5311 204.3332,-2122.8641 207.4585,-2129.1277\" stroke=\"#000000\"/>\n</g>\n<!-- 139686080748848 -->\n<g class=\"node\" id=\"node38\">\n<title>139686080748848</title>\n<polygon fill=\"none\" points=\"0,-1660.5 0,-1706.5 674,-1706.5 674,-1660.5 0,-1660.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"91\" y=\"-1679.8\">concatenate_82: Concatenate</text>\n<polyline fill=\"none\" points=\"182,-1660.5 182,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-1691.3\">input:</text>\n<polyline fill=\"none\" points=\"182,-1683.5 240,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-1668.3\">output:</text>\n<polyline fill=\"none\" points=\"240,-1660.5 240,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"457\" y=\"-1691.3\">[(None, 8, 8, 128), (None, 8, 8, 16), (None, 8, 8, 16), (None, 8, 8, 115)]</text>\n<polyline fill=\"none\" points=\"240,-1683.5 674,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"457\" y=\"-1668.3\">(None, 8, 8, 275)</text>\n</g>\n<!-- 139686082651080&#45;&gt;139686080748848 -->\n<g class=\"edge\" id=\"edge45\">\n<title>139686082651080-&gt;139686080748848</title>\n<path d=\"M467.5947,-2490.4244C489.0305,-2481.8447 509.8103,-2470.092 526,-2454 561.6438,-2418.5712 564,-2397.7561 564,-2347.5 564,-2347.5 564,-2347.5 564,-1849.5 564,-1799.5356 563.7512,-1777.9041 528,-1743 515.5347,-1730.8301 483.5087,-1719.0613 449.1668,-1709.2481\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"450.0062,-1705.8487 439.4335,-1706.5334 448.1255,-1712.5913 450.0062,-1705.8487\" stroke=\"#000000\"/>\n</g>\n<!-- 139686082328448 -->\n<g class=\"node\" id=\"node26\">\n<title>139686082328448</title>\n<polygon fill=\"none\" points=\"175.5,-2324.5 175.5,-2370.5 536.5,-2370.5 536.5,-2324.5 175.5,-2324.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272\" y=\"-2343.8\">leaky_re_lu_215: LeakyReLU</text>\n<polyline fill=\"none\" points=\"368.5,-2324.5 368.5,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-2355.3\">input:</text>\n<polyline fill=\"none\" points=\"368.5,-2347.5 426.5,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-2332.3\">output:</text>\n<polyline fill=\"none\" points=\"426.5,-2324.5 426.5,-2370.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"481.5\" y=\"-2355.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"426.5,-2347.5 536.5,-2347.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"481.5\" y=\"-2332.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139686082653376&#45;&gt;139686082328448 -->\n<g class=\"edge\" id=\"edge29\">\n<title>139686082653376-&gt;139686082328448</title>\n<path d=\"M356,-2407.3799C356,-2399.1745 356,-2389.7679 356,-2380.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"359.5001,-2380.784 356,-2370.784 352.5001,-2380.784 359.5001,-2380.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081532816 -->\n<g class=\"node\" id=\"node27\">\n<title>139686081532816</title>\n<polygon fill=\"none\" points=\"198,-2241.5 198,-2287.5 514,-2287.5 514,-2241.5 198,-2241.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272\" y=\"-2260.8\">conv2d_239: Conv2D</text>\n<polyline fill=\"none\" points=\"346,-2241.5 346,-2287.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375\" y=\"-2272.3\">input:</text>\n<polyline fill=\"none\" points=\"346,-2264.5 404,-2264.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375\" y=\"-2249.3\">output:</text>\n<polyline fill=\"none\" points=\"404,-2241.5 404,-2287.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459\" y=\"-2272.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"404,-2264.5 514,-2264.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459\" y=\"-2249.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139686082328448&#45;&gt;139686081532816 -->\n<g class=\"edge\" id=\"edge30\">\n<title>139686082328448-&gt;139686081532816</title>\n<path d=\"M356,-2324.3799C356,-2316.1745 356,-2306.7679 356,-2297.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"359.5001,-2297.784 356,-2287.784 352.5001,-2297.784 359.5001,-2297.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081532088 -->\n<g class=\"node\" id=\"node28\">\n<title>139686081532088</title>\n<polygon fill=\"none\" points=\"175.5,-2158.5 175.5,-2204.5 536.5,-2204.5 536.5,-2158.5 175.5,-2158.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272\" y=\"-2177.8\">leaky_re_lu_216: LeakyReLU</text>\n<polyline fill=\"none\" points=\"368.5,-2158.5 368.5,-2204.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-2189.3\">input:</text>\n<polyline fill=\"none\" points=\"368.5,-2181.5 426.5,-2181.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-2166.3\">output:</text>\n<polyline fill=\"none\" points=\"426.5,-2158.5 426.5,-2204.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"481.5\" y=\"-2189.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"426.5,-2181.5 536.5,-2181.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"481.5\" y=\"-2166.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139686081532816&#45;&gt;139686081532088 -->\n<g class=\"edge\" id=\"edge31\">\n<title>139686081532816-&gt;139686081532088</title>\n<path d=\"M356,-2241.3799C356,-2233.1745 356,-2223.7679 356,-2214.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"359.5001,-2214.784 356,-2204.784 352.5001,-2214.784 359.5001,-2214.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081532088&#45;&gt;139686081231504 -->\n<g class=\"edge\" id=\"edge32\">\n<title>139686081532088-&gt;139686081231504</title>\n<path d=\"M341.2365,-2158.3799C335.7122,-2149.7286 329.3352,-2139.7419 323.3917,-2130.4341\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"326.1999,-2128.3286 317.8681,-2121.784 320.3001,-2132.0959 326.1999,-2128.3286\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081229992 -->\n<g class=\"node\" id=\"node30\">\n<title>139686081229992</title>\n<polygon fill=\"none\" points=\"144.5,-1992.5 144.5,-2038.5 467.5,-2038.5 467.5,-1992.5 144.5,-1992.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218.5\" y=\"-2011.8\">conv2d_240: Conv2D</text>\n<polyline fill=\"none\" points=\"292.5,-1992.5 292.5,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321.5\" y=\"-2023.3\">input:</text>\n<polyline fill=\"none\" points=\"292.5,-2015.5 350.5,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321.5\" y=\"-2000.3\">output:</text>\n<polyline fill=\"none\" points=\"350.5,-1992.5 350.5,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409\" y=\"-2023.3\">(None, 8, 8, 179)</text>\n<polyline fill=\"none\" points=\"350.5,-2015.5 467.5,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409\" y=\"-2000.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139686081231504&#45;&gt;139686081229992 -->\n<g class=\"edge\" id=\"edge34\">\n<title>139686081231504-&gt;139686081229992</title>\n<path d=\"M303.8357,-2075.3799C304.1322,-2067.1745 304.4722,-2057.7679 304.7935,-2048.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"308.2948,-2048.9039 305.1584,-2038.784 301.2994,-2048.651 308.2948,-2048.9039\" stroke=\"#000000\"/>\n</g>\n<!-- 139686082763128 -->\n<g class=\"node\" id=\"node31\">\n<title>139686082763128</title>\n<polygon fill=\"none\" points=\"142.5,-1909.5 142.5,-1955.5 503.5,-1955.5 503.5,-1909.5 142.5,-1909.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239\" y=\"-1928.8\">leaky_re_lu_217: LeakyReLU</text>\n<polyline fill=\"none\" points=\"335.5,-1909.5 335.5,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"364.5\" y=\"-1940.3\">input:</text>\n<polyline fill=\"none\" points=\"335.5,-1932.5 393.5,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"364.5\" y=\"-1917.3\">output:</text>\n<polyline fill=\"none\" points=\"393.5,-1909.5 393.5,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448.5\" y=\"-1940.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"393.5,-1932.5 503.5,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448.5\" y=\"-1917.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 139686081229992&#45;&gt;139686082763128 -->\n<g class=\"edge\" id=\"edge35\">\n<title>139686081229992-&gt;139686082763128</title>\n<path d=\"M310.7354,-1992.3799C312.4343,-1984.0854 314.3846,-1974.5633 316.2227,-1965.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"319.6532,-1966.2829 318.231,-1955.784 312.7956,-1964.8783 319.6532,-1966.2829\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081401128 -->\n<g class=\"node\" id=\"node32\">\n<title>139686081401128</title>\n<polygon fill=\"none\" points=\"169.5,-1826.5 169.5,-1872.5 492.5,-1872.5 492.5,-1826.5 169.5,-1826.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.5\" y=\"-1845.8\">conv2d_241: Conv2D</text>\n<polyline fill=\"none\" points=\"317.5,-1826.5 317.5,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-1857.3\">input:</text>\n<polyline fill=\"none\" points=\"317.5,-1849.5 375.5,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-1834.3\">output:</text>\n<polyline fill=\"none\" points=\"375.5,-1826.5 375.5,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434\" y=\"-1857.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"375.5,-1849.5 492.5,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434\" y=\"-1834.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 139686082763128&#45;&gt;139686081401128 -->\n<g class=\"edge\" id=\"edge36\">\n<title>139686082763128-&gt;139686081401128</title>\n<path d=\"M325.2284,-1909.3799C326.0193,-1901.1745 326.926,-1891.7679 327.7828,-1882.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"331.2801,-1883.0737 328.7558,-1872.784 324.3124,-1882.4021 331.2801,-1883.0737\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081403144 -->\n<g class=\"node\" id=\"node35\">\n<title>139686081403144</title>\n<polygon fill=\"none\" points=\"151,-1743.5 151,-1789.5 519,-1789.5 519,-1743.5 151,-1743.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.5\" y=\"-1762.8\">leaky_re_lu_218: LeakyReLU</text>\n<polyline fill=\"none\" points=\"344,-1743.5 344,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-1774.3\">input:</text>\n<polyline fill=\"none\" points=\"344,-1766.5 402,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-1751.3\">output:</text>\n<polyline fill=\"none\" points=\"402,-1743.5 402,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-1774.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"402,-1766.5 519,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.5\" y=\"-1751.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 139686081401128&#45;&gt;139686081403144 -->\n<g class=\"edge\" id=\"edge39\">\n<title>139686081401128-&gt;139686081403144</title>\n<path d=\"M332.1142,-1826.3799C332.5097,-1818.1745 332.963,-1808.7679 333.3914,-1799.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"336.8924,-1799.9409 333.8779,-1789.784 329.9005,-1799.6039 336.8924,-1799.9409\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081230216 -->\n<g class=\"node\" id=\"node36\">\n<title>139686081230216</title>\n<polygon fill=\"none\" points=\"1063.5,-1743.5 1063.5,-1789.5 1424.5,-1789.5 1424.5,-1743.5 1063.5,-1743.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1160\" y=\"-1762.8\">leaky_re_lu_219: LeakyReLU</text>\n<polyline fill=\"none\" points=\"1256.5,-1743.5 1256.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1285.5\" y=\"-1774.3\">input:</text>\n<polyline fill=\"none\" points=\"1256.5,-1766.5 1314.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1285.5\" y=\"-1751.3\">output:</text>\n<polyline fill=\"none\" points=\"1314.5,-1743.5 1314.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1369.5\" y=\"-1774.3\">(None, 8, 8, 16)</text>\n<polyline fill=\"none\" points=\"1314.5,-1766.5 1424.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1369.5\" y=\"-1751.3\">(None, 8, 8, 16)</text>\n</g>\n<!-- 139686080977384&#45;&gt;139686081230216 -->\n<g class=\"edge\" id=\"edge40\">\n<title>139686080977384-&gt;139686081230216</title>\n<path d=\"M1224.7355,-4067.2988C1232.1164,-4035.3564 1244,-3975.9399 1244,-3924.5 1244,-3924.5 1244,-3924.5 1244,-1932.5 1244,-1886.4711 1244,-1833.2629 1244,-1799.7496\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1247.5001,-1799.5948 1244,-1789.5948 1240.5001,-1799.5948 1247.5001,-1799.5948\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081151496 -->\n<g class=\"node\" id=\"node37\">\n<title>139686081151496</title>\n<polygon fill=\"none\" points=\"647.5,-1743.5 647.5,-1789.5 1008.5,-1789.5 1008.5,-1743.5 647.5,-1743.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"744\" y=\"-1762.8\">leaky_re_lu_220: LeakyReLU</text>\n<polyline fill=\"none\" points=\"840.5,-1743.5 840.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"869.5\" y=\"-1774.3\">input:</text>\n<polyline fill=\"none\" points=\"840.5,-1766.5 898.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"869.5\" y=\"-1751.3\">output:</text>\n<polyline fill=\"none\" points=\"898.5,-1743.5 898.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"953.5\" y=\"-1774.3\">(None, 8, 8, 16)</text>\n<polyline fill=\"none\" points=\"898.5,-1766.5 1008.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"953.5\" y=\"-1751.3\">(None, 8, 8, 16)</text>\n</g>\n<!-- 139686081153736&#45;&gt;139686081151496 -->\n<g class=\"edge\" id=\"edge41\">\n<title>139686081153736-&gt;139686081151496</title>\n<path d=\"M838.8232,-2656.4569C834.6926,-2624.4498 828,-2564.6915 828,-2513.5 828,-2513.5 828,-2513.5 828,-1932.5 828,-1886.4711 828,-1833.2629 828,-1799.7496\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"831.5001,-1799.5948 828,-1789.5948 824.5001,-1799.5948 831.5001,-1799.5948\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081403144&#45;&gt;139686080748848 -->\n<g class=\"edge\" id=\"edge42\">\n<title>139686081403144-&gt;139686080748848</title>\n<path d=\"M335.5571,-1743.3799C335.7548,-1735.1745 335.9815,-1725.7679 336.1957,-1716.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"339.6969,-1716.8655 336.4389,-1706.784 332.699,-1716.6968 339.6969,-1716.8655\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081230216&#45;&gt;139686080748848 -->\n<g class=\"edge\" id=\"edge43\">\n<title>139686081230216-&gt;139686080748848</title>\n<path d=\"M1063.433,-1747.5444C1047.7318,-1745.9757 1032.0861,-1744.4408 1017,-1743 887.1958,-1730.6029 743.3524,-1717.8707 621.5181,-1707.3817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"621.5591,-1703.8724 611.2959,-1706.5025 620.9592,-1710.8467 621.5591,-1703.8724\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079262392 -->\n<g class=\"node\" id=\"node50\">\n<title>139686079262392</title>\n<polygon fill=\"none\" points=\"1086,-1577.5 1086,-1623.5 1402,-1623.5 1402,-1577.5 1086,-1577.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1160\" y=\"-1596.8\">conv2d_249: Conv2D</text>\n<polyline fill=\"none\" points=\"1234,-1577.5 1234,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1263\" y=\"-1608.3\">input:</text>\n<polyline fill=\"none\" points=\"1234,-1600.5 1292,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1263\" y=\"-1585.3\">output:</text>\n<polyline fill=\"none\" points=\"1292,-1577.5 1292,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1347\" y=\"-1608.3\">(None, 8, 8, 16)</text>\n<polyline fill=\"none\" points=\"1292,-1600.5 1402,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1347\" y=\"-1585.3\">(None, 4, 4, 16)</text>\n</g>\n<!-- 139686081230216&#45;&gt;139686079262392 -->\n<g class=\"edge\" id=\"edge58\">\n<title>139686081230216-&gt;139686079262392</title>\n<path d=\"M1244,-1743.4184C1244,-1715.0047 1244,-1666.531 1244,-1634.0156\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1247.5001,-1633.6525 1244,-1623.6525 1240.5001,-1633.6526 1247.5001,-1633.6525\" stroke=\"#000000\"/>\n</g>\n<!-- 139686081151496&#45;&gt;139686080748848 -->\n<g class=\"edge\" id=\"edge44\">\n<title>139686081151496-&gt;139686080748848</title>\n<path d=\"M691.8812,-1743.4901C627.0935,-1732.5382 549.5307,-1719.4268 483.464,-1708.2587\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"483.8271,-1704.7705 473.3836,-1706.5547 482.6603,-1711.6726 483.8271,-1704.7705\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079351832 -->\n<g class=\"node\" id=\"node51\">\n<title>139686079351832</title>\n<polygon fill=\"none\" points=\"692,-1660.5 692,-1706.5 1008,-1706.5 1008,-1660.5 692,-1660.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"766\" y=\"-1679.8\">conv2d_250: Conv2D</text>\n<polyline fill=\"none\" points=\"840,-1660.5 840,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"869\" y=\"-1691.3\">input:</text>\n<polyline fill=\"none\" points=\"840,-1683.5 898,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"869\" y=\"-1668.3\">output:</text>\n<polyline fill=\"none\" points=\"898,-1660.5 898,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"953\" y=\"-1691.3\">(None, 8, 8, 16)</text>\n<polyline fill=\"none\" points=\"898,-1683.5 1008,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"953\" y=\"-1668.3\">(None, 4, 4, 16)</text>\n</g>\n<!-- 139686081151496&#45;&gt;139686079351832 -->\n<g class=\"edge\" id=\"edge59\">\n<title>139686081151496-&gt;139686079351832</title>\n<path d=\"M834.1282,-1743.3799C836.3268,-1735.0854 838.8507,-1725.5633 841.2294,-1716.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"844.6493,-1717.347 843.8283,-1706.784 837.883,-1715.5534 844.6493,-1717.347\" stroke=\"#000000\"/>\n</g>\n<!-- 139686080747616 -->\n<g class=\"node\" id=\"node39\">\n<title>139686080747616</title>\n<polygon fill=\"none\" points=\"133.5,-1577.5 133.5,-1623.5 586.5,-1623.5 586.5,-1577.5 133.5,-1577.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-1596.8\">batch_normalization_56: BatchNormalization</text>\n<polyline fill=\"none\" points=\"411.5,-1577.5 411.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"440.5\" y=\"-1608.3\">input:</text>\n<polyline fill=\"none\" points=\"411.5,-1600.5 469.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"440.5\" y=\"-1585.3\">output:</text>\n<polyline fill=\"none\" points=\"469.5,-1577.5 469.5,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"528\" y=\"-1608.3\">(None, 8, 8, 275)</text>\n<polyline fill=\"none\" points=\"469.5,-1600.5 586.5,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"528\" y=\"-1585.3\">(None, 8, 8, 275)</text>\n</g>\n<!-- 139686080748848&#45;&gt;139686080747616 -->\n<g class=\"edge\" id=\"edge46\">\n<title>139686080748848-&gt;139686080747616</title>\n<path d=\"M343.4068,-1660.3799C345.7053,-1652.0854 348.3439,-1642.5633 350.8308,-1633.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"354.2502,-1634.3555 353.5478,-1623.784 347.5044,-1632.4862 354.2502,-1634.3555\" stroke=\"#000000\"/>\n</g>\n<!-- 139686080748792 -->\n<g class=\"node\" id=\"node40\">\n<title>139686080748792</title>\n<polygon fill=\"none\" points=\"203,-1494.5 203,-1540.5 607,-1540.5 607,-1494.5 203,-1494.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-1513.8\">max_pooling2d_43: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"432,-1494.5 432,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-1525.3\">input:</text>\n<polyline fill=\"none\" points=\"432,-1517.5 490,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-1502.3\">output:</text>\n<polyline fill=\"none\" points=\"490,-1494.5 490,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"548.5\" y=\"-1525.3\">(None, 8, 8, 275)</text>\n<polyline fill=\"none\" points=\"490,-1517.5 607,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"548.5\" y=\"-1502.3\">(None, 4, 4, 275)</text>\n</g>\n<!-- 139686080747616&#45;&gt;139686080748792 -->\n<g class=\"edge\" id=\"edge47\">\n<title>139686080747616-&gt;139686080748792</title>\n<path d=\"M372.535,-1577.3799C377.1771,-1568.8178 382.5284,-1558.9477 387.5301,-1549.7222\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"390.6867,-1551.2433 392.3761,-1540.784 384.533,-1547.9069 390.6867,-1551.2433\" stroke=\"#000000\"/>\n</g>\n<!-- 139686080747840 -->\n<g class=\"node\" id=\"node41\">\n<title>139686080747840</title>\n<polygon fill=\"none\" points=\"444.5,-1411.5 444.5,-1457.5 767.5,-1457.5 767.5,-1411.5 444.5,-1411.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"518.5\" y=\"-1430.8\">conv2d_244: Conv2D</text>\n<polyline fill=\"none\" points=\"592.5,-1411.5 592.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"621.5\" y=\"-1442.3\">input:</text>\n<polyline fill=\"none\" points=\"592.5,-1434.5 650.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"621.5\" y=\"-1419.3\">output:</text>\n<polyline fill=\"none\" points=\"650.5,-1411.5 650.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"709\" y=\"-1442.3\">(None, 4, 4, 275)</text>\n<polyline fill=\"none\" points=\"650.5,-1434.5 767.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"709\" y=\"-1419.3\">(None, 4, 4, 256)</text>\n</g>\n<!-- 139686080748792&#45;&gt;139686080747840 -->\n<g class=\"edge\" id=\"edge48\">\n<title>139686080748792-&gt;139686080747840</title>\n<path d=\"M460.7228,-1494.4901C485.5566,-1484.2353 514.9755,-1472.0872 540.8228,-1461.414\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"542.2617,-1464.6065 550.1688,-1457.5547 539.59,-1458.1364 542.2617,-1464.6065\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079855360 -->\n<g class=\"node\" id=\"node45\">\n<title>139686079855360</title>\n<polygon fill=\"none\" points=\"168,-1079.5 168,-1125.5 642,-1125.5 642,-1079.5 168,-1079.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259\" y=\"-1098.8\">concatenate_83: Concatenate</text>\n<polyline fill=\"none\" points=\"350,-1079.5 350,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379\" y=\"-1110.3\">input:</text>\n<polyline fill=\"none\" points=\"350,-1102.5 408,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379\" y=\"-1087.3\">output:</text>\n<polyline fill=\"none\" points=\"408,-1079.5 408,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"525\" y=\"-1110.3\">[(None, 4, 4, 256), (None, 4, 4, 275)]</text>\n<polyline fill=\"none\" points=\"408,-1102.5 642,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"525\" y=\"-1087.3\">(None, 4, 4, 531)</text>\n</g>\n<!-- 139686080748792&#45;&gt;139686079855360 -->\n<g class=\"edge\" id=\"edge53\">\n<title>139686080748792-&gt;139686079855360</title>\n<path d=\"M405,-1185.5C396.7561,-1170.6081 396.1201,-1151.7874 397.8263,-1135.8342\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"401.3057,-1136.2243 399.2293,-1125.8349 394.3736,-1135.2516 401.3057,-1136.2243\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079021008 -->\n<g class=\"node\" id=\"node56\">\n<title>139686079021008</title>\n<polygon fill=\"none\" points=\"17,-664.5 17,-710.5 793,-710.5 793,-664.5 17,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108\" y=\"-683.8\">concatenate_84: Concatenate</text>\n<polyline fill=\"none\" points=\"199,-664.5 199,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"199,-687.5 257,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"257,-664.5 257,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"525\" y=\"-695.3\">[(None, 4, 4, 512), (None, 4, 4, 16), (None, 4, 4, 16), (None, 4, 4, 16), (None, 4, 4, 275)]</text>\n<polyline fill=\"none\" points=\"257,-687.5 793,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"525\" y=\"-672.3\">(None, 4, 4, 835)</text>\n</g>\n<!-- 139686080748792&#45;&gt;139686079021008 -->\n<g class=\"edge\" id=\"edge68\">\n<title>139686080748792-&gt;139686079021008</title>\n<path d=\"M407.8392,-1494.3227C415.5339,-1427.9355 434.3117,-1238.449 405,-1185.5\" fill=\"none\" stroke=\"#000000\"/>\n<path d=\"M405,-1185.5C341.9519,-1092.3441 236.0866,-1207.9191 159,-1126 126.0503,-1090.9847 140,-1067.5807 140,-1019.5 140,-1019.5 140,-1019.5 140,-853.5 140,-779.3554 215.4251,-737.0757 285.7966,-713.7644\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"287.2273,-716.9815 295.6844,-710.5996 285.0934,-710.3146 287.2273,-716.9815\" stroke=\"#000000\"/>\n</g>\n<!-- 139686080929072 -->\n<g class=\"node\" id=\"node42\">\n<title>139686080929072</title>\n<polygon fill=\"none\" points=\"433,-1328.5 433,-1374.5 801,-1374.5 801,-1328.5 433,-1328.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"529.5\" y=\"-1347.8\">leaky_re_lu_221: LeakyReLU</text>\n<polyline fill=\"none\" points=\"626,-1328.5 626,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655\" y=\"-1359.3\">input:</text>\n<polyline fill=\"none\" points=\"626,-1351.5 684,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655\" y=\"-1336.3\">output:</text>\n<polyline fill=\"none\" points=\"684,-1328.5 684,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"742.5\" y=\"-1359.3\">(None, 4, 4, 256)</text>\n<polyline fill=\"none\" points=\"684,-1351.5 801,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"742.5\" y=\"-1336.3\">(None, 4, 4, 256)</text>\n</g>\n<!-- 139686080747840&#45;&gt;139686080929072 -->\n<g class=\"edge\" id=\"edge49\">\n<title>139686080747840-&gt;139686080929072</title>\n<path d=\"M609.0641,-1411.3799C610.1516,-1403.1745 611.3982,-1393.7679 612.5763,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"616.0699,-1385.1572 613.9142,-1374.784 609.1306,-1384.2375 616.0699,-1385.1572\" stroke=\"#000000\"/>\n</g>\n<!-- 139686080102296 -->\n<g class=\"node\" id=\"node43\">\n<title>139686080102296</title>\n<polygon fill=\"none\" points=\"455.5,-1245.5 455.5,-1291.5 778.5,-1291.5 778.5,-1245.5 455.5,-1245.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"529.5\" y=\"-1264.8\">conv2d_245: Conv2D</text>\n<polyline fill=\"none\" points=\"603.5,-1245.5 603.5,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"632.5\" y=\"-1276.3\">input:</text>\n<polyline fill=\"none\" points=\"603.5,-1268.5 661.5,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"632.5\" y=\"-1253.3\">output:</text>\n<polyline fill=\"none\" points=\"661.5,-1245.5 661.5,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"720\" y=\"-1276.3\">(None, 4, 4, 256)</text>\n<polyline fill=\"none\" points=\"661.5,-1268.5 778.5,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"720\" y=\"-1253.3\">(None, 4, 4, 256)</text>\n</g>\n<!-- 139686080929072&#45;&gt;139686080102296 -->\n<g class=\"edge\" id=\"edge50\">\n<title>139686080929072-&gt;139686080102296</title>\n<path d=\"M617,-1328.3799C617,-1320.1745 617,-1310.7679 617,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"620.5001,-1301.784 617,-1291.784 613.5001,-1301.784 620.5001,-1301.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686080100560 -->\n<g class=\"node\" id=\"node44\">\n<title>139686080100560</title>\n<polygon fill=\"none\" points=\"433,-1162.5 433,-1208.5 801,-1208.5 801,-1162.5 433,-1162.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"529.5\" y=\"-1181.8\">leaky_re_lu_222: LeakyReLU</text>\n<polyline fill=\"none\" points=\"626,-1162.5 626,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655\" y=\"-1193.3\">input:</text>\n<polyline fill=\"none\" points=\"626,-1185.5 684,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655\" y=\"-1170.3\">output:</text>\n<polyline fill=\"none\" points=\"684,-1162.5 684,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"742.5\" y=\"-1193.3\">(None, 4, 4, 256)</text>\n<polyline fill=\"none\" points=\"684,-1185.5 801,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"742.5\" y=\"-1170.3\">(None, 4, 4, 256)</text>\n</g>\n<!-- 139686080102296&#45;&gt;139686080100560 -->\n<g class=\"edge\" id=\"edge51\">\n<title>139686080102296-&gt;139686080100560</title>\n<path d=\"M617,-1245.3799C617,-1237.1745 617,-1227.7679 617,-1218.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"620.5001,-1218.784 617,-1208.784 613.5001,-1218.784 620.5001,-1218.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686080100560&#45;&gt;139686079855360 -->\n<g class=\"edge\" id=\"edge52\">\n<title>139686080100560-&gt;139686079855360</title>\n<path d=\"M558.2277,-1162.4901C531.92,-1152.1904 500.7337,-1139.9806 473.3856,-1129.2736\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"474.4744,-1125.9413 463.8866,-1125.5547 471.9224,-1132.4595 474.4744,-1125.9413\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079856480 -->\n<g class=\"node\" id=\"node46\">\n<title>139686079856480</title>\n<polygon fill=\"none\" points=\"243.5,-996.5 243.5,-1042.5 566.5,-1042.5 566.5,-996.5 243.5,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-1015.8\">conv2d_246: Conv2D</text>\n<polyline fill=\"none\" points=\"391.5,-996.5 391.5,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"391.5,-1019.5 449.5,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"449.5,-996.5 449.5,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508\" y=\"-1027.3\">(None, 4, 4, 531)</text>\n<polyline fill=\"none\" points=\"449.5,-1019.5 566.5,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508\" y=\"-1004.3\">(None, 4, 4, 512)</text>\n</g>\n<!-- 139686079855360&#45;&gt;139686079856480 -->\n<g class=\"edge\" id=\"edge54\">\n<title>139686079855360-&gt;139686079856480</title>\n<path d=\"M405,-1079.3799C405,-1071.1745 405,-1061.7679 405,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-1052.784 405,-1042.784 401.5001,-1052.784 408.5001,-1052.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686080928848 -->\n<g class=\"node\" id=\"node47\">\n<title>139686080928848</title>\n<polygon fill=\"none\" points=\"221,-913.5 221,-959.5 589,-959.5 589,-913.5 221,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-932.8\">leaky_re_lu_223: LeakyReLU</text>\n<polyline fill=\"none\" points=\"414,-913.5 414,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"414,-936.5 472,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"472,-913.5 472,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-944.3\">(None, 4, 4, 512)</text>\n<polyline fill=\"none\" points=\"472,-936.5 589,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-921.3\">(None, 4, 4, 512)</text>\n</g>\n<!-- 139686079856480&#45;&gt;139686080928848 -->\n<g class=\"edge\" id=\"edge55\">\n<title>139686079856480-&gt;139686080928848</title>\n<path d=\"M405,-996.3799C405,-988.1745 405,-978.7679 405,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-969.784 405,-959.784 401.5001,-969.784 408.5001,-969.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079492504 -->\n<g class=\"node\" id=\"node48\">\n<title>139686079492504</title>\n<polygon fill=\"none\" points=\"243.5,-830.5 243.5,-876.5 566.5,-876.5 566.5,-830.5 243.5,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-849.8\">conv2d_247: Conv2D</text>\n<polyline fill=\"none\" points=\"391.5,-830.5 391.5,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"391.5,-853.5 449.5,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"449.5,-830.5 449.5,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508\" y=\"-861.3\">(None, 4, 4, 512)</text>\n<polyline fill=\"none\" points=\"449.5,-853.5 566.5,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508\" y=\"-838.3\">(None, 4, 4, 512)</text>\n</g>\n<!-- 139686080928848&#45;&gt;139686079492504 -->\n<g class=\"edge\" id=\"edge56\">\n<title>139686080928848-&gt;139686079492504</title>\n<path d=\"M405,-913.3799C405,-905.1745 405,-895.7679 405,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-886.784 405,-876.784 401.5001,-886.784 408.5001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079495696 -->\n<g class=\"node\" id=\"node52\">\n<title>139686079495696</title>\n<polygon fill=\"none\" points=\"221,-747.5 221,-793.5 589,-793.5 589,-747.5 221,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-766.8\">leaky_re_lu_224: LeakyReLU</text>\n<polyline fill=\"none\" points=\"414,-747.5 414,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"414,-770.5 472,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"472,-747.5 472,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-778.3\">(None, 4, 4, 512)</text>\n<polyline fill=\"none\" points=\"472,-770.5 589,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-755.3\">(None, 4, 4, 512)</text>\n</g>\n<!-- 139686079492504&#45;&gt;139686079495696 -->\n<g class=\"edge\" id=\"edge60\">\n<title>139686079492504-&gt;139686079495696</title>\n<path d=\"M405,-830.3799C405,-822.1745 405,-812.7679 405,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-803.784 405,-793.784 401.5001,-803.784 408.5001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079856312 -->\n<g class=\"node\" id=\"node53\">\n<title>139686079856312</title>\n<polygon fill=\"none\" points=\"855.5,-2490.5 855.5,-2536.5 1216.5,-2536.5 1216.5,-2490.5 855.5,-2490.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"952\" y=\"-2509.8\">leaky_re_lu_225: LeakyReLU</text>\n<polyline fill=\"none\" points=\"1048.5,-2490.5 1048.5,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1077.5\" y=\"-2521.3\">input:</text>\n<polyline fill=\"none\" points=\"1048.5,-2513.5 1106.5,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1077.5\" y=\"-2498.3\">output:</text>\n<polyline fill=\"none\" points=\"1106.5,-2490.5 1106.5,-2536.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1161.5\" y=\"-2521.3\">(None, 4, 4, 16)</text>\n<polyline fill=\"none\" points=\"1106.5,-2513.5 1216.5,-2513.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1161.5\" y=\"-2498.3\">(None, 4, 4, 16)</text>\n</g>\n<!-- 139686079606344&#45;&gt;139686079856312 -->\n<g class=\"edge\" id=\"edge61\">\n<title>139686079606344-&gt;139686079856312</title>\n<path d=\"M1036,-2573.3799C1036,-2565.1745 1036,-2555.7679 1036,-2546.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1039.5001,-2546.784 1036,-2536.784 1032.5001,-2546.784 1039.5001,-2546.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079260544 -->\n<g class=\"node\" id=\"node54\">\n<title>139686079260544</title>\n<polygon fill=\"none\" points=\"1063.5,-1411.5 1063.5,-1457.5 1424.5,-1457.5 1424.5,-1411.5 1063.5,-1411.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1160\" y=\"-1430.8\">leaky_re_lu_226: LeakyReLU</text>\n<polyline fill=\"none\" points=\"1256.5,-1411.5 1256.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1285.5\" y=\"-1442.3\">input:</text>\n<polyline fill=\"none\" points=\"1256.5,-1434.5 1314.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1285.5\" y=\"-1419.3\">output:</text>\n<polyline fill=\"none\" points=\"1314.5,-1411.5 1314.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1369.5\" y=\"-1442.3\">(None, 4, 4, 16)</text>\n<polyline fill=\"none\" points=\"1314.5,-1434.5 1424.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1369.5\" y=\"-1419.3\">(None, 4, 4, 16)</text>\n</g>\n<!-- 139686079262392&#45;&gt;139686079260544 -->\n<g class=\"edge\" id=\"edge62\">\n<title>139686079262392-&gt;139686079260544</title>\n<path d=\"M1244,-1577.4184C1244,-1549.0047 1244,-1500.531 1244,-1468.0156\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1247.5001,-1467.6525 1244,-1457.6525 1240.5001,-1467.6526 1247.5001,-1467.6525\" stroke=\"#000000\"/>\n</g>\n<!-- 139686078916536 -->\n<g class=\"node\" id=\"node55\">\n<title>139686078916536</title>\n<polygon fill=\"none\" points=\"647.5,-1494.5 647.5,-1540.5 1008.5,-1540.5 1008.5,-1494.5 647.5,-1494.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"744\" y=\"-1513.8\">leaky_re_lu_227: LeakyReLU</text>\n<polyline fill=\"none\" points=\"840.5,-1494.5 840.5,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"869.5\" y=\"-1525.3\">input:</text>\n<polyline fill=\"none\" points=\"840.5,-1517.5 898.5,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"869.5\" y=\"-1502.3\">output:</text>\n<polyline fill=\"none\" points=\"898.5,-1494.5 898.5,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"953.5\" y=\"-1525.3\">(None, 4, 4, 16)</text>\n<polyline fill=\"none\" points=\"898.5,-1517.5 1008.5,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"953.5\" y=\"-1502.3\">(None, 4, 4, 16)</text>\n</g>\n<!-- 139686079351832&#45;&gt;139686078916536 -->\n<g class=\"edge\" id=\"edge63\">\n<title>139686079351832-&gt;139686078916536</title>\n<path d=\"M846.941,-1660.4184C843.159,-1631.8812 836.6952,-1583.1091 832.3857,-1550.5924\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"835.852,-1550.106 831.0684,-1540.6525 828.9126,-1551.0257 835.852,-1550.106\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079495696&#45;&gt;139686079021008 -->\n<g class=\"edge\" id=\"edge64\">\n<title>139686079495696-&gt;139686079021008</title>\n<path d=\"M405,-747.3799C405,-739.1745 405,-729.7679 405,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-720.784 405,-710.784 401.5001,-720.784 408.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079856312&#45;&gt;139686079021008 -->\n<g class=\"edge\" id=\"edge65\">\n<title>139686079856312-&gt;139686079021008</title>\n<path d=\"M1036,-2490.4052C1036,-2458.3381 1036,-2398.5104 1036,-2347.5 1036,-2347.5 1036,-2347.5 1036,-1600.5 1036,-1563.6111 1004.1092,-1453.0409 1036,-1434.5\" fill=\"none\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079260544&#45;&gt;139686079021008 -->\n<g class=\"edge\" id=\"edge66\">\n<title>139686079260544-&gt;139686079021008</title>\n<path d=\"M1238.8322,-1411.4768C1236.1253,-1394.1214 1235.0004,-1370.1968 1244,-1351.5\" fill=\"none\" stroke=\"#000000\"/>\n</g>\n<!-- 139686078916536&#45;&gt;139686079021008 -->\n<g class=\"edge\" id=\"edge67\">\n<title>139686078916536-&gt;139686079021008</title>\n<path d=\"M900.701,-1494.4191C941.7884,-1479.9389 993.3126,-1459.318 1036,-1434.5\" fill=\"none\" stroke=\"#000000\"/>\n<path d=\"M1036,-1434.5C1047.6113,-1427.7493 1043.8992,-1418.5609 1055,-1411 1127.7848,-1361.425 1205.805,-1430.8502 1244,-1351.5\" fill=\"none\" stroke=\"#000000\"/>\n<path d=\"M1244,-1351.5C1275.9987,-1285.0226 1244,-1259.2778 1244,-1185.5 1244,-1185.5 1244,-1185.5 1244,-853.5 1244,-791.8065 890.3899,-740.253 642.3,-711.6753\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"642.379,-708.1616 632.0455,-710.5002 641.582,-715.1161 642.379,-708.1616\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079020560 -->\n<g class=\"node\" id=\"node57\">\n<title>139686079020560</title>\n<polygon fill=\"none\" points=\"178.5,-581.5 178.5,-627.5 631.5,-627.5 631.5,-581.5 178.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-600.8\">batch_normalization_57: BatchNormalization</text>\n<polyline fill=\"none\" points=\"456.5,-581.5 456.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"456.5,-604.5 514.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"514.5,-581.5 514.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573\" y=\"-612.3\">(None, 4, 4, 835)</text>\n<polyline fill=\"none\" points=\"514.5,-604.5 631.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573\" y=\"-589.3\">(None, 4, 4, 835)</text>\n</g>\n<!-- 139686079021008&#45;&gt;139686079020560 -->\n<g class=\"edge\" id=\"edge69\">\n<title>139686079021008-&gt;139686079020560</title>\n<path d=\"M405,-664.3799C405,-656.1745 405,-646.7679 405,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-637.784 405,-627.784 401.5001,-637.784 408.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686079018656 -->\n<g class=\"node\" id=\"node58\">\n<title>139686079018656</title>\n<polygon fill=\"none\" points=\"243.5,-498.5 243.5,-544.5 566.5,-544.5 566.5,-498.5 243.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-517.8\">conv2d_251: Conv2D</text>\n<polyline fill=\"none\" points=\"391.5,-498.5 391.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"391.5,-521.5 449.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"449.5,-498.5 449.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508\" y=\"-529.3\">(None, 4, 4, 835)</text>\n<polyline fill=\"none\" points=\"449.5,-521.5 566.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508\" y=\"-506.3\">(None, 2, 2, 512)</text>\n</g>\n<!-- 139686079020560&#45;&gt;139686079018656 -->\n<g class=\"edge\" id=\"edge70\">\n<title>139686079020560-&gt;139686079018656</title>\n<path d=\"M405,-581.3799C405,-573.1745 405,-563.7679 405,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-554.784 405,-544.784 401.5001,-554.784 408.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686078671336 -->\n<g class=\"node\" id=\"node59\">\n<title>139686078671336</title>\n<polygon fill=\"none\" points=\"221,-415.5 221,-461.5 589,-461.5 589,-415.5 221,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-434.8\">leaky_re_lu_228: LeakyReLU</text>\n<polyline fill=\"none\" points=\"414,-415.5 414,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"414,-438.5 472,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"472,-415.5 472,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-446.3\">(None, 2, 2, 512)</text>\n<polyline fill=\"none\" points=\"472,-438.5 589,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-423.3\">(None, 2, 2, 512)</text>\n</g>\n<!-- 139686079018656&#45;&gt;139686078671336 -->\n<g class=\"edge\" id=\"edge71\">\n<title>139686079018656-&gt;139686078671336</title>\n<path d=\"M405,-498.3799C405,-490.1745 405,-480.7679 405,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-471.784 405,-461.784 401.5001,-471.784 408.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686078751296 -->\n<g class=\"node\" id=\"node60\">\n<title>139686078751296</title>\n<polygon fill=\"none\" points=\"243.5,-332.5 243.5,-378.5 566.5,-378.5 566.5,-332.5 243.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-351.8\">conv2d_252: Conv2D</text>\n<polyline fill=\"none\" points=\"391.5,-332.5 391.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"391.5,-355.5 449.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"449.5,-332.5 449.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508\" y=\"-363.3\">(None, 2, 2, 512)</text>\n<polyline fill=\"none\" points=\"449.5,-355.5 566.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508\" y=\"-340.3\">(None, 2, 2, 256)</text>\n</g>\n<!-- 139686078671336&#45;&gt;139686078751296 -->\n<g class=\"edge\" id=\"edge72\">\n<title>139686078671336-&gt;139686078751296</title>\n<path d=\"M405,-415.3799C405,-407.1745 405,-397.7679 405,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-388.784 405,-378.784 401.5001,-388.784 408.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686078754656 -->\n<g class=\"node\" id=\"node61\">\n<title>139686078754656</title>\n<polygon fill=\"none\" points=\"221,-249.5 221,-295.5 589,-295.5 589,-249.5 221,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-268.8\">leaky_re_lu_229: LeakyReLU</text>\n<polyline fill=\"none\" points=\"414,-249.5 414,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"414,-272.5 472,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"443\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"472,-249.5 472,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-280.3\">(None, 2, 2, 256)</text>\n<polyline fill=\"none\" points=\"472,-272.5 589,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-257.3\">(None, 2, 2, 256)</text>\n</g>\n<!-- 139686078751296&#45;&gt;139686078754656 -->\n<g class=\"edge\" id=\"edge73\">\n<title>139686078751296-&gt;139686078754656</title>\n<path d=\"M405,-332.3799C405,-324.1745 405,-314.7679 405,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-305.784 405,-295.784 401.5001,-305.784 408.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686077598408 -->\n<g class=\"node\" id=\"node62\">\n<title>139686077598408</title>\n<polygon fill=\"none\" points=\"178.5,-166.5 178.5,-212.5 631.5,-212.5 631.5,-166.5 178.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-185.8\">batch_normalization_58: BatchNormalization</text>\n<polyline fill=\"none\" points=\"456.5,-166.5 456.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"456.5,-189.5 514.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"514.5,-166.5 514.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573\" y=\"-197.3\">(None, 2, 2, 256)</text>\n<polyline fill=\"none\" points=\"514.5,-189.5 631.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573\" y=\"-174.3\">(None, 2, 2, 256)</text>\n</g>\n<!-- 139686078754656&#45;&gt;139686077598408 -->\n<g class=\"edge\" id=\"edge74\">\n<title>139686078754656-&gt;139686077598408</title>\n<path d=\"M405,-249.3799C405,-241.1745 405,-231.7679 405,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-222.784 405,-212.784 401.5001,-222.784 408.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686078585768 -->\n<g class=\"node\" id=\"node63\">\n<title>139686078585768</title>\n<polygon fill=\"none\" points=\"142.5,-83.5 142.5,-129.5 667.5,-129.5 667.5,-83.5 142.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-102.8\">global_average_pooling2d_11: GlobalAveragePooling2D</text>\n<polyline fill=\"none\" points=\"492.5,-83.5 492.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"521.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"492.5,-106.5 550.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"521.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"550.5,-83.5 550.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"609\" y=\"-114.3\">(None, 2, 2, 256)</text>\n<polyline fill=\"none\" points=\"550.5,-106.5 667.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"609\" y=\"-91.3\">(None, 256)</text>\n</g>\n<!-- 139686077598408&#45;&gt;139686078585768 -->\n<g class=\"edge\" id=\"edge75\">\n<title>139686077598408-&gt;139686078585768</title>\n<path d=\"M405,-166.3799C405,-158.1745 405,-148.7679 405,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-139.784 405,-129.784 401.5001,-139.784 408.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139686077599304 -->\n<g class=\"node\" id=\"node64\">\n<title>139686077599304</title>\n<polygon fill=\"none\" points=\"276,-.5 276,-46.5 534,-46.5 534,-.5 276,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"332.5\" y=\"-19.8\">dense_11: Dense</text>\n<polyline fill=\"none\" points=\"389,-.5 389,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"418\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"389,-23.5 447,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"418\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"447,-.5 447,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490.5\" y=\"-31.3\">(None, 256)</text>\n<polyline fill=\"none\" points=\"447,-23.5 534,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490.5\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 139686078585768&#45;&gt;139686077599304 -->\n<g class=\"edge\" id=\"edge76\">\n<title>139686078585768-&gt;139686077599304</title>\n<path d=\"M405,-83.3799C405,-75.1745 405,-65.7679 405,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"408.5001,-56.784 405,-46.784 401.5001,-56.784 408.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-hDgH2UVrUM",
        "colab_type": "code",
        "outputId": "7606d510-28ca-4a8d-cb2a-bb39008a66d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6535
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD, Adagrad\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_14.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=5, verbose=1, min_lr=1e-4) #<<---------\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "# optimizer = Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
        "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                        batch_size=128),\n",
        "                        samples_per_epoch=x_train.shape[0],\n",
        "                        nb_epoch=100,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=390, epochs=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 1.2125 - acc: 0.5663 - val_loss: 1.0308 - val_acc: 0.6683\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.66830, saving model to cifar10_model_14.h5\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.7688 - acc: 0.7317 - val_loss: 1.2345 - val_acc: 0.6587\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.66830\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.6352 - acc: 0.7790 - val_loss: 0.7532 - val_acc: 0.7590\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.66830 to 0.75900, saving model to cifar10_model_14.h5\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.5651 - acc: 0.8042 - val_loss: 0.7114 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.75900 to 0.78050, saving model to cifar10_model_14.h5\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5145 - acc: 0.8193 - val_loss: 0.6199 - val_acc: 0.7968\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.78050 to 0.79680, saving model to cifar10_model_14.h5\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.4747 - acc: 0.8334 - val_loss: 0.6543 - val_acc: 0.7873\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.79680\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.4409 - acc: 0.8481 - val_loss: 0.5449 - val_acc: 0.8188\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.79680 to 0.81880, saving model to cifar10_model_14.h5\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 29s 76ms/step - loss: 0.4129 - acc: 0.8555 - val_loss: 0.5431 - val_acc: 0.8224\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.81880 to 0.82240, saving model to cifar10_model_14.h5\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.3910 - acc: 0.8645 - val_loss: 0.5240 - val_acc: 0.8264\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.82240 to 0.82640, saving model to cifar10_model_14.h5\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.3672 - acc: 0.8717 - val_loss: 0.5662 - val_acc: 0.8156\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.82640\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.3492 - acc: 0.8779 - val_loss: 0.5231 - val_acc: 0.8217\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.82640\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.3326 - acc: 0.8824 - val_loss: 0.5592 - val_acc: 0.8336\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.82640 to 0.83360, saving model to cifar10_model_14.h5\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.3220 - acc: 0.8868 - val_loss: 0.5739 - val_acc: 0.8292\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.83360\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.3053 - acc: 0.8932 - val_loss: 0.4617 - val_acc: 0.8547\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.83360 to 0.85470, saving model to cifar10_model_14.h5\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 29s 76ms/step - loss: 0.2885 - acc: 0.8997 - val_loss: 0.5155 - val_acc: 0.8461\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.85470\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.2764 - acc: 0.9020 - val_loss: 0.4252 - val_acc: 0.8651\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.85470 to 0.86510, saving model to cifar10_model_14.h5\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2671 - acc: 0.9050 - val_loss: 0.6947 - val_acc: 0.7889\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.86510\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2553 - acc: 0.9101 - val_loss: 0.4746 - val_acc: 0.8506\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.86510\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.2480 - acc: 0.9126 - val_loss: 0.4795 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.86510\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.2379 - acc: 0.9163 - val_loss: 0.4580 - val_acc: 0.8607\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.86510\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.2273 - acc: 0.9195 - val_loss: 0.4506 - val_acc: 0.8597\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.86510\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.1749 - acc: 0.9383 - val_loss: 0.3870 - val_acc: 0.8748\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.86510 to 0.87480, saving model to cifar10_model_14.h5\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.1577 - acc: 0.9448 - val_loss: 0.5131 - val_acc: 0.8563\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.87480\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.1521 - acc: 0.9465 - val_loss: 0.4194 - val_acc: 0.8784\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.87480 to 0.87840, saving model to cifar10_model_14.h5\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.1430 - acc: 0.9494 - val_loss: 0.4437 - val_acc: 0.8735\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.87840\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 29s 76ms/step - loss: 0.1386 - acc: 0.9516 - val_loss: 0.4126 - val_acc: 0.8813\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.87840 to 0.88130, saving model to cifar10_model_14.h5\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.1348 - acc: 0.9520 - val_loss: 0.4160 - val_acc: 0.8824\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.88130 to 0.88240, saving model to cifar10_model_14.h5\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.1321 - acc: 0.9534 - val_loss: 0.4368 - val_acc: 0.8807\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.88240\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.1235 - acc: 0.9563 - val_loss: 0.4597 - val_acc: 0.8799\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.88240\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.1199 - acc: 0.9572 - val_loss: 0.4071 - val_acc: 0.8851\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.88240 to 0.88510, saving model to cifar10_model_14.h5\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.1175 - acc: 0.9590 - val_loss: 0.4355 - val_acc: 0.8795\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.88510\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.1110 - acc: 0.9606 - val_loss: 0.4481 - val_acc: 0.8827\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.88510\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.1087 - acc: 0.9610 - val_loss: 0.4805 - val_acc: 0.8837\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.88510\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.1057 - acc: 0.9621 - val_loss: 0.4101 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.88510 to 0.88960, saving model to cifar10_model_14.h5\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.1052 - acc: 0.9626 - val_loss: 0.4548 - val_acc: 0.8823\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.88960\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0997 - acc: 0.9647 - val_loss: 0.4311 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.88960\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.1011 - acc: 0.9636 - val_loss: 0.4214 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.88960\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0963 - acc: 0.9669 - val_loss: 0.4673 - val_acc: 0.8821\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.88960\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 29s 76ms/step - loss: 0.0972 - acc: 0.9649 - val_loss: 0.5615 - val_acc: 0.8683\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.88960\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 29s 76ms/step - loss: 0.0723 - acc: 0.9748 - val_loss: 0.4399 - val_acc: 0.8898\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.88960 to 0.88980, saving model to cifar10_model_14.h5\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0620 - acc: 0.9789 - val_loss: 0.4196 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.88980\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0598 - acc: 0.9786 - val_loss: 0.4317 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.88980 to 0.89690, saving model to cifar10_model_14.h5\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0584 - acc: 0.9800 - val_loss: 0.4416 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.89690\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0582 - acc: 0.9793 - val_loss: 0.4313 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00044: val_acc improved from 0.89690 to 0.89850, saving model to cifar10_model_14.h5\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0578 - acc: 0.9801 - val_loss: 0.4480 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.89850\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 29s 76ms/step - loss: 0.0534 - acc: 0.9814 - val_loss: 0.4159 - val_acc: 0.8977\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.89850\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0527 - acc: 0.9825 - val_loss: 0.4394 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.89850\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0516 - acc: 0.9820 - val_loss: 0.4489 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00048: val_acc improved from 0.89850 to 0.90050, saving model to cifar10_model_14.h5\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0506 - acc: 0.9828 - val_loss: 0.4776 - val_acc: 0.8910\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.90050\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0508 - acc: 0.9825 - val_loss: 0.4527 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00050: val_acc improved from 0.90050 to 0.90260, saving model to cifar10_model_14.h5\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0529 - acc: 0.9815 - val_loss: 0.4476 - val_acc: 0.8943\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.90260\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0471 - acc: 0.9831 - val_loss: 0.5108 - val_acc: 0.8844\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.90260\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0475 - acc: 0.9831 - val_loss: 0.5314 - val_acc: 0.8826\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.90260\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0471 - acc: 0.9827 - val_loss: 0.5118 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.90260\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0468 - acc: 0.9832 - val_loss: 0.4585 - val_acc: 0.9010\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.90260\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0368 - acc: 0.9875 - val_loss: 0.4582 - val_acc: 0.9005\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.90260\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0341 - acc: 0.9882 - val_loss: 0.4694 - val_acc: 0.8971\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.90260\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0329 - acc: 0.9893 - val_loss: 0.4471 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.90260\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 29s 76ms/step - loss: 0.0325 - acc: 0.9889 - val_loss: 0.4694 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.90260\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0312 - acc: 0.9895 - val_loss: 0.4644 - val_acc: 0.9014\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.90260\n",
            "\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0280 - acc: 0.9903 - val_loss: 0.4670 - val_acc: 0.9008\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.90260\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 0.0263 - acc: 0.9912 - val_loss: 0.4483 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00062: val_acc improved from 0.90260 to 0.90450, saving model to cifar10_model_14.h5\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0252 - acc: 0.9914 - val_loss: 0.4535 - val_acc: 0.9046\n",
            "\n",
            "Epoch 00063: val_acc improved from 0.90450 to 0.90460, saving model to cifar10_model_14.h5\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0246 - acc: 0.9919 - val_loss: 0.4591 - val_acc: 0.9029\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.90460\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0241 - acc: 0.9915 - val_loss: 0.4705 - val_acc: 0.9018\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.90460\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 29s 76ms/step - loss: 0.0233 - acc: 0.9918 - val_loss: 0.4525 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.90460\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.0230 - acc: 0.9926 - val_loss: 0.4536 - val_acc: 0.9039\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.90460\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0229 - acc: 0.9919 - val_loss: 0.4746 - val_acc: 0.9015\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.90460\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0215 - acc: 0.9930 - val_loss: 0.4730 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.90460\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0230 - acc: 0.9922 - val_loss: 0.4673 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.90460\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0208 - acc: 0.9935 - val_loss: 0.4683 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.90460\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.0213 - acc: 0.9925 - val_loss: 0.4674 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.90460\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.0211 - acc: 0.9929 - val_loss: 0.4566 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.90460\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.0199 - acc: 0.9932 - val_loss: 0.4641 - val_acc: 0.9051\n",
            "\n",
            "Epoch 00074: val_acc improved from 0.90460 to 0.90510, saving model to cifar10_model_14.h5\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.0187 - acc: 0.9937 - val_loss: 0.4570 - val_acc: 0.9055\n",
            "\n",
            "Epoch 00075: val_acc improved from 0.90510 to 0.90550, saving model to cifar10_model_14.h5\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.0203 - acc: 0.9935 - val_loss: 0.4789 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.90550\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.0191 - acc: 0.9936 - val_loss: 0.4585 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.90550\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.0199 - acc: 0.9931 - val_loss: 0.4655 - val_acc: 0.9059\n",
            "\n",
            "Epoch 00078: val_acc improved from 0.90550 to 0.90590, saving model to cifar10_model_14.h5\n",
            "Epoch 79/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.0201 - acc: 0.9934 - val_loss: 0.4806 - val_acc: 0.9057\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.90590\n",
            "Epoch 80/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.0201 - acc: 0.9933 - val_loss: 0.4717 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.90590\n",
            "Epoch 81/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.0198 - acc: 0.9934 - val_loss: 0.4690 - val_acc: 0.9037\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.90590\n",
            "Epoch 82/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.0191 - acc: 0.9937 - val_loss: 0.4679 - val_acc: 0.9048\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.90590\n",
            "Epoch 83/100\n",
            "146/390 [==========>...................] - ETA: 16s - loss: 0.0219 - acc: 0.9926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-84313f94c769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                         \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x8ySZSRVr2-",
        "colab_type": "code",
        "outputId": "4449405d-9516-41fa-cae7-bab786304f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_14.h5')  # 加入dropout 也许做的更好\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 387us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.465526815700531, 0.9059]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDCwYL6m7Y7P",
        "colab_type": "text"
      },
      "source": [
        "## 深度方向的可分离 2D 卷积 SeparableConv2D\n",
        "\n",
        "极大的减少参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "18a77677-328e-43fa-e1ff-29a3e2154135",
        "id": "FsapCp8a7Sva",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1439
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, SeparableConv2D, Conv2D, MaxPool2D, Dropout, Dense, GlobalAveragePooling2D, BatchNormalization, concatenate\n",
        "from keras import layers, models\n",
        "\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "temp = inputs\n",
        "x = SeparableConv2D(16, (3, 3), padding='same', activation='relu')(inputs)\n",
        "x = SeparableConv2D(16, (3, 3), padding='same', activation='relu')(x)\n",
        "x = SeparableConv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "temp = x\n",
        "x = SeparableConv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
        "x = SeparableConv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
        "x = SeparableConv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.1)(x)\n",
        "\n",
        "temp = x\n",
        "x = SeparableConv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "x = SeparableConv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = SeparableConv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "x = SeparableConv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = concatenate([x, temp])\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "temp = x\n",
        "x = SeparableConv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = SeparableConv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = SeparableConv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "x = SeparableConv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "x = concatenate([x, temp])\n",
        "x = SeparableConv2D(256, (1, 1), padding='same', activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=x)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_33 (SeparableC (None, 32, 32, 16)   91          input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_34 (SeparableC (None, 32, 32, 16)   416         separable_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_35 (SeparableC (None, 32, 32, 32)   688         separable_conv2d_34[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_93 (Concatenate)    (None, 32, 32, 35)   0           separable_conv2d_35[0][0]        \n",
            "                                                                 input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 32, 32, 35)   140         concatenate_93[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_50 (MaxPooling2D) (None, 16, 16, 35)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_36 (SeparableC (None, 16, 16, 32)   1467        max_pooling2d_50[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_37 (SeparableC (None, 16, 16, 32)   1344        separable_conv2d_36[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_38 (SeparableC (None, 16, 16, 64)   2400        separable_conv2d_37[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_94 (Concatenate)    (None, 16, 16, 99)   0           separable_conv2d_38[0][0]        \n",
            "                                                                 max_pooling2d_50[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 16, 16, 99)   396         concatenate_94[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling2D) (None, 8, 8, 99)     0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 8, 8, 99)     0           max_pooling2d_51[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_39 (SeparableC (None, 8, 8, 64)     7291        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_40 (SeparableC (None, 8, 8, 64)     4736        separable_conv2d_39[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 64)     256         separable_conv2d_40[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_41 (SeparableC (None, 8, 8, 64)     4736        batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_42 (SeparableC (None, 8, 8, 128)    8896        separable_conv2d_41[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_95 (Concatenate)    (None, 8, 8, 227)    0           separable_conv2d_42[0][0]        \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 227)    908         concatenate_95[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling2D) (None, 4, 4, 227)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 4, 4, 227)    0           max_pooling2d_52[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_43 (SeparableC (None, 4, 4, 128)    31227       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_44 (SeparableC (None, 4, 4, 128)    17664       separable_conv2d_43[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 4, 4, 128)    512         separable_conv2d_44[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_45 (SeparableC (None, 4, 4, 256)    34176       batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_46 (SeparableC (None, 4, 4, 256)    68096       separable_conv2d_45[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_96 (Concatenate)    (None, 4, 4, 483)    0           separable_conv2d_46[0][0]        \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_47 (SeparableC (None, 4, 4, 256)    124387      concatenate_96[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 4, 4, 256)    1024        separable_conv2d_47[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_14 (Gl (None, 256)          0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 256)          0           global_average_pooling2d_14[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 10)           2570        dropout_9[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 313,421\n",
            "Trainable params: 311,803\n",
            "Non-trainable params: 1,618\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ToD9rSYk7SUb",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        zca_whitening=False,  # 应用ZCA白化\n",
        "        rotation_range=10,  # 在一个范围下随机旋转图像(degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # 水平随机移位图像（总宽度的分数）\n",
        "        height_shift_range=0.1,  # 随机地垂直移动图像（总高度的分数）\n",
        "        horizontal_flip=True,  # 随机翻转图像\n",
        "        vertical_flip=False)  # 随机翻转图像\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "79b02f1e-b665-4eca-df09-a03557d0c654",
        "id": "P5uhiAJt7R79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3709
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, SGD\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('cifar10_model_15.h5', monitor='val_acc', verbose=1, \n",
        "                                   mode='auto', period=1, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, min_lr=1e-4)\n",
        "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "callbacks = [model_checkpoint, reduce_lr, early_stopping]\n",
        "\n",
        "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                        batch_size=128),\n",
        "                        samples_per_epoch=x_train.shape[0],\n",
        "                        nb_epoch=100,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=390, epochs=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 1.4865 - acc: 0.4600 - val_loss: 3.9205 - val_acc: 0.2217\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.22170, saving model to cifar10_model_15.h5\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 1.1601 - acc: 0.5857 - val_loss: 3.1333 - val_acc: 0.3617\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.22170 to 0.36170, saving model to cifar10_model_15.h5\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 1.0212 - acc: 0.6373 - val_loss: 1.3561 - val_acc: 0.5755\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.36170 to 0.57550, saving model to cifar10_model_15.h5\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.9266 - acc: 0.6721 - val_loss: 2.7239 - val_acc: 0.3533\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.57550\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.8655 - acc: 0.6964 - val_loss: 0.9270 - val_acc: 0.6867\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.57550 to 0.68670, saving model to cifar10_model_15.h5\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.8134 - acc: 0.7153 - val_loss: 1.1666 - val_acc: 0.6483\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.68670\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.7761 - acc: 0.7274 - val_loss: 1.5701 - val_acc: 0.5392\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.68670\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.7404 - acc: 0.7425 - val_loss: 0.8159 - val_acc: 0.7193\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.68670 to 0.71930, saving model to cifar10_model_15.h5\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.7111 - acc: 0.7529 - val_loss: 0.9310 - val_acc: 0.7061\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.71930\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.6880 - acc: 0.7585 - val_loss: 1.0749 - val_acc: 0.6800\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.71930\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.6640 - acc: 0.7663 - val_loss: 0.7998 - val_acc: 0.7386\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.71930 to 0.73860, saving model to cifar10_model_15.h5\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 24s 63ms/step - loss: 0.6520 - acc: 0.7728 - val_loss: 0.7609 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.73860 to 0.74810, saving model to cifar10_model_15.h5\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.6252 - acc: 0.7833 - val_loss: 0.9336 - val_acc: 0.7014\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.74810\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.6196 - acc: 0.7842 - val_loss: 0.8259 - val_acc: 0.7293\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.74810\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.6012 - acc: 0.7878 - val_loss: 1.3696 - val_acc: 0.6327\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.74810\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.5879 - acc: 0.7947 - val_loss: 1.0371 - val_acc: 0.6909\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.74810\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.5769 - acc: 0.7984 - val_loss: 0.7620 - val_acc: 0.7558\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.74810 to 0.75580, saving model to cifar10_model_15.h5\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.5663 - acc: 0.8026 - val_loss: 0.7796 - val_acc: 0.7459\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.75580\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.5523 - acc: 0.8077 - val_loss: 0.6363 - val_acc: 0.7826\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.75580 to 0.78260, saving model to cifar10_model_15.h5\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 26s 66ms/step - loss: 0.5494 - acc: 0.8073 - val_loss: 0.6747 - val_acc: 0.7802\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.78260\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 26s 67ms/step - loss: 0.5369 - acc: 0.8126 - val_loss: 0.6336 - val_acc: 0.7872\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.78260 to 0.78720, saving model to cifar10_model_15.h5\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.5277 - acc: 0.8163 - val_loss: 0.7975 - val_acc: 0.7555\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.78720\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.5158 - acc: 0.8215 - val_loss: 0.5780 - val_acc: 0.8041\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.78720 to 0.80410, saving model to cifar10_model_15.h5\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.5143 - acc: 0.8208 - val_loss: 0.6429 - val_acc: 0.7869\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80410\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.5013 - acc: 0.8241 - val_loss: 0.7326 - val_acc: 0.7683\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80410\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.5001 - acc: 0.8244 - val_loss: 0.8298 - val_acc: 0.7482\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80410\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.4906 - acc: 0.8265 - val_loss: 0.6942 - val_acc: 0.7822\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80410\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.4826 - acc: 0.8316 - val_loss: 0.5474 - val_acc: 0.8188\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.80410 to 0.81880, saving model to cifar10_model_15.h5\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.4757 - acc: 0.8339 - val_loss: 0.5112 - val_acc: 0.8226\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.81880 to 0.82260, saving model to cifar10_model_15.h5\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.4637 - acc: 0.8383 - val_loss: 0.6392 - val_acc: 0.7929\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.82260\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.4719 - acc: 0.8346 - val_loss: 0.8547 - val_acc: 0.7436\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.82260\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.4615 - acc: 0.8373 - val_loss: 0.6215 - val_acc: 0.7993\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.82260\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.4601 - acc: 0.8406 - val_loss: 0.6789 - val_acc: 0.7797\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.82260\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.4521 - acc: 0.8418 - val_loss: 0.6244 - val_acc: 0.7975\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.82260\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.4049 - acc: 0.8599 - val_loss: 0.4839 - val_acc: 0.8424\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.82260 to 0.84240, saving model to cifar10_model_15.h5\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.3846 - acc: 0.8650 - val_loss: 0.4665 - val_acc: 0.8480\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.84240 to 0.84800, saving model to cifar10_model_15.h5\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3829 - acc: 0.8648 - val_loss: 0.5172 - val_acc: 0.8324\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.84800\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3686 - acc: 0.8705 - val_loss: 0.4791 - val_acc: 0.8439\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.84800\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3704 - acc: 0.8685 - val_loss: 0.4471 - val_acc: 0.8572\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.84800 to 0.85720, saving model to cifar10_model_15.h5\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3633 - acc: 0.8731 - val_loss: 0.4682 - val_acc: 0.8498\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.85720\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.3616 - acc: 0.8721 - val_loss: 0.4953 - val_acc: 0.8424\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.85720\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3513 - acc: 0.8763 - val_loss: 0.4796 - val_acc: 0.8418\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.85720\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.3532 - acc: 0.8762 - val_loss: 0.4653 - val_acc: 0.8505\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.85720\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3485 - acc: 0.8782 - val_loss: 0.4507 - val_acc: 0.8545\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.85720\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3375 - acc: 0.8824 - val_loss: 0.4610 - val_acc: 0.8525\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.85720\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.3382 - acc: 0.8822 - val_loss: 0.4668 - val_acc: 0.8513\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.85720\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 25s 63ms/step - loss: 0.3320 - acc: 0.8830 - val_loss: 0.4732 - val_acc: 0.8488\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.85720\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 25s 65ms/step - loss: 0.3350 - acc: 0.8817 - val_loss: 0.4844 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.85720\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 25s 64ms/step - loss: 0.3335 - acc: 0.8819 - val_loss: 0.4593 - val_acc: 0.8540\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.85720\n",
            "Epoch 00049: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b2a532f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9LHEY0bJFKk",
        "colab_type": "code",
        "outputId": "1e101fa7-7bab-42a9-ada1-b4e4ce7ad45a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('cifar10_model_15.h5')\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 443us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.44707265548706054, 0.8572]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7scO4Gga8ARi",
        "colab_type": "text"
      },
      "source": [
        "## ensemble 集成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3JnqIiT2e4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "def ensemble_predictions(num_networks):\n",
        "    pred_labels = []\n",
        "    test_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    # For each neural network in the ensemble.\n",
        "    for i in num_networks:\n",
        "        try:\n",
        "            model = load_model('cifar10_model_{}.h5'.format(i))\n",
        "        except:\n",
        "            print('cifar10_model_{}.h5'.format(i), '读取失败！')\n",
        "            continue\n",
        "        \n",
        "        result = model.evaluate(x_train, y_train, batch_size=256)\n",
        "        test_acc = result[-1]         #<<------------- this's train_acc, not test_acc\n",
        "        test_accuracies.append(test_acc)       \n",
        "        \n",
        "        result = model.evaluate(x_test, y_test, batch_size=256)\n",
        "        val_acc = result[-1]\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        # Print status message.\n",
        "        print(\"Network: {0}, Accuracy on Validation-Set: {1:.8f}, Test-Set: {2:.8f}\".format(i, val_acc, test_acc))\n",
        "\n",
        "\n",
        "        \n",
        "        pred = model.predict(x_test)\n",
        "        pred_labels.append(pred)\n",
        "    \n",
        "    return np.array(pred_labels), np.array(test_accuracies), np.array(val_accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnBQu8ZJ75sk",
        "colab_type": "code",
        "outputId": "e037c536-b3bb-4b57-9357-35ffbdcf32ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "pred_labels, test_accuracies, val_accuracies = ensemble_predictions(num_networks=[13,14,15])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 9s 173us/step\n",
            "10000/10000 [==============================] - 1s 83us/step\n",
            "Network: 13, Accuracy on Validation-Set: 0.90140000, Test-Set: 0.98466000\n",
            "50000/50000 [==============================] - 12s 234us/step\n",
            "10000/10000 [==============================] - 1s 122us/step\n",
            "Network: 14, Accuracy on Validation-Set: 0.90590000, Test-Set: 0.99588000\n",
            "50000/50000 [==============================] - 8s 156us/step\n",
            "10000/10000 [==============================] - 1s 63us/step\n",
            "Network: 15, Accuracy on Validation-Set: 0.85720000, Test-Set: 0.90168000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X_tvAu775mM",
        "colab_type": "code",
        "outputId": "17a65169-bbfd-416e-ea5d-2b9a86c4c750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "print(\"Mean test-set accuracy: {0:.8f}\".format(np.mean(test_accuracies)))\n",
        "print(\"Min test-set accuracy:  {0:.8f}\".format(np.min(test_accuracies)))\n",
        "print(\"Max test-set accuracy:  {0:.8f}\".format(np.max(test_accuracies)))\n",
        "\n",
        "print(\"Mean val-set accuracy: {0:.8f}\".format(np.mean(val_accuracies)))\n",
        "print(\"Min val-set accuracy:  {0:.8f}\".format(np.min(val_accuracies)))\n",
        "print(\"Max val-set accuracy:  {0:.8f}\".format(np.max(val_accuracies)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean test-set accuracy: 0.96074000\n",
            "Min test-set accuracy:  0.90168000\n",
            "Max test-set accuracy:  0.99588000\n",
            "Mean val-set accuracy: 0.88816667\n",
            "Min val-set accuracy:  0.85720000\n",
            "Max val-set accuracy:  0.90590000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GSGAtADQSwk",
        "colab_type": "code",
        "outputId": "7da9a0fb-9fd8-4358-8c43-ba87473025d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ensemble_pred_labels = np.mean(pred_labels, axis=0)\n",
        "\n",
        "ensemble_cls_pred = np.argmax(ensemble_pred_labels, axis=1)\n",
        "\n",
        "ensemble_pred_labels.shape, ensemble_cls_pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 10), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JllWNfeSQSpr",
        "colab_type": "code",
        "outputId": "cad0000a-2dc9-4592-a55f-0be25410add1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels_correct = np.argmax(y_test, axis=1)\n",
        "\n",
        "ensemble_correct = (ensemble_cls_pred == labels_correct)\n",
        "ensemble_correct"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True, ...,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ly5GxpvQSgN",
        "colab_type": "code",
        "outputId": "351f836f-feb7-4184-c051-c2eefd5e49b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(np.sum(ensemble_correct))\n",
        "print('ensemble_model acc=', np.sum(ensemble_correct)/labels_correct.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9153\n",
            "ensemble_model acc= 0.9153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl2KNM7fQo8M",
        "colab_type": "code",
        "outputId": "905514a0-b978-4583-8891-f8a97d96b36f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ensemble_incorrect = np.logical_not(ensemble_correct)\n",
        "\n",
        "print('ensemble_model wrong=', np.sum(ensemble_incorrect)/labels_correct.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ensemble_model wrong= 0.0847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh3tJZkrQtBm",
        "colab_type": "code",
        "outputId": "ebb6b567-68c7-4d54-a847-53155ab6cbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "best_net = np.argmax(val_accuracies)\n",
        "print(best_net)\n",
        "val_accuracies[best_net]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9059"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcVjfHIQQ01f",
        "colab_type": "text"
      },
      "source": [
        "ensemble_model val_acc= 0.9153\n",
        "\n",
        "best_net val_acc = 0.9059\n",
        "\n",
        "你还可以考虑不同的集成方式。\n",
        "\n",
        "That's all!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASOV2DfMQ0A_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}